{"meta":{"version":1,"warehouse":"6.0.0"},"models":{"Asset":[{"_id":"source/robots.txt","path":"robots.txt","modified":1,"renderable":0},{"_id":"source/images/Deepseek细粒度并行优化/1765984854415-8c92bb5b-773d-40bf-ae91-0f3c183b4ad9.png","path":"images/Deepseek细粒度并行优化/1765984854415-8c92bb5b-773d-40bf-ae91-0f3c183b4ad9.png","modified":1,"renderable":0},{"_id":"source/images/Deepseek细粒度并行优化/1766036708163-c76d1b1a-8375-44b2-af90-51ae6bc16d0a.png","path":"images/Deepseek细粒度并行优化/1766036708163-c76d1b1a-8375-44b2-af90-51ae6bc16d0a.png","modified":1,"renderable":0},{"_id":"source/images/Deepseek细粒度并行优化/1766039139599-0e8f3bbd-7d96-4c6a-8a8f-80cade8c0bd6.png","path":"images/Deepseek细粒度并行优化/1766039139599-0e8f3bbd-7d96-4c6a-8a8f-80cade8c0bd6.png","modified":1,"renderable":0},{"_id":"source/images/Deepseek细粒度并行优化/image-20260202201646610.png","path":"images/Deepseek细粒度并行优化/image-20260202201646610.png","modified":1,"renderable":0},{"_id":"source/images/Deepseek细粒度并行优化/image-20260202201915235.png","path":"images/Deepseek细粒度并行优化/image-20260202201915235.png","modified":1,"renderable":0},{"_id":"source/images/Deepseek细粒度并行优化/1766038523899-adf5d01b-a6a4-4f79-8f71-8c8313e55ae9.png","path":"images/Deepseek细粒度并行优化/1766038523899-adf5d01b-a6a4-4f79-8f71-8c8313e55ae9.png","modified":1,"renderable":0},{"_id":"source/images/Deepseek细粒度并行优化/image-20260202201605950.png","path":"images/Deepseek细粒度并行优化/image-20260202201605950.png","modified":1,"renderable":0},{"_id":"source/images/Deepseek细粒度并行优化/image-20260202201955025.png","path":"images/Deepseek细粒度并行优化/image-20260202201955025.png","modified":1,"renderable":0},{"_id":"source/images/Deepseek细粒度并行优化/image-20260202201704975.png","path":"images/Deepseek细粒度并行优化/image-20260202201704975.png","modified":1,"renderable":0},{"_id":"source/images/k8s-scheduler/image-20260202015836525.png","path":"images/k8s-scheduler/image-20260202015836525.png","modified":1,"renderable":0},{"_id":"source/images/k8s-scheduler/image-20260202015902141.png","path":"images/k8s-scheduler/image-20260202015902141.png","modified":1,"renderable":0},{"_id":"source/images/k8s-scheduler/image-20260202015909730.png","path":"images/k8s-scheduler/image-20260202015909730.png","modified":1,"renderable":0},{"_id":"source/images/k8s-scheduler/image-20260202020113094.png","path":"images/k8s-scheduler/image-20260202020113094.png","modified":1,"renderable":0},{"_id":"source/images/k8s-scheduler/image-20260202020144193.png","path":"images/k8s-scheduler/image-20260202020144193.png","modified":1,"renderable":0},{"_id":"source/images/Sharded-Context-Parallel/522353220-6b15a757-e1ac-4d92-a03b-b7b8bf063e27.png","path":"images/Sharded-Context-Parallel/522353220-6b15a757-e1ac-4d92-a03b-b7b8bf063e27.png","modified":1,"renderable":0},{"_id":"source/images/Sharded-Context-Parallel/543207039-e199ca08-7637-4efa-8934-2946e0423e39.png","path":"images/Sharded-Context-Parallel/543207039-e199ca08-7637-4efa-8934-2946e0423e39.png","modified":1,"renderable":0},{"_id":"source/images/Sharded-Context-Parallel/image-20260203005622667.png","path":"images/Sharded-Context-Parallel/image-20260203005622667.png","modified":1,"renderable":0},{"_id":"source/images/Sharded-Context-Parallel/image-20260203005907133.png","path":"images/Sharded-Context-Parallel/image-20260203005907133.png","modified":1,"renderable":0},{"_id":"source/images/Sharded-Context-Parallel/image-20260203005548367.png","path":"images/Sharded-Context-Parallel/image-20260203005548367.png","modified":1,"renderable":0},{"_id":"source/images/Sharded-Context-Parallel/image-20260203005633972.png","path":"images/Sharded-Context-Parallel/image-20260203005633972.png","modified":1,"renderable":0},{"_id":"source/images/Sharded-Context-Parallel/layer_sharding.png","path":"images/Sharded-Context-Parallel/layer_sharding.png","modified":1,"renderable":0},{"_id":"source/images/Sharded-Context-Parallel/image-20260203011606196.png","path":"images/Sharded-Context-Parallel/image-20260203011606196.png","modified":1,"renderable":0},{"_id":"themes/butterfly/source/css/var.styl","path":"css/var.styl","modified":1,"renderable":1},{"_id":"themes/butterfly/source/js/main.js","path":"js/main.js","modified":1,"renderable":1},{"_id":"themes/butterfly/source/css/index.styl","path":"css/index.styl","modified":1,"renderable":1},{"_id":"themes/butterfly/source/js/tw_cn.js","path":"js/tw_cn.js","modified":1,"renderable":1},{"_id":"themes/butterfly/source/img/404.jpg","path":"img/404.jpg","modified":1,"renderable":1},{"_id":"themes/butterfly/source/img/butterfly-icon.png","path":"img/butterfly-icon.png","modified":1,"renderable":1},{"_id":"themes/butterfly/source/img/error-page.png","path":"img/error-page.png","modified":1,"renderable":1},{"_id":"themes/butterfly/source/js/utils.js","path":"js/utils.js","modified":1,"renderable":1},{"_id":"themes/butterfly/source/img/friend_404.gif","path":"img/friend_404.gif","modified":1,"renderable":1},{"_id":"themes/butterfly/source/img/zzh_favicon.png","path":"img/zzh_favicon.png","modified":1,"renderable":1},{"_id":"themes/butterfly/source/img/favicon.ico","path":"img/favicon.ico","modified":1,"renderable":1},{"_id":"themes/butterfly/source/img/github_avatar.JPG","path":"img/github_avatar.JPG","modified":1,"renderable":1},{"_id":"themes/butterfly/source/js/search/local-search.js","path":"js/search/local-search.js","modified":1,"renderable":1},{"_id":"themes/butterfly/source/js/search/algolia.js","path":"js/search/algolia.js","modified":1,"renderable":1}],"Cache":[{"_id":"source/robots.txt","hash":"3f1f93969116e20641728be333c706dec3155316","modified":1769977572536},{"_id":"source/_posts/Sharded-Context-Parallel.md","hash":"826719b7c6d8582c2198238864028f21db14294e","modified":1770053250496},{"_id":"source/_posts/Deepseek细粒度并行优化.md","hash":"7cdb205e49cf39a72e24b576e5c45d1db267f2af","modified":1770053267665},{"_id":"source/_posts/hello-world.md","hash":"44992930ba21515cad58dc7d422444baaf4c9b8f","modified":1770053288924},{"_id":"source/googlee3293c3acdaf4f9f.html","hash":"438e3a017f65dbd1f6a3bc0b35b8290c4c6afa07","modified":1769977772729},{"_id":"source/tags/index.md","hash":"54e7279af07cc6ac2250007836468939a126e54c","modified":1769973766336},{"_id":"source/categories/index.md","hash":"841211fe527c772b8f3dab52c161f9733f36fbca","modified":1769973766331},{"_id":"source/_posts/k8s-scheduler.md","hash":"fdceeef586f6fc2b478e902b9d50df460f0e2a7a","modified":1769978480253},{"_id":"source/images/Deepseek细粒度并行优化/image-20260202201646610.png","hash":"c11f4adcdb349bf56d0100839ebc06597041c49f","modified":1770034606610},{"_id":"source/images/Deepseek细粒度并行优化/image-20260202201955025.png","hash":"a4cd907f63678e99f6c867a3e4697fbc9c70eea7","modified":1770034795026},{"_id":"source/images/Deepseek细粒度并行优化/image-20260202201704975.png","hash":"c11f4adcdb349bf56d0100839ebc06597041c49f","modified":1770034624976},{"_id":"source/images/Deepseek细粒度并行优化/image-20260202201605950.png","hash":"c1319b8e5df0c844c2936662d6f6199151d0ae5c","modified":1770034565950},{"_id":"source/about/index.md","hash":"c7540d43b983ac15e8e548fcb0c72bc5447a2ae6","modified":1769973766330},{"_id":"source/images/Deepseek细粒度并行优化/1766038523899-adf5d01b-a6a4-4f79-8f71-8c8313e55ae9.png","hash":"33a3d3b424ab6ee9ed0ce04d1182e0c80b5ba208","modified":1770035206913},{"_id":"source/images/k8s-scheduler/image-20260202015836525.png","hash":"7f62253291e0871528dbafffdc788d4fbb5ba3e4","modified":1769973766332},{"_id":"source/images/Deepseek细粒度并行优化/image-20260202201915235.png","hash":"99b3dd2e08378e2e530e4c32e7f911a1a75a65ef","modified":1770034755236},{"_id":"source/images/k8s-scheduler/image-20260202015902141.png","hash":"a41e2530b61f138feb02f563af9d9b1eb3e80301","modified":1769973766333},{"_id":"source/images/Sharded-Context-Parallel/522353220-6b15a757-e1ac-4d92-a03b-b7b8bf063e27.png","hash":"f95d5da76ca6c1f73c8930c54bfd9eca8206ca34","modified":1770049247833},{"_id":"source/images/Sharded-Context-Parallel/image-20260203005907133.png","hash":"6e5d1ba7387e2823ac91231df2f60ac2dd945163","modified":1770051547134},{"_id":"source/images/Sharded-Context-Parallel/layer_sharding.png","hash":"26ddfbd9872e52251cc59280a18bf9f93b691ddc","modified":1768906601662},{"_id":"themes/butterfly/plugins.yml","hash":"9827d948ad26bc13a90862c18090ed2d20761d5a","modified":1769889880612},{"_id":"themes/butterfly/README_CN.md","hash":"5595df16d0b28133a232cb5f45bbcf60798073e9","modified":1769889880604},{"_id":"themes/butterfly/languages/en.yml","hash":"6d2a5795862abc121a164e8519e7587bb57af7c7","modified":1769889880605},{"_id":"themes/butterfly/package.json","hash":"c3b121a6403087e30b6ed530aa6abb6cd1465315","modified":1769889880612},{"_id":"themes/butterfly/LICENSE","hash":"c8bc7df08db9dd3b39c2c2259a163a36cf2f6808","modified":1769889880604},{"_id":"themes/butterfly/_config.yml","hash":"2af6be3a1413f9ee85bcabde7c174c7d2a406cea","modified":1769978049412},{"_id":"themes/butterfly/languages/ja.yml","hash":"d97b97ebb8a1c8754373b450d4e81341b5dcd208","modified":1769889880605},{"_id":"themes/butterfly/languages/default.yml","hash":"97e89708bea9740e7e156b53304d7f4697f6332d","modified":1769889880604},{"_id":"themes/butterfly/languages/zh-CN.yml","hash":"25e717994a3eab37ccb9cf3ae5fec5647b525ced","modified":1769889880605},{"_id":"themes/butterfly/languages/zh-HK.yml","hash":"e2958e5b72fd2cb33b6706bc1588de6b8d9dde8f","modified":1769889880605},{"_id":"themes/butterfly/layout/archive.pug","hash":"bc77220dfc269b8faad0930e1a4142ebf68165e5","modified":1769889880605},{"_id":"themes/butterfly/languages/ko.yml","hash":"4a959730509b211484b20d9fcabc80a9c7e8cc1f","modified":1769889880605},{"_id":"themes/butterfly/layout/category.pug","hash":"a7e9805a781e34e38d27462e6ce2a5821c34bb9f","modified":1769889880605},{"_id":"themes/butterfly/languages/zh-TW.yml","hash":"af38319aa58cab193f90ef8caecdb9a26cdd165a","modified":1769889880605},{"_id":"themes/butterfly/layout/includes/footer.pug","hash":"da95d64f44e1e6b516d1f96f57b4b0a537c29c19","modified":1769889880605},{"_id":"themes/butterfly/layout/index.pug","hash":"a93004cc8ec8050df603d32a6e6e02cd96fd9875","modified":1769889880611},{"_id":"themes/butterfly/layout/page.pug","hash":"7ce2a49c6c41847de4ccea377ade116339984434","modified":1769889880611},{"_id":"themes/butterfly/layout/includes/additional-js.pug","hash":"874bd7496c606edcdc8a6150baff00299dfb9139","modified":1769889880605},{"_id":"themes/butterfly/layout/includes/head.pug","hash":"1d11e334b22dbbedcb0f751f9ee9789d4416605e","modified":1769889880605},{"_id":"themes/butterfly/layout/includes/pagination.pug","hash":"908163a8a5e6d0d9e175a2feeecda7bde58ef05a","modified":1769889880607},{"_id":"themes/butterfly/layout/includes/layout.pug","hash":"b04541e080f4485c94cad8ff477a0b140b02ddb9","modified":1769889880606},{"_id":"themes/butterfly/scripts/common/postDesc.js","hash":"ba98361b9d469076bfb045e5ff42eaf764a38fb1","modified":1769889880612},{"_id":"themes/butterfly/layout/includes/sidebar.pug","hash":"3e65b7bf6bccccbba7e15349f0a44f15c64c5b5e","modified":1769889880607},{"_id":"themes/butterfly/layout/includes/rightside.pug","hash":"3617840416f26078117f760579fb544dce07e1bc","modified":1769889880607},{"_id":"themes/butterfly/scripts/common/default_config.js","hash":"c8fa9f1a23cc404d102870e4885d9d4ba6621f59","modified":1769889880612},{"_id":"themes/butterfly/scripts/events/cdn.js","hash":"9fbab1a8c8709fc8d330bae9ba4b17a5ca5d783a","modified":1769889880612},{"_id":"themes/butterfly/scripts/events/init.js","hash":"e9eb5075c558862c4f8fbf25e2fd4ca31175fe8c","modified":1769889880612},{"_id":"themes/butterfly/scripts/events/404.js","hash":"039fc75f363d79669b0b2177d929cdff6f2ef7a4","modified":1769889880612},{"_id":"themes/butterfly/scripts/events/stylus.js","hash":"bac639c404588ea62e601ef0bcd368c3bd0119af","modified":1769889880612},{"_id":"themes/butterfly/scripts/events/welcome.js","hash":"f59e10305fef59ea3e62a7395106c0927582879d","modified":1769889880612},{"_id":"themes/butterfly/scripts/filters/random_cover.js","hash":"e3280c8f8ba5a8ce2235b78c7f70dbf3bc622979","modified":1769889880612},{"_id":"themes/butterfly/scripts/filters/post_lazyload.js","hash":"f96ccb349501dd2a268f1b64861600e3dc15e4e8","modified":1769889880612},{"_id":"themes/butterfly/scripts/helpers/aside_categories.js","hash":"a7e3776b7177c168fa5880397e9611fd3d23a995","modified":1769889880612},{"_id":"themes/butterfly/scripts/helpers/aside_archives.js","hash":"37b5c46198a2d8fbc60af857a7aa6f0929529922","modified":1769889880612},{"_id":"themes/butterfly/scripts/helpers/getArchiveLength.js","hash":"263b008efe595d841cbf488f6d59f509b7042e30","modified":1769889880613},{"_id":"themes/butterfly/scripts/helpers/page.js","hash":"6955e2a64cfa6315f68165b3fb3e8a5aa44ab057","modified":1769889880613},{"_id":"themes/butterfly/scripts/helpers/related_post.js","hash":"44ee8bc90a2e961837d4fcf280366910e88d8c52","modified":1769889880613},{"_id":"themes/butterfly/scripts/helpers/inject_head_js.js","hash":"f94370706fe2c8b0597a81afe2f3e9c29e919d83","modified":1769889880613},{"_id":"themes/butterfly/scripts/helpers/series.js","hash":"45367c4ce827329867dbcc750ec125da9ccb2cfd","modified":1769889880613},{"_id":"themes/butterfly/scripts/tag/chartjs.js","hash":"195ba802d7e8406c155124a9c939a2318f82938b","modified":1769889880613},{"_id":"themes/butterfly/scripts/tag/button.js","hash":"2f44e1b3ccd170b256eae178299d6fa933a8d490","modified":1769889880613},{"_id":"themes/butterfly/scripts/tag/gallery.js","hash":"fa3d0a64f7fce4aff7928d4ddd95548978ba001c","modified":1769889880613},{"_id":"themes/butterfly/scripts/tag/flink.js","hash":"25eefe10189caf3910a0e5d5b2f2043ae9255531","modified":1769889880613},{"_id":"themes/butterfly/scripts/tag/hide.js","hash":"1ebe936e202c1baee8f6b7862a431e43db807229","modified":1769889880613},{"_id":"themes/butterfly/scripts/tag/inlineImg.js","hash":"89c6c78d2db43b190055d5690741a79bab4f3e7e","modified":1769889880613},{"_id":"themes/butterfly/scripts/tag/note.js","hash":"e68d8d21f3a86e3646907a3685550ee20e8d4a9f","modified":1769889880613},{"_id":"themes/butterfly/scripts/tag/label.js","hash":"cf0bc17d0180231167cc6aa8a00fc64f198cb9f9","modified":1769889880613},{"_id":"themes/butterfly/scripts/tag/series.js","hash":"40bc9a065e3a1423e0e66f4911e00713ca9f5e9e","modified":1769889880613},{"_id":"themes/butterfly/scripts/tag/timeline.js","hash":"176804f07567aa80f1ed95897a968a996b155dec","modified":1769889880614},{"_id":"themes/butterfly/scripts/tag/mermaid.js","hash":"795b83d4664101a762222c80f01def86331b102e","modified":1769889880613},{"_id":"themes/butterfly/scripts/tag/tabs.js","hash":"3c486b149e28edd1a06843f05a5c355000991b82","modified":1769889880614},{"_id":"themes/butterfly/source/css/var.styl","hash":"41e5eb8c62fdf6ba12c98d026d6f26f08a4380e2","modified":1769889880617},{"_id":"themes/butterfly/source/js/main.js","hash":"4fb88103d8d76e53033d2fac13ea49549699f669","modified":1769889880618},{"_id":"themes/butterfly/source/css/index.styl","hash":"b13d96924a5534bff91d75566b196ac87b4fac22","modified":1769889880617},{"_id":"themes/butterfly/source/img/404.jpg","hash":"fb4489bc1d30c93d28f7332158c1c6c1416148de","modified":1769889880617},{"_id":"themes/butterfly/source/img/error-page.png","hash":"d2519710498a871ca3e913c57e2ba20a805b6430","modified":1769889880618},{"_id":"themes/butterfly/scripts/tag/score.js","hash":"f2f8a789967cda9559778b1936233dfb46a1f3a3","modified":1769889880613},{"_id":"themes/butterfly/source/js/utils.js","hash":"257260811cda85073bb5fd9f9ab25d29be9e4aff","modified":1769889880619},{"_id":"themes/butterfly/source/js/tw_cn.js","hash":"0561cc5c3d252d9b9b0d04a553028e9450965b6b","modified":1769889880619},{"_id":"themes/butterfly/source/img/friend_404.gif","hash":"8d2d0ebef70a8eb07329f57e645889b0e420fa48","modified":1769889880618},{"_id":"themes/butterfly/source/img/favicon.ico","hash":"455ac256580bf31a45813dbbdb87219bfc8bfb04","modified":1769889880618},{"_id":"themes/butterfly/README.md","hash":"d67b31fceac787d415a441f7eafc1832e8be7869","modified":1769889880604},{"_id":"themes/butterfly/layout/post.pug","hash":"65c4a49c65c3fc4d9dc88b9791a75710c698c3a1","modified":1769889880612},{"_id":"themes/butterfly/layout/tag.pug","hash":"ca5333bd262cb58c195c844b593a0eed0c721766","modified":1769889880612},{"_id":"themes/butterfly/layout/includes/head/Open_Graph.pug","hash":"e93a36d3c29b5a02c7f26a23f96e1f84b063cbe8","modified":1769889880605},{"_id":"themes/butterfly/layout/includes/head/analytics.pug","hash":"c2156c77a011b20fafd34f03ca073397c21b099f","modified":1769889880605},{"_id":"themes/butterfly/layout/includes/head/config_site.pug","hash":"56a3c32de1a15627ff38c67f1131cdd6ec5ac924","modified":1769889880605},{"_id":"themes/butterfly/layout/includes/head/preconnect.pug","hash":"1e1a69aa2cbda2e621c741b3802093244b3cc04e","modified":1769889880606},{"_id":"themes/butterfly/layout/includes/head/google_adsense.pug","hash":"f29123e603cbbcc6ce277d4e8f600ba67498077c","modified":1769889880605},{"_id":"themes/butterfly/layout/includes/head/site_verification.pug","hash":"5168caadc4cf541f5d6676a9c5e8ae47a948f9ad","modified":1769889880606},{"_id":"themes/butterfly/layout/includes/head/structured_data.pug","hash":"49db40e9d3edcf6323e6fe7c074ab09e41453c82","modified":1769889880606},{"_id":"themes/butterfly/layout/includes/header/index.pug","hash":"44331c9db74b281b5c5c41439d3407a9076df1a1","modified":1769889880606},{"_id":"themes/butterfly/layout/includes/header/nav.pug","hash":"f478a82ba4c15d4f6a5db38eca5c61f7054fa71d","modified":1769889880606},{"_id":"themes/butterfly/layout/includes/head/pwa.pug","hash":"83ed05ef1e39f2ee70c3fba2cf96e488d8ffec66","modified":1769889880606},{"_id":"themes/butterfly/layout/includes/header/menu_item.pug","hash":"733184f88e3a586a5fcc9d193ad500556b6c8eed","modified":1769889880606},{"_id":"themes/butterfly/layout/includes/header/social.pug","hash":"e2d31e0f450ad42c47f7ee96375799342bf2f19b","modified":1769889880606},{"_id":"themes/butterfly/layout/includes/head/config.pug","hash":"e20c41be7bdc07fdaef7952a2eb953eebd006ceb","modified":1769889880605},{"_id":"themes/butterfly/layout/includes/loading/fullpage-loading.pug","hash":"d4d266eced4b9167bed86bcc5addc327f78cbdcc","modified":1769889880606},{"_id":"themes/butterfly/layout/includes/mixins/article-sort.pug","hash":"ef7afe0df7a3746744ac8185da7163b7406120ca","modified":1769889880606},{"_id":"themes/butterfly/layout/includes/loading/pace.pug","hash":"9d2d539555bab495959b9df734ed5c43a9f9e5a9","modified":1769889880606},{"_id":"themes/butterfly/layout/includes/loading/index.pug","hash":"d76ce71ba106e350670c021a3dcae57547d01830","modified":1769889880606},{"_id":"themes/butterfly/layout/includes/post/reward.pug","hash":"db92f25ff3fd061882f81bf74ca560ff66983a0c","modified":1769889880607},{"_id":"themes/butterfly/layout/includes/post/outdate-notice.pug","hash":"b7ce9484bc5c97ea6154f0b78fb9b8951fafedbd","modified":1769889880607},{"_id":"themes/butterfly/layout/includes/post/post-copyright.pug","hash":"b96c232e5178d927987791d9ae386dd83679535a","modified":1769889880607},{"_id":"themes/butterfly/layout/includes/page/categories.pug","hash":"5276a8d2835e05bd535fedc9f593a0ce8c3e8437","modified":1769889880607},{"_id":"themes/butterfly/layout/includes/header/post-info.pug","hash":"7d799c4694adb6e265e3f4b975d7f7f6a7021a17","modified":1769889880606},{"_id":"themes/butterfly/layout/includes/page/tags.pug","hash":"af99f4f29bbccfa9d640766b6eb9ecf776374097","modified":1769889880607},{"_id":"themes/butterfly/layout/includes/page/404.pug","hash":"15d32c511e4875066fcbe9cb84c3ada07b5a7c41","modified":1769889880607},{"_id":"themes/butterfly/layout/includes/widget/card_ad.pug","hash":"a8312b527493dabbadbb1280760168d3bc909a3b","modified":1769889880611},{"_id":"themes/butterfly/layout/includes/page/default-page.pug","hash":"efb40388e37cca0b5e7c3c66e811a42f8d32c910","modified":1769889880607},{"_id":"themes/butterfly/layout/includes/page/flink.pug","hash":"6b0fa5f048aca8e9cbe56978301af918cf7ac34a","modified":1769889880607},{"_id":"themes/butterfly/layout/includes/widget/card_announcement.pug","hash":"21e019bdc3b1e796bb00976bb29af2d51f873624","modified":1769889880611},{"_id":"themes/butterfly/layout/includes/widget/card_archives.pug","hash":"73d33b6930e7944187a4b3403daf25d27077a2dd","modified":1769889880611},{"_id":"themes/butterfly/layout/includes/widget/card_bottom_self.pug","hash":"1dba77d250eeebfb6e293d504352c7e9ea31980b","modified":1769889880611},{"_id":"themes/butterfly/layout/includes/widget/card_author.pug","hash":"1aba8aa7cd767dc96879d13a13b4c8ceb9023233","modified":1769889880611},{"_id":"themes/butterfly/layout/includes/widget/card_categories.pug","hash":"66e383b4ef374951eb87dd1bf4cdb7a667193fb5","modified":1769889880611},{"_id":"themes/butterfly/layout/includes/widget/card_post_toc.pug","hash":"1dd19a564320d248dbcee7f118a5b96c6466da65","modified":1769889880611},{"_id":"themes/butterfly/layout/includes/widget/card_newest_comment.pug","hash":"d8753772889b5d0f4d15639ed6af5e91e53b1d03","modified":1769889880611},{"_id":"themes/butterfly/layout/includes/widget/card_tags.pug","hash":"5e9466ad66fc96959c3de75d97ee92134aab5945","modified":1769889880611},{"_id":"themes/butterfly/layout/includes/widget/card_recent_post.pug","hash":"bb842d2aa6469d65bf06af1372f0a19a9e4ef44c","modified":1769889880611},{"_id":"themes/butterfly/layout/includes/widget/card_webinfo.pug","hash":"fcddd80cdeb6aa81f342cd9f0102302f6ba087a8","modified":1769889880611},{"_id":"themes/butterfly/layout/includes/widget/index.pug","hash":"45f620cd87b9ef2aa9d1e024e697ed6b4eecff34","modified":1769889880611},{"_id":"themes/butterfly/layout/includes/third-party/effect.pug","hash":"43014bfc63583d3ee8808d526dd165848c0ed52f","modified":1769889880609},{"_id":"themes/butterfly/layout/includes/third-party/aplayer.pug","hash":"ed79fef5b5025415ea12eaed970f3fe7f6ef9596","modified":1769889880607},{"_id":"themes/butterfly/layout/includes/widget/card_top_self.pug","hash":"7b5ae404a1205546b7de4be42291315cf918f2b3","modified":1769889880611},{"_id":"themes/butterfly/layout/includes/third-party/prismjs.pug","hash":"e5eed62d90a4bc075d0b88bc756d20d5ff41f54f","modified":1769889880610},{"_id":"themes/butterfly/layout/includes/third-party/pjax.pug","hash":"7cf5ea1dc9a7ebbd945ab6d16e829be345a1392b","modified":1769889880610},{"_id":"themes/butterfly/layout/includes/widget/card_post_series.pug","hash":"e0bb72fa0ce15964b11b8fe421cae3432394e35f","modified":1769889880611},{"_id":"themes/butterfly/layout/includes/third-party/umami_analytics.pug","hash":"c6b9c2d04ae2d87a985cd1f9c1164749a543b714","modified":1769889880610},{"_id":"themes/butterfly/source/css/_mode/darkmode.styl","hash":"3f96290299c33e7b60c01b2c8b2a5a92be83e12b","modified":1769889880615},{"_id":"themes/butterfly/source/css/_mode/readmode.styl","hash":"0039d67b27ee98a3340e44539e89dee9e231062e","modified":1769889880615},{"_id":"themes/butterfly/source/css/_highlight/highlight.styl","hash":"54ef7d3927f96e2b5922d92e98f86e27562d0b63","modified":1769889880614},{"_id":"themes/butterfly/source/css/_global/index.styl","hash":"9426ab6c6fe84a76582dcb4e7762385c7c0a47f4","modified":1769889880614},{"_id":"themes/butterfly/source/css/_layout/aside.styl","hash":"1cb1c5fcdefc55aab674d7d84d057151f8f76577","modified":1769889880615},{"_id":"themes/butterfly/source/css/_highlight/theme.styl","hash":"a51edfd3e499e7d38c32241c40e8e4d371efca73","modified":1769889880614},{"_id":"themes/butterfly/layout/includes/third-party/subtitle.pug","hash":"236c3ce26dd76e80b04d457789475c42da5ac0c8","modified":1769889880610},{"_id":"themes/butterfly/source/css/_layout/footer.styl","hash":"5692bcf8929f7ef12b10d860da6cb90ca55752c0","modified":1769889880615},{"_id":"themes/butterfly/source/css/_layout/chat.styl","hash":"4cc02bcbaa4a1933a82a9ea57a603fe2d059fc77","modified":1769889880615},{"_id":"themes/butterfly/source/css/_global/function.styl","hash":"3aaee8878917abb3f438605ee74e2338216e8f88","modified":1769889880614},{"_id":"themes/butterfly/source/css/_layout/post.styl","hash":"543eaf9c7df7e0db841e5946ee5f9082c3c46290","modified":1769889880615},{"_id":"themes/butterfly/source/css/_layout/comments.styl","hash":"fbfce4d67cacd1df22fb73d89d008693f59d9d91","modified":1769889880615},{"_id":"themes/butterfly/source/css/_layout/head.styl","hash":"f30720e897322ce818f3def0a3f91eef23478923","modified":1769889880615},{"_id":"themes/butterfly/source/css/_layout/loading.styl","hash":"f0b01bbf321c2c24fdccaee367dd9fd448031a72","modified":1769889880615},{"_id":"themes/butterfly/source/css/_layout/pagination.styl","hash":"7d7554573c005399bc8c2264a85896d2d51be1e1","modified":1769889880615},{"_id":"themes/butterfly/source/css/_layout/relatedposts.styl","hash":"ef8e8549fe7ad4b99793844a93b4a89f77f417d5","modified":1769889880615},{"_id":"themes/butterfly/source/css/_layout/rightside.styl","hash":"d4e8a938ef2a1f4bf895d187e4fa529c7476e238","modified":1769889880615},{"_id":"themes/butterfly/source/css/_layout/third-party.styl","hash":"d148c8c9d9b2e4897cbb74338a1068cdb1c1b64b","modified":1769889880615},{"_id":"themes/butterfly/source/css/_page/categories.styl","hash":"c4cda7b0c99015df29ce00fdfddd2f7679653754","modified":1769889880616},{"_id":"themes/butterfly/source/css/_layout/sidebar.styl","hash":"e22bc88ab369c362905b29514d585b1d6bbfc5f3","modified":1769889880615},{"_id":"themes/butterfly/source/css/_layout/reward.styl","hash":"37944e0c390cd6f63055fdeeb68f337514d87349","modified":1769889880615},{"_id":"themes/butterfly/source/css/_page/common.styl","hash":"1a1766f8ea6a6576ec6129887e55221f540b9358","modified":1769889880616},{"_id":"themes/butterfly/source/css/_page/archives.styl","hash":"5abe5480d83ff8b452a780a484d50a44091475bf","modified":1769889880616},{"_id":"themes/butterfly/source/css/_page/404.styl","hash":"205ccc7d0ec6ce1193b46bc0c9ce0385594581fb","modified":1769889880616},{"_id":"themes/butterfly/source/css/_page/shuoshuo.styl","hash":"a764c44ce1f17f966b2f439762f038570af00b1b","modified":1769889880616},{"_id":"themes/butterfly/source/css/_page/flink.styl","hash":"1f8d715faf3b91b53426e38195c0920afb3bfa1c","modified":1769889880616},{"_id":"themes/butterfly/source/css/_search/index.styl","hash":"5a8a181324a2f6b7d8240ea871971444403fa554","modified":1769889880616},{"_id":"themes/butterfly/source/css/_page/homepage.styl","hash":"fc26e980fedde31644ebf878967f66ef9ba32be2","modified":1769889880616},{"_id":"themes/butterfly/source/css/_page/tags.styl","hash":"4681a9d93a20b8de9f58cdbc794702f76f35192b","modified":1769889880616},{"_id":"themes/butterfly/source/css/_tags/button.styl","hash":"f3fd3c43f16606a7b956fcb94b0d975b2d705fff","modified":1769889880616},{"_id":"themes/butterfly/layout/includes/page/shuoshuo.pug","hash":"2cc8f09b56ade6c581398d977fe38c1ecd9ed024","modified":1769889880607},{"_id":"themes/butterfly/source/css/_tags/inlineImg.styl","hash":"3be8d0a75e7cc96548667cae0cb6a474279bd0b5","modified":1769889880617},{"_id":"themes/butterfly/source/css/_tags/hexo.styl","hash":"985b183db7b7bfd8f9bdb60494549fb7f850348b","modified":1769889880616},{"_id":"themes/butterfly/source/css/_tags/gallery.styl","hash":"30d1f809efd252ed0233d96d4374efd2b01d2292","modified":1769889880616},{"_id":"themes/butterfly/source/css/_tags/label.styl","hash":"e84f1de06b818557cc4c45f9958121952ae268b8","modified":1769889880617},{"_id":"themes/butterfly/source/css/_tags/hide.styl","hash":"fe348f881d7f8b6022015e25fa0050bd6613c779","modified":1769889880617},{"_id":"themes/butterfly/source/css/_tags/note.styl","hash":"db2e94a2dd24a2777c9a74b35f98c11d71488003","modified":1769889880617},{"_id":"themes/butterfly/source/css/_third-party/normalize.min.css","hash":"8549829fb7d3c21cd9e119884962e8c463a4a267","modified":1769889880617},{"_id":"themes/butterfly/layout/includes/mixins/indexPostUI.pug","hash":"abc76a3a57ec063cb0ef3330452b76c2fbb59de3","modified":1769889880606},{"_id":"themes/butterfly/source/css/_tags/timeline.styl","hash":"e846ddaef494d46cdfa2379deacfe74fa1cc5264","modified":1769889880617},{"_id":"themes/butterfly/source/css/_tags/tabs.styl","hash":"3a88eedcb694da79e92581ce50cb1a430b1fb615","modified":1769889880617},{"_id":"themes/butterfly/source/css/_tags/series.styl","hash":"0657169849bc4bf4d93b5492ade040c8f58c1901","modified":1769889880617},{"_id":"themes/butterfly/source/js/search/local-search.js","hash":"4adfe4087d8350a1188135a32a3bf76c6b305787","modified":1769889880619},{"_id":"themes/butterfly/source/js/search/algolia.js","hash":"13f37791badfb942f639cc25092ee32d43de31bf","modified":1769889880619},{"_id":"themes/butterfly/source/css/_search/algolia.styl","hash":"f6d0cfb510a0e351ec20b043d3d3784d0f6c96a4","modified":1769889880616},{"_id":"themes/butterfly/source/css/_search/local-search.styl","hash":"d33d4af89231f4b0f1300bf2e9725344b4fab969","modified":1769889880616},{"_id":"themes/butterfly/layout/includes/third-party/abcjs/abcjs.pug","hash":"c4113038f4d084c7a0ed6d76e7257af717dea605","modified":1769889880607},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/artalk.pug","hash":"b03ee8625149191f9d5d057bbc9824b68d8dd0c4","modified":1769889880608},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/disqus.pug","hash":"d6fff5a7f84c8b09f282f9ddc0020a68a8aac9ea","modified":1769889880608},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/fb.pug","hash":"cbfbcf34a24d21ba2b21cf9eedb76f4c3c563c5a","modified":1769889880608},{"_id":"themes/butterfly/layout/includes/third-party/abcjs/index.pug","hash":"f0a90d8e39915a74b16ef22e851f179415cd7eaa","modified":1769889880607},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/index.pug","hash":"846cabae287ae31b3bbfac3da022475713dd5ecc","modified":1769889880608},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/twikoo.pug","hash":"be45b522286bbc64724341f23a5056ad24d3f796","modified":1769889880608},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/remark42.pug","hash":"716dc463fe4ef5112e7018ed60804125fdfa5cad","modified":1769889880608},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/waline.pug","hash":"fd2320ee25507bb8ef49f932c2d170586b44ea4d","modified":1769889880608},{"_id":"themes/butterfly/layout/includes/third-party/comments/artalk.pug","hash":"9801f581cd1d2aaa3eed8739487b9b3ec395c354","modified":1769889880608},{"_id":"themes/butterfly/layout/includes/third-party/comments/disqus.pug","hash":"f2ea5249b3e6670f6c8c77868f4f42c502e43830","modified":1769889880608},{"_id":"themes/butterfly/layout/includes/third-party/comments/disqusjs.pug","hash":"c81fa7d8a5cb96d1ae07bfa8c46b84a58161add1","modified":1769889880608},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/valine.pug","hash":"7884883ec15792f7e54daacb3c62b851dde2b66a","modified":1769889880608},{"_id":"themes/butterfly/layout/includes/third-party/comments/facebook_comments.pug","hash":"8af585e6d6f73ee57114eefad574dc6e8ea9f570","modified":1769889880608},{"_id":"themes/butterfly/layout/includes/third-party/comments/gitalk.pug","hash":"58914c58a190e3bc0aa37cb581e77e442b563501","modified":1769889880608},{"_id":"themes/butterfly/layout/includes/third-party/comments/giscus.pug","hash":"592b2251db6c1abeb8b0eebe3b2e6d9aa0dec445","modified":1769889880608},{"_id":"themes/butterfly/layout/includes/third-party/comments/index.pug","hash":"332b532bafbaf369fde840883b77e5a23d050a39","modified":1769889880609},{"_id":"themes/butterfly/layout/includes/third-party/comments/livere.pug","hash":"9d84a681289175dec75a85f301d2fc9ce1b2bb7a","modified":1769889880609},{"_id":"themes/butterfly/layout/includes/third-party/comments/js.pug","hash":"3abbaaa4ea575c45b3cebffd40bad1acc6ffce84","modified":1769889880609},{"_id":"themes/butterfly/layout/includes/third-party/comments/twikoo.pug","hash":"53d99831f29aeb2e336ed1407d79590041f77002","modified":1769889880609},{"_id":"themes/butterfly/layout/includes/third-party/comments/remark42.pug","hash":"ea9766439b6b1936306916a8b08d2681afbc8ea9","modified":1769889880609},{"_id":"themes/butterfly/layout/includes/third-party/comments/waline.pug","hash":"e2bf15357485cd502414b3b20f5b1f762a2fd014","modified":1769889880609},{"_id":"themes/butterfly/layout/includes/third-party/comments/utterances.pug","hash":"30a7d157890de69deab28baa47fb7bb28b040efd","modified":1769889880609},{"_id":"themes/butterfly/layout/includes/third-party/chat/chatra.pug","hash":"5b29badecbbe828112c001156023fc0566045cf6","modified":1769889880608},{"_id":"themes/butterfly/layout/includes/third-party/comments/valine.pug","hash":"24f18b0c67803210d53abbf9c1d454c000b06eee","modified":1769889880609},{"_id":"themes/butterfly/layout/includes/third-party/chat/crisp.pug","hash":"24d094fd917947c0ca7492fa094328b1a183b873","modified":1769889880608},{"_id":"themes/butterfly/layout/includes/third-party/math/chartjs.pug","hash":"732eb1118ea1a73aa5c164d639097c614f8e9953","modified":1769889880609},{"_id":"themes/butterfly/layout/includes/third-party/chat/index.pug","hash":"e8438941085def0591a72fc9b0d705dbf107f54f","modified":1769889880608},{"_id":"themes/butterfly/layout/includes/third-party/chat/tidio.pug","hash":"62466b251052cae609b6369d4cb4b6a85320757d","modified":1769889880608},{"_id":"themes/butterfly/layout/includes/third-party/math/mathjax.pug","hash":"cb5c8b0f2ac19a732ab78e26020dd5c8c70c0642","modified":1769889880609},{"_id":"themes/butterfly/layout/includes/third-party/math/index.pug","hash":"af66d13204030d47537b9e31a6173e63589ce7ff","modified":1769889880609},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/common.pug","hash":"27fa75affebc6e84a487c62bceff783bde595256","modified":1769889880609},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/artalk.pug","hash":"187302dbc916852ff2fdf47061e272c061611dda","modified":1769889880609},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/disqus-comment.pug","hash":"fa4b4194749d05f7249f365f2b89c0281057ce54","modified":1769889880609},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/github-issues.pug","hash":"72e2970b23570e308f8af5d8ba8e5e3321d01bbf","modified":1769889880610},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/index.pug","hash":"a7c07dbc1e970a5b247091458e1ee9b144a3366d","modified":1769889880610},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/remark42.pug","hash":"34edfebf0cace0852806be774910ccb0e0914650","modified":1769889880610},{"_id":"themes/butterfly/layout/includes/third-party/math/katex.pug","hash":"b83db9fa64d42a0bfd97efb660e09be3f166a144","modified":1769889880609},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/waline.pug","hash":"ec6c685080634ac46ffbea1b8f10313388888f43","modified":1769889880610},{"_id":"themes/butterfly/layout/includes/third-party/search/algolia.pug","hash":"c34c1b19b3cfe24ca11c5edfb34613507a9a00c7","modified":1769889880610},{"_id":"themes/butterfly/layout/includes/third-party/search/docsearch.pug","hash":"013756ff3363344987cc00fc9bd833baf193c341","modified":1769889880610},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/twikoo-comment.pug","hash":"d2e12a9fc302a4efe52c90d44896fbd73e193a1f","modified":1769889880610},{"_id":"themes/butterfly/layout/includes/third-party/search/index.pug","hash":"f8557548d2ad8dd149c562193991c6c6cda02415","modified":1769889880610},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/valine.pug","hash":"d376ec17fb19fcdcf0d2ad71330190146d3af879","modified":1769889880610},{"_id":"themes/butterfly/layout/includes/third-party/search/local-search.pug","hash":"70364f4a9d9f13d713533a0fe0a9798707f1c1b3","modified":1769889880610},{"_id":"themes/butterfly/layout/includes/third-party/share/index.pug","hash":"e51e896ccb13900de38dc81cf44dc789e2418a12","modified":1769889880610},{"_id":"themes/butterfly/source/css/_highlight/highlight/index.styl","hash":"ef52ebf1e8e751a412f9456fdaeee7d88afd9a72","modified":1769889880614},{"_id":"themes/butterfly/source/css/_highlight/highlight/diff.styl","hash":"a91dc5ddbf7b453daef7144bdbf89e6039234077","modified":1769889880614},{"_id":"themes/butterfly/layout/includes/third-party/share/share-js.pug","hash":"efef352c1d122409575386bf3894dce8e87032e2","modified":1769889880610},{"_id":"themes/butterfly/layout/includes/third-party/share/addtoany.pug","hash":"f5ee1c9c8ffa4bca972d30f4de69268b8d47f052","modified":1769889880610},{"_id":"source/images/Deepseek细粒度并行优化/1766039139599-0e8f3bbd-7d96-4c6a-8a8f-80cade8c0bd6.png","hash":"23848564a60be2a63717c241b534d3a934a17817","modified":1770035245665},{"_id":"themes/butterfly/source/css/_highlight/prismjs/index.styl","hash":"3676e5c2519cffcaf93a12ffef4c4878ffbc39d4","modified":1769889880614},{"_id":"themes/butterfly/source/css/_highlight/prismjs/diff.styl","hash":"077ec530831be1d80e93da380406b9f5abd0918a","modified":1769889880614},{"_id":"themes/butterfly/source/css/_highlight/prismjs/line-number.styl","hash":"de4bb5fc2dfca368b35e4c1109c92f7abc9e2245","modified":1769889880614},{"_id":"themes/butterfly/layout/includes/third-party/math/mermaid.pug","hash":"4859cfb07d3402d40d3597d324de6cf85613bca7","modified":1769889880609},{"_id":"source/images/Sharded-Context-Parallel/image-20260203005633972.png","hash":"aec2c6caeccc465a83b0200412e3dc05dca139db","modified":1770051393972},{"_id":"source/images/Sharded-Context-Parallel/image-20260203011606196.png","hash":"f3603bf844629ba4d67311fe1770fed69718cac3","modified":1770052566196},{"_id":"source/images/Deepseek细粒度并行优化/1765984854415-8c92bb5b-773d-40bf-ae91-0f3c183b4ad9.png","hash":"95093fe58f9de59749e1d1700e660be5cc4a28a9","modified":1770035147732},{"_id":"source/images/k8s-scheduler/image-20260202015909730.png","hash":"5a9b9a728d67b9a28dc950a4045a9f1cc041ad7a","modified":1769973766333},{"_id":"source/images/k8s-scheduler/image-20260202020113094.png","hash":"6717a17f48c2f02820157bc9a0de733e5b71ceca","modified":1769973766335},{"_id":"source/images/Sharded-Context-Parallel/543207039-e199ca08-7637-4efa-8934-2946e0423e39.png","hash":"4b1472d46e2c9b7eea8002232f083e3a9bfc6fc3","modified":1770049213565},{"_id":"source/images/k8s-scheduler/image-20260202020144193.png","hash":"a6b45510b8296371496564ff584d391022b927fe","modified":1769973766336},{"_id":"source/images/Deepseek细粒度并行优化/1766036708163-c76d1b1a-8375-44b2-af90-51ae6bc16d0a.png","hash":"abd540642061e9932a5d6a9a3362613d905d63f7","modified":1770035174733},{"_id":"themes/butterfly/source/img/butterfly-icon.png","hash":"f5dd732fed5c3bcd4aa76bac3441bac8485fb432","modified":1769889880618},{"_id":"themes/butterfly/source/img/github_avatar.JPG","hash":"710628754fce0d30f096272059a7e6509154b707","modified":1769890396167},{"_id":"source/images/Sharded-Context-Parallel/image-20260203005622667.png","hash":"fed9ed13d32096c5a83579cde975061636aadd6c","modified":1770051382667},{"_id":"source/images/Sharded-Context-Parallel/image-20260203005548367.png","hash":"fed9ed13d32096c5a83579cde975061636aadd6c","modified":1770051348367},{"_id":"themes/butterfly/source/img/zzh_favicon.png","hash":"110214cc0f71781244295adfa640ceb899e88d66","modified":1769890704160}],"Category":[{"name":"MLsys","_id":"cuidyUd-40QcwVtkj5Lk4sEGa"},{"name":"技术教程","_id":"cuidZ52iqtzd9eDvrpeUhMLXv"}],"Data":[],"Page":[{"_content":"google-site-verification: googlee3293c3acdaf4f9f.html","source":"googlee3293c3acdaf4f9f.html","raw":"google-site-verification: googlee3293c3acdaf4f9f.html","date":"2026-02-01T20:29:32.730Z","updated":"2026-02-01T20:29:32.729Z","path":"googlee3293c3acdaf4f9f.html","title":"","comments":1,"layout":"page","_id":"cuidWiWcdrVZ-R8TtAbgmCUKI","content":"google-site-verification: googlee3293c3acdaf4f9f.html","excerpt":"","more":"google-site-verification: googlee3293c3acdaf4f9f.html"},{"title":"about","date":"2026-01-31T20:10:29.000Z","type":"about","_content":"","source":"about/index.md","raw":"---\ntitle: about\ndate: 2026-02-01 04:10:29\ntype: about\n---\n","updated":"2026-02-01T19:22:46.330Z","path":"about/index.html","comments":1,"layout":"page","_id":"cuidRhiXCZEOueicPazuKu9sc","content":"","excerpt":"","more":""},{"title":"tags","date":"2026-01-31T20:10:23.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2026-02-01 04:10:23\ntype: tags\n---\n","updated":"2026-02-01T19:22:46.336Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cuidP1_8VamliVwiFqKXdW6Ea","content":"","excerpt":"","more":""},{"title":"categories","date":"2026-01-31T20:09:57.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2026-02-01 04:09:57\ntype: categories\n---\n","updated":"2026-02-01T19:22:46.331Z","path":"categories/index.html","comments":1,"layout":"page","_id":"cuidox64ZLAMWJcVu4V4eZqwy","content":"","excerpt":"","more":""}],"Post":[{"title":"Sharded Context Parallelism：极致挖掘 CP 潜力","date":"2025-12-03T19:11:56.000Z","updated":"2026-02-02T16:11:56.000Z","description":"提出 Sharded Context Parallelism 方案，通过单卡粒度 CP、Shard Linear 机制及通信掩盖技术，彻底消除冗余计算与通信开销。在 DeepSeek-v3.2 上实现 336% 的吞吐提升。","keywords":"Context Parallelism, Sharded CP, DeepSeek, vllm, Parallel Inference","_content":"\n# Sharded Context Parallelism: 极致挖掘 CP 潜力\n\n## 1. 背景与挑战\n\n### 1.1 Context Parallelism 的崛起\n上下文并行（Context Parallelism, CP）已成为扩展长上下文（Long Context）及稀疏注意力（Sparse Attention）模型推理的关键技术。相较于传统的张量并行（TP），CP 具备显著优势（参考 [MLSys 2025](https://mlsys.org/virtual/2025/3329)）：\n- **低延迟**：通过序列维度的并行计算显著降低首字延迟（TTFT）。\n- **低通信**：节点间通信量远低于 TP，适合跨节点扩展。\n- **分布式 KV Cache**：KV 缓存容量随设备数线性扩展，有效支撑超长序列。\n\n### 1.2 现有 CP+TP 架构的瓶颈\n然而，当前的 CP 主流实现（如 RFC #22693）通常采用 **CP+TP 混合架构**。在处理 DeepSeek-V3/V3.2 等稀疏模型时，这种架构暴露出了三大核心局限：\n\n#### (1) 显存瓶颈：权重冗余存储\n在 CP 组内，尽管序列被切分，但每个 Rank 仍需持有**完整的权重副本**（或 TP 分片）。\n- **后果**：总显存占用随 CP Rank 数线性增长，严重限制了 CP 在细粒度（如单卡单 Rank）场景下的扩展能力。\n\n#### (2) 计算瓶颈：稀疏逻辑冗余\n每个 CP Rank 内部仍需执行完整的 TP 逻辑。对于 DeepSeek DSA 等稀疏模型，**Indexer 模块**（负责动态选择活跃 Token）无法通过 TP 并行化。\n- **后果**：每个 Rank 必须在其本地序列上独立运行**完整的 Indexer 逻辑**。这导致对大量非活跃/无关 Token 的冗余计算，且冗余量随 CP 规模线性增加。\n\n#### (3) 存储瓶颈：KV Cache 去重不彻底\n虽然 PCP/DCP 实现了 CP 间的 KV Cache 去重，但在 Rank 内部的 TP 设备组之间，KV Cache 仍然是**完全复制**的。\n\n---\n\n## 2. 核心方案：Sharded Context Parallelism\n\n为了突破上述限制，我们提出了 **Sharded Context Parallelism（分片上下文并行）**。该方案支持**单 GPU 粒度**的 CP，通过极致的软硬协同设计，实现了显存、计算与通信的三重优化。\n\n### 2.1 核心创新\n1.  **Shard Linear 机制**：借鉴 FSDP 思想，按需加载权重，彻底消除权重的冗余显存占用。\n2.  **零冗余计算**：每张卡仅计算其负责的序列片段（SeqLen），Indexer 等模块不再重复计算。\n3.  **零通信开销**：通过深度流水线优化，完全掩盖 Attention 阶段的通信延迟。\n\n### 2.2 实验成果\n我们在昇腾 910C NPU 的 `vllm-ascend` 框架中实现了该方案。\n- **吞吐提升**：在 DeepSeek-v3.2 上获得 **336%** 的吞吐量提升。\n- **长文性能**：在 128K 上下文场景下，性能提升高达 **500%**。\n- **开源贡献**：[vllm-project/vllm-ascend#4702](https://github.com/vllm-project/vllm-ascend/pull/4702)\n\n---\n\n## 3. 技术实现详解：以 DeepSeek V3.2 为例\n\n### 3.1 整体架构与通信掩盖\nDeepSeek V3.2 的 Sharded CP 架构设计如下图所示：\n\n<img src=\"/images/Sharded-Context-Parallel/543207039-e199ca08-7637-4efa-8934-2946e0423e39.png\" alt=\"Architecture Overview\" style=\"zoom:50%;\" />\n\n#### 通信消除策略\n由于 Attention 权重通常是全量或 TP 冗余存储，我们采取了以下激进策略：\n1.  **消除 Output All-Reduce**：利用 CP 特性，每张卡仅输出部分 Token 的结果，直接取消了 `o_proj` 后的 All-Reduce。\n2.  **KV Cache 聚合与掩盖**：\n    - 计算 Attention 需要完整的 KV。我们将主模型的 KV Cache、RoPE 以及 Indexer 模块的 K Cache 进行横向拼接。\n    - 发起一次 **All-Gather** 操作，将其与计算密集型的 `q_up_proj` 并行执行，实现**通信完全被计算掩盖**。\n    - **显存优化**：KV Cache 按层通信，用完即存入 Block 或释放，无额外显存峰值。\n\n#### MoE 部分优化\n对 MoE 模块同样应用序列并行（SP）。Attention 结束后，每张卡持有部分 Token 的完整结果。在进入 MoE 之前的 Quant 及 Route Logits 计算后，对结果进行 All-Gather，该过程同样通过计算掩盖实现零开销。\n\n### 3.2 Shard Linear：权重的极致分片\n\n针对占用 MLA 大部分显存的 **Q_proj** 和 **O_proj**，我们引入了 **Shard Linear** 特性。\n\n#### 设计理念\n受 FSDP 启发，Shard Linear 改变了权重的生命周期管理：\n1.  **静态存储**：权重以 TP 分片形式静态存储于各卡显存。\n2.  **动态聚合**：计算前异步发起 All-Gather 获取完整权重。\n3.  **完整计算**：使用完整权重进行矩阵乘法。\n\n<img src=\"/images/Sharded-Context-Parallel/522353220-6b15a757-e1ac-4d92-a03b-b7b8bf063e27.png\" alt=\"Shard Linear Concept\" style=\"zoom: 33%;\" />\n\n#### 针对 NPU 优化的 Broadcast 机制\n由于昇腾 NPU 存在私有权重格式（NZ 格式）及量化属性（Quant Scale 等），直接使用 FSDP 的 All-Gather 会导致格式失效。我们设计了基于 **Broadcast** 的预取方案：\n\n1.  **层级分片（Layer Sharding）**：将各层权重按 `Layer ID % Device Count` 策略分配到不同设备。\n2.  **启动预热**：每张卡额外冗余缓存前 $K$ 层的完整权重，确保首 token 推理无延迟启动。\n3.  **异步预取（Asynchronous Prefetch）**：\n    - 在 SP 第一阶段 All-Gather 完成后（进入 Attention 前），定位 $L+K$ 层权重所在的源设备。\n    - 源设备发起 **Broadcast**，将完整权重分发至所有卡。\n    - 由于 Prefill 阶段 `q_up_proj` 和 `FlashAttention` 耗时较长，Broadcast 通信可被**完全掩盖**。\n4.  **及时释放**：前向计算完成后，立即释放该层权重。\n\n<img src=\"/images/Sharded-Context-Parallel/layer_sharding.png\" alt=\"layer_sharding\" style=\"zoom:50%;\" />\n\n> 此特性已合入 vllm-ascend 主分支：[PR #2931](https://github.com/vllm-project/vllm-ascend/pull/2931)\n\n---\n\n## 4. 性能提升分析⭐️\n\n在昇腾平台能拿到如此大的性能提升，我们自己本身也是非常惊讶，也非常兴奋，因为本来我们做prefill的优化能有10%左右的性能提升都算不错的一个关键特性了。对此我针对了性能提升做了非常详细的分析。\n\n**性能提升benchmark图** && **gsm8k精度图**：\n\n<img src=\"/images/Sharded-Context-Parallel/image-20260203005548367.png\" alt=\"image-20260203005548367\" style=\"zoom:33%;\" />\n\n<img src=\"/images/Sharded-Context-Parallel/image-20260203005633972.png\" alt=\"image-20260203005633972\" style=\"zoom:33%;\" />\n\n### 算子性能分析：\n\n首先看性能差异比较大的算子：\n\n#### 1. SparseFlashAttention\n\n**profile：**\n\n![image-20260203005907133](/images/Sharded-Context-Parallel/image-20260203005907133.png)\n\n**kernel_details**：\n\n| 方案         | Device_id | Model ID   | Task ID | Stream ID | Name                 | Type                 | OP State | Accelerator Core | Start Time(us)       | Duration(us) | Wait Time(us) | Block Dim | Mix Block Dim | **HF32 Eligible** | **Input Shapes**                                             | **Input Data Types**                                         | **Input Formats**          | **Output Shapes** | **Output Data Types** | **Output Formats** | **Context ID** | **aicore_time(us)** | **aic_total_cycles** | **aic_mac_time(us)** | **aic_mac_ratio** | **aic_scalar_time(us)** | **aic_scalar_ratio** | **aic_mte1_time(us)** | **aic_mte1_ratio** | **aic_mte2_time(us)** | **aic_mte2_ratio** | **aic_fixpipe_time(us)** | **aic_fixpipe_ratio** | **aic_icache_miss_rate** | **aiv_time(us)** | **aiv_total_cycles** | **aiv_vec_time(us)** | **aiv_vec_ratio** | **aiv_scalar_time(us)** | **aiv_scalar_ratio** | **aiv_mte2_time(us)** | **aiv_mte2_ratio** | **aiv_mte3_time(us)** | **aiv_mte3_ratio** | **aiv_icache_miss_rate** | **cube_utilization(%)** |\n| ------------ | --------- | ---------- | ------- | --------- | -------------------- | -------------------- | -------- | ---------------- | -------------------- | ------------ | ------------- | --------- | ------------- | ----------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | -------------------------- | ----------------- | --------------------- | ------------------ | -------------- | ------------------- | -------------------- | -------------------- | ----------------- | ----------------------- | -------------------- | --------------------- | ------------------ | --------------------- | ------------------ | ------------------------ | --------------------- | ------------------------ | ---------------- | -------------------- | -------------------- | ----------------- | ----------------------- | -------------------- | --------------------- | ------------------ | --------------------- | ------------------ | ------------------------ | ----------------------- |\n| **cp**       | 0         | 4294967295 | 58111   | 2         | SparseFlashAttention | SparseFlashAttention | dynamic  | MIX_AIC          | 1764761459549479.309 | 3524.631     | 1.055         | 24        | 48            | NO                | \"1024,128,512;485,128,1,512;485,128,1,512;1024,1,2048;5,128;5;5;1024,128,64;485,128,1,64\" | DT_BF16;DT_BF16;DT_BF16;INT32;INT32;INT32;INT32;DT_BF16;DT_BF16 | ND;ND;ND;ND;ND;ND;ND;ND;ND | \"1024,128,512\"    | DT_BF16               | ND                 | 0              | 2767.033            | 122856248            | 1270.05              | 0.459             | 1090.331                | 0.394                | 1124.983              | 0.407              | 1901.353              | 0.687              | 1908.977                 | 0.69                  | 0                        | 2769.781         | 245956577            | 802.586              | 0.29              | 2338.385                | 0.844                | 1725.753              | 0.623              | 714.356               | 0.258              | 0                        | 75.365                  |\n| **baseline** | 0         | 4294967295 | 32713   | 2         | SparseFlashAttention | SparseFlashAttention | dynamic  | MIX_AIC          | 1764762104173838.715 | 39846.596    | 1.135         | 24        | 48            | NO                | \"16384,8,512;699,128,1,512;699,128,1,512;16384,1,2048;4,128;4;4;16384,8,64;699,128,1,64\" | DT_BF16;DT_BF16;DT_BF16;INT32;INT32;INT32;INT32;DT_BF16;DT_BF16 | ND;ND;ND;ND;ND;ND;ND;ND;ND | \"16384,8,512\"     | DT_BF16               | ND                 | 0              | 30812.793           | 1368088000           | 5191.721             | 0.168             | 12573.224               | 0.408                | 13614.999             | 0.442              | 24602.17              | 0.798              | 23509.344                | 0.763                 | 0                        | 30813.542        | 2736242537           | 1104.192             | 0.036             | 28802.779               | 0.935                | 24316.9               | 0.789              | 5973.504              | 0.194              | 0                        | 74.235                  |\n\n**我们来看一下其中的一些关键指标**\n\n| 维度 | CP | Baseline | 差异分析 |\n| :--- | :--- | :--- | ---- |\n| **执行耗时 (Duration)** | 3.52 ms | 39.85 ms | cp 快 11.3 倍 |\n| **input_shape** | `[1024, 128, 512]...` | `[16384, 8, 512]...` | CP 方案切分 seq，但是保留完整的 head，随维度不同但是数据量相同 |\n| **output_shape** | `[1024, 128, 512]` | `[16384, 8, 512]` | 同上（这里我们可以推断 sfa 的的计算量是完全是相同的） |\n| **cube_utilization(%)** | 75.365% | 74.235% | 利用率相近，说明计算效率相当 |\n| **aic_mte1_time**<br />**aic_mte2_time**<br />**aiv_mte2_time**<br />**aiv_mte3_time** | 1124.98 μs<br />1901.35 μs<br />1725.75 μs<br />714.36 μs | 13614.99 μs<br />24602.17 μs<br />24316.9 μs<br />5973.5 μs | 基本都是 12 倍左右，mte就是 CP 方案快的关键 |\n\nMTE 是 CP 方案中性能提升的 **关键**\n\n**在 华为昇腾AI 处理器（如 Ascend 910）中，MTE 是专门负责数据搬运的硬件单元，与计算单元（如 AI Core 中的 Cube、Vector 单元）解耦并行工作。**\n\n由于 CP 方案显著减少了 KV Cache 的读取量，大幅降低了内存传输引擎（MTE）的负担，从而缩短了数据搬运时间。这一优化有效缓解了访存瓶颈，使得 SFA算子中的矩阵乘计算能够更高效地流水执行，最终带来整体性能的显著加速。\n\n**为什么 CP 能减少 kv cache 访存 ?**\n\n在SFA计算中，baseline 方案采用 TP：每张卡持有完整的 seqlen 的 Q，但只分配部分注意力头，因此需要与对应分片的 KV 进行矩阵乘。\n而 CP 方案则不同：每张卡持有部分 seqlen 的 Q，但拥有全部的注意力头，并与完整的 KV Cache 进行计算。\n\nDeepSeek-V3.2 引入了 Indexer 模块，使得每个 token 仅需访问固定长度2048的 KV，而非整个 kv。在此背景下，CP 方案的优势更加凸显：由于每张卡只处理局部序列，它只需加载与该局部 Q 对应的、经 Indexer 筛选后的少量 KV，显著减少了 KV 的读取量。相比之下，baseline 方案中每张卡持有完整的 seqlen，因此需要读取大量的 kvcache，导致在 SFA 执行过程中频繁触发大规模的 MTE操作，造成严重的访存开销和流水线停顿。\n因为我们 global 的并行配置 baseline 为 TP16，而 CP 方案为 CP16，理论上 baseline KV 读取量可能是 CP 方案的 16 倍，但是由于每个 token 的 top-k(2048)会有重复，所有 kvcache 读取量 并没有 16 倍的差距。\n\n### 2. LightningIndexer 的计算\n\n**profile：**\n\n![image-20260203011606196](/images/Sharded-Context-Parallel/image-20260203011606196.png)\n\n**kernel_details**：\n\n| 方案     | Device_id | Model ID   | Task ID | Stream ID | Name             | Type             | OP State | Accelerator Core | Start Time(us)       | Duration(us) | Wait Time(us) | Block Dim | Mix Block Dim | HF32 Eligible | Input Shapes                                    | Input Data Types                          | Input Formats     | Output Shapes  | Output Data Types | Output Formats | Context ID | aicore_time(us) | aic_total_cycles | aic_mac_time(us) | aic_mac_ratio | aic_scalar_time(us) | aic_scalar_ratio | aic_mte1_time(us) | aic_mte1_ratio | aic_mte2_time(us) | aic_mte2_ratio | aic_fixpipe_time(us) | aic_fixpipe_ratio | aic_icache_miss_rate | aiv_time(us) | aiv_total_cycles | aiv_vec_time(us) | aiv_vec_ratio | aiv_scalar_time(us) | aiv_scalar_ratio | aiv_mte2_time(us) | aiv_mte2_ratio | aiv_mte3_time(us) | aiv_mte3_ratio | aiv_icache_miss_rate | cube_utilization(%) |\n| -------- | --------- | ---------- | ------- | --------- | ---------------- | ---------------- | -------- | ---------------- | -------------------- | ------------ | ------------- | --------- | ------------- | ------------- | ----------------------------------------------- | ----------------------------------------- | ----------------- | -------------- | ----------------- | -------------- | ---------- | --------------- | ---------------- | ---------------- | ------------- | ------------------- | ---------------- | ----------------- | -------------- | ----------------- | -------------- | -------------------- | ----------------- | -------------------- | ------------ | ---------------- | ---------------- | ------------- | ------------------- | ---------------- | ----------------- | -------------- | ----------------- | -------------- | -------------------- | ------------------- |\n| cp       | 0         | 4294967295 | 58109   | 2         | LightningIndexer | LightningIndexer | dynamic  | MIX_AIC          | 1764761459548934.118 | 282.446      | 0.789         | 24        | 48            | NO            | \"1024,64,128;485,128,1,128;1024,64;5;5;5,128\"   | DT_BF16;DT_BF16;DT_BF16;INT32;INT32;INT32 | ND;ND;ND;ND;ND;ND | \"1024,1,2048\"  | INT32             | ND             | 0          | 261.516         | 11611319         | 84.575           | 0.323         | 99.695              | 0.381            | 70.886            | 0.271          | 29.714            | 0.114          | 139.095              | 0.532             | 0.005                | 278.619      | 24741398         | 213.992          | 0.768         | 74.65               | 0.268            | 96.997            | 0.348          | 6.258             | 0.022          | 0.005                | 88.886              |\n| baseline | 0         | 4294967295 | 32711   | 2         | LightningIndexer | LightningIndexer | dynamic  | MIX_AIC          | 1764762104168502.129 | 5092.241     | 2.098         | 24        | 48            | NO            | \"16384,64,128;699,128,1,128;16384,64;4;4;4,128\" | DT_BF16;DT_BF16;DT_BF16;INT32;INT32;INT32 | ND;ND;ND;ND;ND;ND | \"16384,1,2048\" | INT32             | ND             | 0          | 4554.882        | 202236777        | 1736.127         | 0.381         | 1781.882            | 0.391            | 1451.462          | 0.319          | 549.574           | 0.121          | 2590.513             | 0.569             | 0                    | 5085.976     | 451634633        | 4250.194         | 0.836         | 1419.064            | 0.279            | 1844.032          | 0.363          | 65.617            | 0.013          | 0                    | 85.87               |\n\n**关键指标: **\n\n| 维度                | CP               | baseline           | 差异分析                                                     |\n| ------------------- | ---------------- | ------------------ | ------------------------------------------------------------ |\n| 执行耗时 (Duration) | 282.4us          | 5092.2us           | cp 比 baseline 快 18 倍                                      |\n| input_shape         | [1024,64,128]... | [16384,64,128].... | **关键：****维度差异 16 倍**                                 |\n| output_shape        | [1024, 1, 2048]  | [16384, 1, 2048]   | 同上（这里我们可以推断 indexer 在 CP 方案的计算量上远小于 baseline） |\n| aic_mte             | ....             | ....               | cp 远小于 baseline（20x）                                    |\n| aiv_mte             | ....             | ....               | cp 远小于 baseline(18x)                                      |\n\n**lightning Indexer 模块的核心收益来自于消除了** 冗余计算\n\n**为什么 baseline 中 Indexer 模块的三个矩阵无法在 TP 维度却分？**\n\n因为朴素的 TP（Megatron 提出）需要两次矩阵乘来配合，也就是一次行切一次列切，但是 lightning indexer 模块中只有一次矩阵乘就需要，完全的激活去做 top-k，所以在不引入额外通信的前提下就是无法对LightningIndexer 模块的矩阵去做 TP 切分的。\n\n### 3.其他优化\n\n- 消除全流程的冗余计算\n\n- 通信上优化\n  ....\n\n  \n\n\n\n## 5. 总结与展望\n\nSharded Context Parallelism 是一次将 CP 理念推向极致的尝试：\n1.  ✅ **打破粒度限制**：实现单卡级 CP，最大化硬件利用率。\n2.  ✅ **打破显存限制**：Shard Linear 消除权重冗余。\n3.  ✅ **打破计算限制**：彻底消除稀疏模型的 Indexer 冗余。\n4.  ✅ **打破通信限制**：通过全流程掩盖，实现 Attention 阶段“零”通信。\n\n**实测效果**：DeepSeek-v3.2 吞吐量提升 **336%**，验证了该架构在处理复杂稀疏大模型时的卓越效能。\n\n**未来计划**：\n- 进一步集成 **PCP (Partial Context Parallel)**，实现单卡级别的 KV Cache 物理去重。\n- 将 Sharded CP 推广至更多 Transformer 架构模型，坐等Deepseek-V4😊。\n","source":"_posts/Sharded-Context-Parallel.md","raw":"---\ntitle: Sharded Context Parallelism：极致挖掘 CP 潜力\ntags:\n  - DeepSeek\n  - Context Parallelism\n  - Ascend\n  - Optimization\ndate: 2025-12-04 03:11:56\nupdated: 2026-02-03 00:11:56\ncategory: MLsys\ndescription: 提出 Sharded Context Parallelism 方案，通过单卡粒度 CP、Shard Linear 机制及通信掩盖技术，彻底消除冗余计算与通信开销。在 DeepSeek-v3.2 上实现 336% 的吞吐提升。\nkeywords: Context Parallelism, Sharded CP, DeepSeek, vllm, Parallel Inference\n---\n\n# Sharded Context Parallelism: 极致挖掘 CP 潜力\n\n## 1. 背景与挑战\n\n### 1.1 Context Parallelism 的崛起\n上下文并行（Context Parallelism, CP）已成为扩展长上下文（Long Context）及稀疏注意力（Sparse Attention）模型推理的关键技术。相较于传统的张量并行（TP），CP 具备显著优势（参考 [MLSys 2025](https://mlsys.org/virtual/2025/3329)）：\n- **低延迟**：通过序列维度的并行计算显著降低首字延迟（TTFT）。\n- **低通信**：节点间通信量远低于 TP，适合跨节点扩展。\n- **分布式 KV Cache**：KV 缓存容量随设备数线性扩展，有效支撑超长序列。\n\n### 1.2 现有 CP+TP 架构的瓶颈\n然而，当前的 CP 主流实现（如 RFC #22693）通常采用 **CP+TP 混合架构**。在处理 DeepSeek-V3/V3.2 等稀疏模型时，这种架构暴露出了三大核心局限：\n\n#### (1) 显存瓶颈：权重冗余存储\n在 CP 组内，尽管序列被切分，但每个 Rank 仍需持有**完整的权重副本**（或 TP 分片）。\n- **后果**：总显存占用随 CP Rank 数线性增长，严重限制了 CP 在细粒度（如单卡单 Rank）场景下的扩展能力。\n\n#### (2) 计算瓶颈：稀疏逻辑冗余\n每个 CP Rank 内部仍需执行完整的 TP 逻辑。对于 DeepSeek DSA 等稀疏模型，**Indexer 模块**（负责动态选择活跃 Token）无法通过 TP 并行化。\n- **后果**：每个 Rank 必须在其本地序列上独立运行**完整的 Indexer 逻辑**。这导致对大量非活跃/无关 Token 的冗余计算，且冗余量随 CP 规模线性增加。\n\n#### (3) 存储瓶颈：KV Cache 去重不彻底\n虽然 PCP/DCP 实现了 CP 间的 KV Cache 去重，但在 Rank 内部的 TP 设备组之间，KV Cache 仍然是**完全复制**的。\n\n---\n\n## 2. 核心方案：Sharded Context Parallelism\n\n为了突破上述限制，我们提出了 **Sharded Context Parallelism（分片上下文并行）**。该方案支持**单 GPU 粒度**的 CP，通过极致的软硬协同设计，实现了显存、计算与通信的三重优化。\n\n### 2.1 核心创新\n1.  **Shard Linear 机制**：借鉴 FSDP 思想，按需加载权重，彻底消除权重的冗余显存占用。\n2.  **零冗余计算**：每张卡仅计算其负责的序列片段（SeqLen），Indexer 等模块不再重复计算。\n3.  **零通信开销**：通过深度流水线优化，完全掩盖 Attention 阶段的通信延迟。\n\n### 2.2 实验成果\n我们在昇腾 910C NPU 的 `vllm-ascend` 框架中实现了该方案。\n- **吞吐提升**：在 DeepSeek-v3.2 上获得 **336%** 的吞吐量提升。\n- **长文性能**：在 128K 上下文场景下，性能提升高达 **500%**。\n- **开源贡献**：[vllm-project/vllm-ascend#4702](https://github.com/vllm-project/vllm-ascend/pull/4702)\n\n---\n\n## 3. 技术实现详解：以 DeepSeek V3.2 为例\n\n### 3.1 整体架构与通信掩盖\nDeepSeek V3.2 的 Sharded CP 架构设计如下图所示：\n\n<img src=\"/images/Sharded-Context-Parallel/543207039-e199ca08-7637-4efa-8934-2946e0423e39.png\" alt=\"Architecture Overview\" style=\"zoom:50%;\" />\n\n#### 通信消除策略\n由于 Attention 权重通常是全量或 TP 冗余存储，我们采取了以下激进策略：\n1.  **消除 Output All-Reduce**：利用 CP 特性，每张卡仅输出部分 Token 的结果，直接取消了 `o_proj` 后的 All-Reduce。\n2.  **KV Cache 聚合与掩盖**：\n    - 计算 Attention 需要完整的 KV。我们将主模型的 KV Cache、RoPE 以及 Indexer 模块的 K Cache 进行横向拼接。\n    - 发起一次 **All-Gather** 操作，将其与计算密集型的 `q_up_proj` 并行执行，实现**通信完全被计算掩盖**。\n    - **显存优化**：KV Cache 按层通信，用完即存入 Block 或释放，无额外显存峰值。\n\n#### MoE 部分优化\n对 MoE 模块同样应用序列并行（SP）。Attention 结束后，每张卡持有部分 Token 的完整结果。在进入 MoE 之前的 Quant 及 Route Logits 计算后，对结果进行 All-Gather，该过程同样通过计算掩盖实现零开销。\n\n### 3.2 Shard Linear：权重的极致分片\n\n针对占用 MLA 大部分显存的 **Q_proj** 和 **O_proj**，我们引入了 **Shard Linear** 特性。\n\n#### 设计理念\n受 FSDP 启发，Shard Linear 改变了权重的生命周期管理：\n1.  **静态存储**：权重以 TP 分片形式静态存储于各卡显存。\n2.  **动态聚合**：计算前异步发起 All-Gather 获取完整权重。\n3.  **完整计算**：使用完整权重进行矩阵乘法。\n\n<img src=\"/images/Sharded-Context-Parallel/522353220-6b15a757-e1ac-4d92-a03b-b7b8bf063e27.png\" alt=\"Shard Linear Concept\" style=\"zoom: 33%;\" />\n\n#### 针对 NPU 优化的 Broadcast 机制\n由于昇腾 NPU 存在私有权重格式（NZ 格式）及量化属性（Quant Scale 等），直接使用 FSDP 的 All-Gather 会导致格式失效。我们设计了基于 **Broadcast** 的预取方案：\n\n1.  **层级分片（Layer Sharding）**：将各层权重按 `Layer ID % Device Count` 策略分配到不同设备。\n2.  **启动预热**：每张卡额外冗余缓存前 $K$ 层的完整权重，确保首 token 推理无延迟启动。\n3.  **异步预取（Asynchronous Prefetch）**：\n    - 在 SP 第一阶段 All-Gather 完成后（进入 Attention 前），定位 $L+K$ 层权重所在的源设备。\n    - 源设备发起 **Broadcast**，将完整权重分发至所有卡。\n    - 由于 Prefill 阶段 `q_up_proj` 和 `FlashAttention` 耗时较长，Broadcast 通信可被**完全掩盖**。\n4.  **及时释放**：前向计算完成后，立即释放该层权重。\n\n<img src=\"/images/Sharded-Context-Parallel/layer_sharding.png\" alt=\"layer_sharding\" style=\"zoom:50%;\" />\n\n> 此特性已合入 vllm-ascend 主分支：[PR #2931](https://github.com/vllm-project/vllm-ascend/pull/2931)\n\n---\n\n## 4. 性能提升分析⭐️\n\n在昇腾平台能拿到如此大的性能提升，我们自己本身也是非常惊讶，也非常兴奋，因为本来我们做prefill的优化能有10%左右的性能提升都算不错的一个关键特性了。对此我针对了性能提升做了非常详细的分析。\n\n**性能提升benchmark图** && **gsm8k精度图**：\n\n<img src=\"/images/Sharded-Context-Parallel/image-20260203005548367.png\" alt=\"image-20260203005548367\" style=\"zoom:33%;\" />\n\n<img src=\"/images/Sharded-Context-Parallel/image-20260203005633972.png\" alt=\"image-20260203005633972\" style=\"zoom:33%;\" />\n\n### 算子性能分析：\n\n首先看性能差异比较大的算子：\n\n#### 1. SparseFlashAttention\n\n**profile：**\n\n![image-20260203005907133](/images/Sharded-Context-Parallel/image-20260203005907133.png)\n\n**kernel_details**：\n\n| 方案         | Device_id | Model ID   | Task ID | Stream ID | Name                 | Type                 | OP State | Accelerator Core | Start Time(us)       | Duration(us) | Wait Time(us) | Block Dim | Mix Block Dim | **HF32 Eligible** | **Input Shapes**                                             | **Input Data Types**                                         | **Input Formats**          | **Output Shapes** | **Output Data Types** | **Output Formats** | **Context ID** | **aicore_time(us)** | **aic_total_cycles** | **aic_mac_time(us)** | **aic_mac_ratio** | **aic_scalar_time(us)** | **aic_scalar_ratio** | **aic_mte1_time(us)** | **aic_mte1_ratio** | **aic_mte2_time(us)** | **aic_mte2_ratio** | **aic_fixpipe_time(us)** | **aic_fixpipe_ratio** | **aic_icache_miss_rate** | **aiv_time(us)** | **aiv_total_cycles** | **aiv_vec_time(us)** | **aiv_vec_ratio** | **aiv_scalar_time(us)** | **aiv_scalar_ratio** | **aiv_mte2_time(us)** | **aiv_mte2_ratio** | **aiv_mte3_time(us)** | **aiv_mte3_ratio** | **aiv_icache_miss_rate** | **cube_utilization(%)** |\n| ------------ | --------- | ---------- | ------- | --------- | -------------------- | -------------------- | -------- | ---------------- | -------------------- | ------------ | ------------- | --------- | ------------- | ----------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | -------------------------- | ----------------- | --------------------- | ------------------ | -------------- | ------------------- | -------------------- | -------------------- | ----------------- | ----------------------- | -------------------- | --------------------- | ------------------ | --------------------- | ------------------ | ------------------------ | --------------------- | ------------------------ | ---------------- | -------------------- | -------------------- | ----------------- | ----------------------- | -------------------- | --------------------- | ------------------ | --------------------- | ------------------ | ------------------------ | ----------------------- |\n| **cp**       | 0         | 4294967295 | 58111   | 2         | SparseFlashAttention | SparseFlashAttention | dynamic  | MIX_AIC          | 1764761459549479.309 | 3524.631     | 1.055         | 24        | 48            | NO                | \"1024,128,512;485,128,1,512;485,128,1,512;1024,1,2048;5,128;5;5;1024,128,64;485,128,1,64\" | DT_BF16;DT_BF16;DT_BF16;INT32;INT32;INT32;INT32;DT_BF16;DT_BF16 | ND;ND;ND;ND;ND;ND;ND;ND;ND | \"1024,128,512\"    | DT_BF16               | ND                 | 0              | 2767.033            | 122856248            | 1270.05              | 0.459             | 1090.331                | 0.394                | 1124.983              | 0.407              | 1901.353              | 0.687              | 1908.977                 | 0.69                  | 0                        | 2769.781         | 245956577            | 802.586              | 0.29              | 2338.385                | 0.844                | 1725.753              | 0.623              | 714.356               | 0.258              | 0                        | 75.365                  |\n| **baseline** | 0         | 4294967295 | 32713   | 2         | SparseFlashAttention | SparseFlashAttention | dynamic  | MIX_AIC          | 1764762104173838.715 | 39846.596    | 1.135         | 24        | 48            | NO                | \"16384,8,512;699,128,1,512;699,128,1,512;16384,1,2048;4,128;4;4;16384,8,64;699,128,1,64\" | DT_BF16;DT_BF16;DT_BF16;INT32;INT32;INT32;INT32;DT_BF16;DT_BF16 | ND;ND;ND;ND;ND;ND;ND;ND;ND | \"16384,8,512\"     | DT_BF16               | ND                 | 0              | 30812.793           | 1368088000           | 5191.721             | 0.168             | 12573.224               | 0.408                | 13614.999             | 0.442              | 24602.17              | 0.798              | 23509.344                | 0.763                 | 0                        | 30813.542        | 2736242537           | 1104.192             | 0.036             | 28802.779               | 0.935                | 24316.9               | 0.789              | 5973.504              | 0.194              | 0                        | 74.235                  |\n\n**我们来看一下其中的一些关键指标**\n\n| 维度 | CP | Baseline | 差异分析 |\n| :--- | :--- | :--- | ---- |\n| **执行耗时 (Duration)** | 3.52 ms | 39.85 ms | cp 快 11.3 倍 |\n| **input_shape** | `[1024, 128, 512]...` | `[16384, 8, 512]...` | CP 方案切分 seq，但是保留完整的 head，随维度不同但是数据量相同 |\n| **output_shape** | `[1024, 128, 512]` | `[16384, 8, 512]` | 同上（这里我们可以推断 sfa 的的计算量是完全是相同的） |\n| **cube_utilization(%)** | 75.365% | 74.235% | 利用率相近，说明计算效率相当 |\n| **aic_mte1_time**<br />**aic_mte2_time**<br />**aiv_mte2_time**<br />**aiv_mte3_time** | 1124.98 μs<br />1901.35 μs<br />1725.75 μs<br />714.36 μs | 13614.99 μs<br />24602.17 μs<br />24316.9 μs<br />5973.5 μs | 基本都是 12 倍左右，mte就是 CP 方案快的关键 |\n\nMTE 是 CP 方案中性能提升的 **关键**\n\n**在 华为昇腾AI 处理器（如 Ascend 910）中，MTE 是专门负责数据搬运的硬件单元，与计算单元（如 AI Core 中的 Cube、Vector 单元）解耦并行工作。**\n\n由于 CP 方案显著减少了 KV Cache 的读取量，大幅降低了内存传输引擎（MTE）的负担，从而缩短了数据搬运时间。这一优化有效缓解了访存瓶颈，使得 SFA算子中的矩阵乘计算能够更高效地流水执行，最终带来整体性能的显著加速。\n\n**为什么 CP 能减少 kv cache 访存 ?**\n\n在SFA计算中，baseline 方案采用 TP：每张卡持有完整的 seqlen 的 Q，但只分配部分注意力头，因此需要与对应分片的 KV 进行矩阵乘。\n而 CP 方案则不同：每张卡持有部分 seqlen 的 Q，但拥有全部的注意力头，并与完整的 KV Cache 进行计算。\n\nDeepSeek-V3.2 引入了 Indexer 模块，使得每个 token 仅需访问固定长度2048的 KV，而非整个 kv。在此背景下，CP 方案的优势更加凸显：由于每张卡只处理局部序列，它只需加载与该局部 Q 对应的、经 Indexer 筛选后的少量 KV，显著减少了 KV 的读取量。相比之下，baseline 方案中每张卡持有完整的 seqlen，因此需要读取大量的 kvcache，导致在 SFA 执行过程中频繁触发大规模的 MTE操作，造成严重的访存开销和流水线停顿。\n因为我们 global 的并行配置 baseline 为 TP16，而 CP 方案为 CP16，理论上 baseline KV 读取量可能是 CP 方案的 16 倍，但是由于每个 token 的 top-k(2048)会有重复，所有 kvcache 读取量 并没有 16 倍的差距。\n\n### 2. LightningIndexer 的计算\n\n**profile：**\n\n![image-20260203011606196](/images/Sharded-Context-Parallel/image-20260203011606196.png)\n\n**kernel_details**：\n\n| 方案     | Device_id | Model ID   | Task ID | Stream ID | Name             | Type             | OP State | Accelerator Core | Start Time(us)       | Duration(us) | Wait Time(us) | Block Dim | Mix Block Dim | HF32 Eligible | Input Shapes                                    | Input Data Types                          | Input Formats     | Output Shapes  | Output Data Types | Output Formats | Context ID | aicore_time(us) | aic_total_cycles | aic_mac_time(us) | aic_mac_ratio | aic_scalar_time(us) | aic_scalar_ratio | aic_mte1_time(us) | aic_mte1_ratio | aic_mte2_time(us) | aic_mte2_ratio | aic_fixpipe_time(us) | aic_fixpipe_ratio | aic_icache_miss_rate | aiv_time(us) | aiv_total_cycles | aiv_vec_time(us) | aiv_vec_ratio | aiv_scalar_time(us) | aiv_scalar_ratio | aiv_mte2_time(us) | aiv_mte2_ratio | aiv_mte3_time(us) | aiv_mte3_ratio | aiv_icache_miss_rate | cube_utilization(%) |\n| -------- | --------- | ---------- | ------- | --------- | ---------------- | ---------------- | -------- | ---------------- | -------------------- | ------------ | ------------- | --------- | ------------- | ------------- | ----------------------------------------------- | ----------------------------------------- | ----------------- | -------------- | ----------------- | -------------- | ---------- | --------------- | ---------------- | ---------------- | ------------- | ------------------- | ---------------- | ----------------- | -------------- | ----------------- | -------------- | -------------------- | ----------------- | -------------------- | ------------ | ---------------- | ---------------- | ------------- | ------------------- | ---------------- | ----------------- | -------------- | ----------------- | -------------- | -------------------- | ------------------- |\n| cp       | 0         | 4294967295 | 58109   | 2         | LightningIndexer | LightningIndexer | dynamic  | MIX_AIC          | 1764761459548934.118 | 282.446      | 0.789         | 24        | 48            | NO            | \"1024,64,128;485,128,1,128;1024,64;5;5;5,128\"   | DT_BF16;DT_BF16;DT_BF16;INT32;INT32;INT32 | ND;ND;ND;ND;ND;ND | \"1024,1,2048\"  | INT32             | ND             | 0          | 261.516         | 11611319         | 84.575           | 0.323         | 99.695              | 0.381            | 70.886            | 0.271          | 29.714            | 0.114          | 139.095              | 0.532             | 0.005                | 278.619      | 24741398         | 213.992          | 0.768         | 74.65               | 0.268            | 96.997            | 0.348          | 6.258             | 0.022          | 0.005                | 88.886              |\n| baseline | 0         | 4294967295 | 32711   | 2         | LightningIndexer | LightningIndexer | dynamic  | MIX_AIC          | 1764762104168502.129 | 5092.241     | 2.098         | 24        | 48            | NO            | \"16384,64,128;699,128,1,128;16384,64;4;4;4,128\" | DT_BF16;DT_BF16;DT_BF16;INT32;INT32;INT32 | ND;ND;ND;ND;ND;ND | \"16384,1,2048\" | INT32             | ND             | 0          | 4554.882        | 202236777        | 1736.127         | 0.381         | 1781.882            | 0.391            | 1451.462          | 0.319          | 549.574           | 0.121          | 2590.513             | 0.569             | 0                    | 5085.976     | 451634633        | 4250.194         | 0.836         | 1419.064            | 0.279            | 1844.032          | 0.363          | 65.617            | 0.013          | 0                    | 85.87               |\n\n**关键指标: **\n\n| 维度                | CP               | baseline           | 差异分析                                                     |\n| ------------------- | ---------------- | ------------------ | ------------------------------------------------------------ |\n| 执行耗时 (Duration) | 282.4us          | 5092.2us           | cp 比 baseline 快 18 倍                                      |\n| input_shape         | [1024,64,128]... | [16384,64,128].... | **关键：****维度差异 16 倍**                                 |\n| output_shape        | [1024, 1, 2048]  | [16384, 1, 2048]   | 同上（这里我们可以推断 indexer 在 CP 方案的计算量上远小于 baseline） |\n| aic_mte             | ....             | ....               | cp 远小于 baseline（20x）                                    |\n| aiv_mte             | ....             | ....               | cp 远小于 baseline(18x)                                      |\n\n**lightning Indexer 模块的核心收益来自于消除了** 冗余计算\n\n**为什么 baseline 中 Indexer 模块的三个矩阵无法在 TP 维度却分？**\n\n因为朴素的 TP（Megatron 提出）需要两次矩阵乘来配合，也就是一次行切一次列切，但是 lightning indexer 模块中只有一次矩阵乘就需要，完全的激活去做 top-k，所以在不引入额外通信的前提下就是无法对LightningIndexer 模块的矩阵去做 TP 切分的。\n\n### 3.其他优化\n\n- 消除全流程的冗余计算\n\n- 通信上优化\n  ....\n\n  \n\n\n\n## 5. 总结与展望\n\nSharded Context Parallelism 是一次将 CP 理念推向极致的尝试：\n1.  ✅ **打破粒度限制**：实现单卡级 CP，最大化硬件利用率。\n2.  ✅ **打破显存限制**：Shard Linear 消除权重冗余。\n3.  ✅ **打破计算限制**：彻底消除稀疏模型的 Indexer 冗余。\n4.  ✅ **打破通信限制**：通过全流程掩盖，实现 Attention 阶段“零”通信。\n\n**实测效果**：DeepSeek-v3.2 吞吐量提升 **336%**，验证了该架构在处理复杂稀疏大模型时的卓越效能。\n\n**未来计划**：\n- 进一步集成 **PCP (Partial Context Parallel)**，实现单卡级别的 KV Cache 物理去重。\n- 将 Sharded CP 推广至更多 Transformer 架构模型，坐等Deepseek-V4😊。\n","slug":"Sharded-Context-Parallel","published":1,"comments":1,"layout":"post","photos":[],"_id":"cuidvZwLBwExEKdx-oaUYficy","content":"<h1 id=\"Sharded-Context-Parallelism-极致挖掘-CP-潜力\"><a href=\"#Sharded-Context-Parallelism-极致挖掘-CP-潜力\" class=\"headerlink\" title=\"Sharded Context Parallelism: 极致挖掘 CP 潜力\"></a>Sharded Context Parallelism: 极致挖掘 CP 潜力</h1><h2 id=\"1-背景与挑战\"><a href=\"#1-背景与挑战\" class=\"headerlink\" title=\"1. 背景与挑战\"></a>1. 背景与挑战</h2><h3 id=\"1-1-Context-Parallelism-的崛起\"><a href=\"#1-1-Context-Parallelism-的崛起\" class=\"headerlink\" title=\"1.1 Context Parallelism 的崛起\"></a>1.1 Context Parallelism 的崛起</h3><p>上下文并行（Context Parallelism, CP）已成为扩展长上下文（Long Context）及稀疏注意力（Sparse Attention）模型推理的关键技术。相较于传统的张量并行（TP），CP 具备显著优势（参考 <a href=\"https://mlsys.org/virtual/2025/3329\">MLSys 2025</a>）：</p>\n<ul>\n<li><strong>低延迟</strong>：通过序列维度的并行计算显著降低首字延迟（TTFT）。</li>\n<li><strong>低通信</strong>：节点间通信量远低于 TP，适合跨节点扩展。</li>\n<li><strong>分布式 KV Cache</strong>：KV 缓存容量随设备数线性扩展，有效支撑超长序列。</li>\n</ul>\n<h3 id=\"1-2-现有-CP-TP-架构的瓶颈\"><a href=\"#1-2-现有-CP-TP-架构的瓶颈\" class=\"headerlink\" title=\"1.2 现有 CP+TP 架构的瓶颈\"></a>1.2 现有 CP+TP 架构的瓶颈</h3><p>然而，当前的 CP 主流实现（如 RFC #22693）通常采用 <strong>CP+TP 混合架构</strong>。在处理 DeepSeek-V3&#x2F;V3.2 等稀疏模型时，这种架构暴露出了三大核心局限：</p>\n<h4 id=\"1-显存瓶颈：权重冗余存储\"><a href=\"#1-显存瓶颈：权重冗余存储\" class=\"headerlink\" title=\"(1) 显存瓶颈：权重冗余存储\"></a>(1) 显存瓶颈：权重冗余存储</h4><p>在 CP 组内，尽管序列被切分，但每个 Rank 仍需持有<strong>完整的权重副本</strong>（或 TP 分片）。</p>\n<ul>\n<li><strong>后果</strong>：总显存占用随 CP Rank 数线性增长，严重限制了 CP 在细粒度（如单卡单 Rank）场景下的扩展能力。</li>\n</ul>\n<h4 id=\"2-计算瓶颈：稀疏逻辑冗余\"><a href=\"#2-计算瓶颈：稀疏逻辑冗余\" class=\"headerlink\" title=\"(2) 计算瓶颈：稀疏逻辑冗余\"></a>(2) 计算瓶颈：稀疏逻辑冗余</h4><p>每个 CP Rank 内部仍需执行完整的 TP 逻辑。对于 DeepSeek DSA 等稀疏模型，<strong>Indexer 模块</strong>（负责动态选择活跃 Token）无法通过 TP 并行化。</p>\n<ul>\n<li><strong>后果</strong>：每个 Rank 必须在其本地序列上独立运行<strong>完整的 Indexer 逻辑</strong>。这导致对大量非活跃&#x2F;无关 Token 的冗余计算，且冗余量随 CP 规模线性增加。</li>\n</ul>\n<h4 id=\"3-存储瓶颈：KV-Cache-去重不彻底\"><a href=\"#3-存储瓶颈：KV-Cache-去重不彻底\" class=\"headerlink\" title=\"(3) 存储瓶颈：KV Cache 去重不彻底\"></a>(3) 存储瓶颈：KV Cache 去重不彻底</h4><p>虽然 PCP&#x2F;DCP 实现了 CP 间的 KV Cache 去重，但在 Rank 内部的 TP 设备组之间，KV Cache 仍然是<strong>完全复制</strong>的。</p>\n<hr>\n<h2 id=\"2-核心方案：Sharded-Context-Parallelism\"><a href=\"#2-核心方案：Sharded-Context-Parallelism\" class=\"headerlink\" title=\"2. 核心方案：Sharded Context Parallelism\"></a>2. 核心方案：Sharded Context Parallelism</h2><p>为了突破上述限制，我们提出了 <strong>Sharded Context Parallelism（分片上下文并行）</strong>。该方案支持<strong>单 GPU 粒度</strong>的 CP，通过极致的软硬协同设计，实现了显存、计算与通信的三重优化。</p>\n<h3 id=\"2-1-核心创新\"><a href=\"#2-1-核心创新\" class=\"headerlink\" title=\"2.1 核心创新\"></a>2.1 核心创新</h3><ol>\n<li><strong>Shard Linear 机制</strong>：借鉴 FSDP 思想，按需加载权重，彻底消除权重的冗余显存占用。</li>\n<li><strong>零冗余计算</strong>：每张卡仅计算其负责的序列片段（SeqLen），Indexer 等模块不再重复计算。</li>\n<li><strong>零通信开销</strong>：通过深度流水线优化，完全掩盖 Attention 阶段的通信延迟。</li>\n</ol>\n<h3 id=\"2-2-实验成果\"><a href=\"#2-2-实验成果\" class=\"headerlink\" title=\"2.2 实验成果\"></a>2.2 实验成果</h3><p>我们在昇腾 910C NPU 的 <code>vllm-ascend</code> 框架中实现了该方案。</p>\n<ul>\n<li><strong>吞吐提升</strong>：在 DeepSeek-v3.2 上获得 <strong>336%</strong> 的吞吐量提升。</li>\n<li><strong>长文性能</strong>：在 128K 上下文场景下，性能提升高达 <strong>500%</strong>。</li>\n<li><strong>开源贡献</strong>：<a href=\"https://github.com/vllm-project/vllm-ascend/pull/4702\">vllm-project&#x2F;vllm-ascend#4702</a></li>\n</ul>\n<hr>\n<h2 id=\"3-技术实现详解：以-DeepSeek-V3-2-为例\"><a href=\"#3-技术实现详解：以-DeepSeek-V3-2-为例\" class=\"headerlink\" title=\"3. 技术实现详解：以 DeepSeek V3.2 为例\"></a>3. 技术实现详解：以 DeepSeek V3.2 为例</h2><h3 id=\"3-1-整体架构与通信掩盖\"><a href=\"#3-1-整体架构与通信掩盖\" class=\"headerlink\" title=\"3.1 整体架构与通信掩盖\"></a>3.1 整体架构与通信掩盖</h3><p>DeepSeek V3.2 的 Sharded CP 架构设计如下图所示：</p>\n<img src=\"/images/Sharded-Context-Parallel/543207039-e199ca08-7637-4efa-8934-2946e0423e39.png\" alt=\"Architecture Overview\" style=\"zoom:50%;\" />\n\n<h4 id=\"通信消除策略\"><a href=\"#通信消除策略\" class=\"headerlink\" title=\"通信消除策略\"></a>通信消除策略</h4><p>由于 Attention 权重通常是全量或 TP 冗余存储，我们采取了以下激进策略：</p>\n<ol>\n<li><strong>消除 Output All-Reduce</strong>：利用 CP 特性，每张卡仅输出部分 Token 的结果，直接取消了 <code>o_proj</code> 后的 All-Reduce。</li>\n<li><strong>KV Cache 聚合与掩盖</strong>：<ul>\n<li>计算 Attention 需要完整的 KV。我们将主模型的 KV Cache、RoPE 以及 Indexer 模块的 K Cache 进行横向拼接。</li>\n<li>发起一次 <strong>All-Gather</strong> 操作，将其与计算密集型的 <code>q_up_proj</code> 并行执行，实现<strong>通信完全被计算掩盖</strong>。</li>\n<li><strong>显存优化</strong>：KV Cache 按层通信，用完即存入 Block 或释放，无额外显存峰值。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"MoE-部分优化\"><a href=\"#MoE-部分优化\" class=\"headerlink\" title=\"MoE 部分优化\"></a>MoE 部分优化</h4><p>对 MoE 模块同样应用序列并行（SP）。Attention 结束后，每张卡持有部分 Token 的完整结果。在进入 MoE 之前的 Quant 及 Route Logits 计算后，对结果进行 All-Gather，该过程同样通过计算掩盖实现零开销。</p>\n<h3 id=\"3-2-Shard-Linear：权重的极致分片\"><a href=\"#3-2-Shard-Linear：权重的极致分片\" class=\"headerlink\" title=\"3.2 Shard Linear：权重的极致分片\"></a>3.2 Shard Linear：权重的极致分片</h3><p>针对占用 MLA 大部分显存的 <strong>Q_proj</strong> 和 <strong>O_proj</strong>，我们引入了 <strong>Shard Linear</strong> 特性。</p>\n<h4 id=\"设计理念\"><a href=\"#设计理念\" class=\"headerlink\" title=\"设计理念\"></a>设计理念</h4><p>受 FSDP 启发，Shard Linear 改变了权重的生命周期管理：</p>\n<ol>\n<li><strong>静态存储</strong>：权重以 TP 分片形式静态存储于各卡显存。</li>\n<li><strong>动态聚合</strong>：计算前异步发起 All-Gather 获取完整权重。</li>\n<li><strong>完整计算</strong>：使用完整权重进行矩阵乘法。</li>\n</ol>\n<img src=\"/images/Sharded-Context-Parallel/522353220-6b15a757-e1ac-4d92-a03b-b7b8bf063e27.png\" alt=\"Shard Linear Concept\" style=\"zoom: 33%;\" />\n\n<h4 id=\"针对-NPU-优化的-Broadcast-机制\"><a href=\"#针对-NPU-优化的-Broadcast-机制\" class=\"headerlink\" title=\"针对 NPU 优化的 Broadcast 机制\"></a>针对 NPU 优化的 Broadcast 机制</h4><p>由于昇腾 NPU 存在私有权重格式（NZ 格式）及量化属性（Quant Scale 等），直接使用 FSDP 的 All-Gather 会导致格式失效。我们设计了基于 <strong>Broadcast</strong> 的预取方案：</p>\n<ol>\n<li><strong>层级分片（Layer Sharding）</strong>：将各层权重按 <code>Layer ID % Device Count</code> 策略分配到不同设备。</li>\n<li><strong>启动预热</strong>：每张卡额外冗余缓存前 $K$ 层的完整权重，确保首 token 推理无延迟启动。</li>\n<li><strong>异步预取（Asynchronous Prefetch）</strong>：<ul>\n<li>在 SP 第一阶段 All-Gather 完成后（进入 Attention 前），定位 $L+K$ 层权重所在的源设备。</li>\n<li>源设备发起 <strong>Broadcast</strong>，将完整权重分发至所有卡。</li>\n<li>由于 Prefill 阶段 <code>q_up_proj</code> 和 <code>FlashAttention</code> 耗时较长，Broadcast 通信可被<strong>完全掩盖</strong>。</li>\n</ul>\n</li>\n<li><strong>及时释放</strong>：前向计算完成后，立即释放该层权重。</li>\n</ol>\n<img src=\"/images/Sharded-Context-Parallel/layer_sharding.png\" alt=\"layer_sharding\" style=\"zoom:50%;\" />\n\n<blockquote>\n<p>此特性已合入 vllm-ascend 主分支：<a href=\"https://github.com/vllm-project/vllm-ascend/pull/2931\">PR #2931</a></p>\n</blockquote>\n<hr>\n<h2 id=\"4-性能提升分析⭐️\"><a href=\"#4-性能提升分析⭐️\" class=\"headerlink\" title=\"4. 性能提升分析⭐️\"></a>4. 性能提升分析⭐️</h2><p>在昇腾平台能拿到如此大的性能提升，我们自己本身也是非常惊讶，也非常兴奋，因为本来我们做prefill的优化能有10%左右的性能提升都算不错的一个关键特性了。对此我针对了性能提升做了非常详细的分析。</p>\n<p><strong>性能提升benchmark图</strong> &amp;&amp; <strong>gsm8k精度图</strong>：</p>\n<img src=\"/images/Sharded-Context-Parallel/image-20260203005548367.png\" alt=\"image-20260203005548367\" style=\"zoom:33%;\" />\n\n<img src=\"/images/Sharded-Context-Parallel/image-20260203005633972.png\" alt=\"image-20260203005633972\" style=\"zoom:33%;\" />\n\n<h3 id=\"算子性能分析：\"><a href=\"#算子性能分析：\" class=\"headerlink\" title=\"算子性能分析：\"></a>算子性能分析：</h3><p>首先看性能差异比较大的算子：</p>\n<h4 id=\"1-SparseFlashAttention\"><a href=\"#1-SparseFlashAttention\" class=\"headerlink\" title=\"1. SparseFlashAttention\"></a>1. SparseFlashAttention</h4><p><strong>profile：</strong></p>\n<p><img src=\"/images/Sharded-Context-Parallel/image-20260203005907133.png\" alt=\"image-20260203005907133\"></p>\n<p><strong>kernel_details</strong>：</p>\n<table>\n<thead>\n<tr>\n<th>方案</th>\n<th>Device_id</th>\n<th>Model ID</th>\n<th>Task ID</th>\n<th>Stream ID</th>\n<th>Name</th>\n<th>Type</th>\n<th>OP State</th>\n<th>Accelerator Core</th>\n<th>Start Time(us)</th>\n<th>Duration(us)</th>\n<th>Wait Time(us)</th>\n<th>Block Dim</th>\n<th>Mix Block Dim</th>\n<th><strong>HF32 Eligible</strong></th>\n<th><strong>Input Shapes</strong></th>\n<th><strong>Input Data Types</strong></th>\n<th><strong>Input Formats</strong></th>\n<th><strong>Output Shapes</strong></th>\n<th><strong>Output Data Types</strong></th>\n<th><strong>Output Formats</strong></th>\n<th><strong>Context ID</strong></th>\n<th><strong>aicore_time(us)</strong></th>\n<th><strong>aic_total_cycles</strong></th>\n<th><strong>aic_mac_time(us)</strong></th>\n<th><strong>aic_mac_ratio</strong></th>\n<th><strong>aic_scalar_time(us)</strong></th>\n<th><strong>aic_scalar_ratio</strong></th>\n<th><strong>aic_mte1_time(us)</strong></th>\n<th><strong>aic_mte1_ratio</strong></th>\n<th><strong>aic_mte2_time(us)</strong></th>\n<th><strong>aic_mte2_ratio</strong></th>\n<th><strong>aic_fixpipe_time(us)</strong></th>\n<th><strong>aic_fixpipe_ratio</strong></th>\n<th><strong>aic_icache_miss_rate</strong></th>\n<th><strong>aiv_time(us)</strong></th>\n<th><strong>aiv_total_cycles</strong></th>\n<th><strong>aiv_vec_time(us)</strong></th>\n<th><strong>aiv_vec_ratio</strong></th>\n<th><strong>aiv_scalar_time(us)</strong></th>\n<th><strong>aiv_scalar_ratio</strong></th>\n<th><strong>aiv_mte2_time(us)</strong></th>\n<th><strong>aiv_mte2_ratio</strong></th>\n<th><strong>aiv_mte3_time(us)</strong></th>\n<th><strong>aiv_mte3_ratio</strong></th>\n<th><strong>aiv_icache_miss_rate</strong></th>\n<th><strong>cube_utilization(%)</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>cp</strong></td>\n<td>0</td>\n<td>4294967295</td>\n<td>58111</td>\n<td>2</td>\n<td>SparseFlashAttention</td>\n<td>SparseFlashAttention</td>\n<td>dynamic</td>\n<td>MIX_AIC</td>\n<td>1764761459549479.309</td>\n<td>3524.631</td>\n<td>1.055</td>\n<td>24</td>\n<td>48</td>\n<td>NO</td>\n<td>“1024,128,512;485,128,1,512;485,128,1,512;1024,1,2048;5,128;5;5;1024,128,64;485,128,1,64”</td>\n<td>DT_BF16;DT_BF16;DT_BF16;INT32;INT32;INT32;INT32;DT_BF16;DT_BF16</td>\n<td>ND;ND;ND;ND;ND;ND;ND;ND;ND</td>\n<td>“1024,128,512”</td>\n<td>DT_BF16</td>\n<td>ND</td>\n<td>0</td>\n<td>2767.033</td>\n<td>122856248</td>\n<td>1270.05</td>\n<td>0.459</td>\n<td>1090.331</td>\n<td>0.394</td>\n<td>1124.983</td>\n<td>0.407</td>\n<td>1901.353</td>\n<td>0.687</td>\n<td>1908.977</td>\n<td>0.69</td>\n<td>0</td>\n<td>2769.781</td>\n<td>245956577</td>\n<td>802.586</td>\n<td>0.29</td>\n<td>2338.385</td>\n<td>0.844</td>\n<td>1725.753</td>\n<td>0.623</td>\n<td>714.356</td>\n<td>0.258</td>\n<td>0</td>\n<td>75.365</td>\n</tr>\n<tr>\n<td><strong>baseline</strong></td>\n<td>0</td>\n<td>4294967295</td>\n<td>32713</td>\n<td>2</td>\n<td>SparseFlashAttention</td>\n<td>SparseFlashAttention</td>\n<td>dynamic</td>\n<td>MIX_AIC</td>\n<td>1764762104173838.715</td>\n<td>39846.596</td>\n<td>1.135</td>\n<td>24</td>\n<td>48</td>\n<td>NO</td>\n<td>“16384,8,512;699,128,1,512;699,128,1,512;16384,1,2048;4,128;4;4;16384,8,64;699,128,1,64”</td>\n<td>DT_BF16;DT_BF16;DT_BF16;INT32;INT32;INT32;INT32;DT_BF16;DT_BF16</td>\n<td>ND;ND;ND;ND;ND;ND;ND;ND;ND</td>\n<td>“16384,8,512”</td>\n<td>DT_BF16</td>\n<td>ND</td>\n<td>0</td>\n<td>30812.793</td>\n<td>1368088000</td>\n<td>5191.721</td>\n<td>0.168</td>\n<td>12573.224</td>\n<td>0.408</td>\n<td>13614.999</td>\n<td>0.442</td>\n<td>24602.17</td>\n<td>0.798</td>\n<td>23509.344</td>\n<td>0.763</td>\n<td>0</td>\n<td>30813.542</td>\n<td>2736242537</td>\n<td>1104.192</td>\n<td>0.036</td>\n<td>28802.779</td>\n<td>0.935</td>\n<td>24316.9</td>\n<td>0.789</td>\n<td>5973.504</td>\n<td>0.194</td>\n<td>0</td>\n<td>74.235</td>\n</tr>\n</tbody></table>\n<p><strong>我们来看一下其中的一些关键指标</strong></p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">维度</th>\n<th align=\"left\">CP</th>\n<th align=\"left\">Baseline</th>\n<th>差异分析</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\"><strong>执行耗时 (Duration)</strong></td>\n<td align=\"left\">3.52 ms</td>\n<td align=\"left\">39.85 ms</td>\n<td>cp 快 11.3 倍</td>\n</tr>\n<tr>\n<td align=\"left\"><strong>input_shape</strong></td>\n<td align=\"left\"><code>[1024, 128, 512]...</code></td>\n<td align=\"left\"><code>[16384, 8, 512]...</code></td>\n<td>CP 方案切分 seq，但是保留完整的 head，随维度不同但是数据量相同</td>\n</tr>\n<tr>\n<td align=\"left\"><strong>output_shape</strong></td>\n<td align=\"left\"><code>[1024, 128, 512]</code></td>\n<td align=\"left\"><code>[16384, 8, 512]</code></td>\n<td>同上（这里我们可以推断 sfa 的的计算量是完全是相同的）</td>\n</tr>\n<tr>\n<td align=\"left\"><strong>cube_utilization(%)</strong></td>\n<td align=\"left\">75.365%</td>\n<td align=\"left\">74.235%</td>\n<td>利用率相近，说明计算效率相当</td>\n</tr>\n<tr>\n<td align=\"left\"><strong>aic_mte1_time</strong><br /><strong>aic_mte2_time</strong><br /><strong>aiv_mte2_time</strong><br /><strong>aiv_mte3_time</strong></td>\n<td align=\"left\">1124.98 μs<br />1901.35 μs<br />1725.75 μs<br />714.36 μs</td>\n<td align=\"left\">13614.99 μs<br />24602.17 μs<br />24316.9 μs<br />5973.5 μs</td>\n<td>基本都是 12 倍左右，mte就是 CP 方案快的关键</td>\n</tr>\n</tbody></table>\n<p>MTE 是 CP 方案中性能提升的 <strong>关键</strong></p>\n<p><strong>在 华为昇腾AI 处理器（如 Ascend 910）中，MTE 是专门负责数据搬运的硬件单元，与计算单元（如 AI Core 中的 Cube、Vector 单元）解耦并行工作。</strong></p>\n<p>由于 CP 方案显著减少了 KV Cache 的读取量，大幅降低了内存传输引擎（MTE）的负担，从而缩短了数据搬运时间。这一优化有效缓解了访存瓶颈，使得 SFA算子中的矩阵乘计算能够更高效地流水执行，最终带来整体性能的显著加速。</p>\n<p><strong>为什么 CP 能减少 kv cache 访存 ?</strong></p>\n<p>在SFA计算中，baseline 方案采用 TP：每张卡持有完整的 seqlen 的 Q，但只分配部分注意力头，因此需要与对应分片的 KV 进行矩阵乘。<br>而 CP 方案则不同：每张卡持有部分 seqlen 的 Q，但拥有全部的注意力头，并与完整的 KV Cache 进行计算。</p>\n<p>DeepSeek-V3.2 引入了 Indexer 模块，使得每个 token 仅需访问固定长度2048的 KV，而非整个 kv。在此背景下，CP 方案的优势更加凸显：由于每张卡只处理局部序列，它只需加载与该局部 Q 对应的、经 Indexer 筛选后的少量 KV，显著减少了 KV 的读取量。相比之下，baseline 方案中每张卡持有完整的 seqlen，因此需要读取大量的 kvcache，导致在 SFA 执行过程中频繁触发大规模的 MTE操作，造成严重的访存开销和流水线停顿。<br>因为我们 global 的并行配置 baseline 为 TP16，而 CP 方案为 CP16，理论上 baseline KV 读取量可能是 CP 方案的 16 倍，但是由于每个 token 的 top-k(2048)会有重复，所有 kvcache 读取量 并没有 16 倍的差距。</p>\n<h3 id=\"2-LightningIndexer-的计算\"><a href=\"#2-LightningIndexer-的计算\" class=\"headerlink\" title=\"2. LightningIndexer 的计算\"></a>2. LightningIndexer 的计算</h3><p><strong>profile：</strong></p>\n<p><img src=\"/images/Sharded-Context-Parallel/image-20260203011606196.png\" alt=\"image-20260203011606196\"></p>\n<p><strong>kernel_details</strong>：</p>\n<table>\n<thead>\n<tr>\n<th>方案</th>\n<th>Device_id</th>\n<th>Model ID</th>\n<th>Task ID</th>\n<th>Stream ID</th>\n<th>Name</th>\n<th>Type</th>\n<th>OP State</th>\n<th>Accelerator Core</th>\n<th>Start Time(us)</th>\n<th>Duration(us)</th>\n<th>Wait Time(us)</th>\n<th>Block Dim</th>\n<th>Mix Block Dim</th>\n<th>HF32 Eligible</th>\n<th>Input Shapes</th>\n<th>Input Data Types</th>\n<th>Input Formats</th>\n<th>Output Shapes</th>\n<th>Output Data Types</th>\n<th>Output Formats</th>\n<th>Context ID</th>\n<th>aicore_time(us)</th>\n<th>aic_total_cycles</th>\n<th>aic_mac_time(us)</th>\n<th>aic_mac_ratio</th>\n<th>aic_scalar_time(us)</th>\n<th>aic_scalar_ratio</th>\n<th>aic_mte1_time(us)</th>\n<th>aic_mte1_ratio</th>\n<th>aic_mte2_time(us)</th>\n<th>aic_mte2_ratio</th>\n<th>aic_fixpipe_time(us)</th>\n<th>aic_fixpipe_ratio</th>\n<th>aic_icache_miss_rate</th>\n<th>aiv_time(us)</th>\n<th>aiv_total_cycles</th>\n<th>aiv_vec_time(us)</th>\n<th>aiv_vec_ratio</th>\n<th>aiv_scalar_time(us)</th>\n<th>aiv_scalar_ratio</th>\n<th>aiv_mte2_time(us)</th>\n<th>aiv_mte2_ratio</th>\n<th>aiv_mte3_time(us)</th>\n<th>aiv_mte3_ratio</th>\n<th>aiv_icache_miss_rate</th>\n<th>cube_utilization(%)</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>cp</td>\n<td>0</td>\n<td>4294967295</td>\n<td>58109</td>\n<td>2</td>\n<td>LightningIndexer</td>\n<td>LightningIndexer</td>\n<td>dynamic</td>\n<td>MIX_AIC</td>\n<td>1764761459548934.118</td>\n<td>282.446</td>\n<td>0.789</td>\n<td>24</td>\n<td>48</td>\n<td>NO</td>\n<td>“1024,64,128;485,128,1,128;1024,64;5;5;5,128”</td>\n<td>DT_BF16;DT_BF16;DT_BF16;INT32;INT32;INT32</td>\n<td>ND;ND;ND;ND;ND;ND</td>\n<td>“1024,1,2048”</td>\n<td>INT32</td>\n<td>ND</td>\n<td>0</td>\n<td>261.516</td>\n<td>11611319</td>\n<td>84.575</td>\n<td>0.323</td>\n<td>99.695</td>\n<td>0.381</td>\n<td>70.886</td>\n<td>0.271</td>\n<td>29.714</td>\n<td>0.114</td>\n<td>139.095</td>\n<td>0.532</td>\n<td>0.005</td>\n<td>278.619</td>\n<td>24741398</td>\n<td>213.992</td>\n<td>0.768</td>\n<td>74.65</td>\n<td>0.268</td>\n<td>96.997</td>\n<td>0.348</td>\n<td>6.258</td>\n<td>0.022</td>\n<td>0.005</td>\n<td>88.886</td>\n</tr>\n<tr>\n<td>baseline</td>\n<td>0</td>\n<td>4294967295</td>\n<td>32711</td>\n<td>2</td>\n<td>LightningIndexer</td>\n<td>LightningIndexer</td>\n<td>dynamic</td>\n<td>MIX_AIC</td>\n<td>1764762104168502.129</td>\n<td>5092.241</td>\n<td>2.098</td>\n<td>24</td>\n<td>48</td>\n<td>NO</td>\n<td>“16384,64,128;699,128,1,128;16384,64;4;4;4,128”</td>\n<td>DT_BF16;DT_BF16;DT_BF16;INT32;INT32;INT32</td>\n<td>ND;ND;ND;ND;ND;ND</td>\n<td>“16384,1,2048”</td>\n<td>INT32</td>\n<td>ND</td>\n<td>0</td>\n<td>4554.882</td>\n<td>202236777</td>\n<td>1736.127</td>\n<td>0.381</td>\n<td>1781.882</td>\n<td>0.391</td>\n<td>1451.462</td>\n<td>0.319</td>\n<td>549.574</td>\n<td>0.121</td>\n<td>2590.513</td>\n<td>0.569</td>\n<td>0</td>\n<td>5085.976</td>\n<td>451634633</td>\n<td>4250.194</td>\n<td>0.836</td>\n<td>1419.064</td>\n<td>0.279</td>\n<td>1844.032</td>\n<td>0.363</td>\n<td>65.617</td>\n<td>0.013</td>\n<td>0</td>\n<td>85.87</td>\n</tr>\n</tbody></table>\n<p>**关键指标: **</p>\n<table>\n<thead>\n<tr>\n<th>维度</th>\n<th>CP</th>\n<th>baseline</th>\n<th>差异分析</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>执行耗时 (Duration)</td>\n<td>282.4us</td>\n<td>5092.2us</td>\n<td>cp 比 baseline 快 18 倍</td>\n</tr>\n<tr>\n<td>input_shape</td>\n<td>[1024,64,128]…</td>\n<td>[16384,64,128]….</td>\n<td>**关键：**<strong>维度差异 16 倍</strong></td>\n</tr>\n<tr>\n<td>output_shape</td>\n<td>[1024, 1, 2048]</td>\n<td>[16384, 1, 2048]</td>\n<td>同上（这里我们可以推断 indexer 在 CP 方案的计算量上远小于 baseline）</td>\n</tr>\n<tr>\n<td>aic_mte</td>\n<td>….</td>\n<td>….</td>\n<td>cp 远小于 baseline（20x）</td>\n</tr>\n<tr>\n<td>aiv_mte</td>\n<td>….</td>\n<td>….</td>\n<td>cp 远小于 baseline(18x)</td>\n</tr>\n</tbody></table>\n<p><strong>lightning Indexer 模块的核心收益来自于消除了</strong> 冗余计算</p>\n<p><strong>为什么 baseline 中 Indexer 模块的三个矩阵无法在 TP 维度却分？</strong></p>\n<p>因为朴素的 TP（Megatron 提出）需要两次矩阵乘来配合，也就是一次行切一次列切，但是 lightning indexer 模块中只有一次矩阵乘就需要，完全的激活去做 top-k，所以在不引入额外通信的前提下就是无法对LightningIndexer 模块的矩阵去做 TP 切分的。</p>\n<h3 id=\"3-其他优化\"><a href=\"#3-其他优化\" class=\"headerlink\" title=\"3.其他优化\"></a>3.其他优化</h3><ul>\n<li><p>消除全流程的冗余计算</p>\n</li>\n<li><p>通信上优化<br>….</p>\n</li>\n</ul>\n<h2 id=\"5-总结与展望\"><a href=\"#5-总结与展望\" class=\"headerlink\" title=\"5. 总结与展望\"></a>5. 总结与展望</h2><p>Sharded Context Parallelism 是一次将 CP 理念推向极致的尝试：</p>\n<ol>\n<li>✅ <strong>打破粒度限制</strong>：实现单卡级 CP，最大化硬件利用率。</li>\n<li>✅ <strong>打破显存限制</strong>：Shard Linear 消除权重冗余。</li>\n<li>✅ <strong>打破计算限制</strong>：彻底消除稀疏模型的 Indexer 冗余。</li>\n<li>✅ <strong>打破通信限制</strong>：通过全流程掩盖，实现 Attention 阶段“零”通信。</li>\n</ol>\n<p><strong>实测效果</strong>：DeepSeek-v3.2 吞吐量提升 <strong>336%</strong>，验证了该架构在处理复杂稀疏大模型时的卓越效能。</p>\n<p><strong>未来计划</strong>：</p>\n<ul>\n<li>进一步集成 <strong>PCP (Partial Context Parallel)</strong>，实现单卡级别的 KV Cache 物理去重。</li>\n<li>将 Sharded CP 推广至更多 Transformer 架构模型，坐等Deepseek-V4😊。</li>\n</ul>\n","excerpt":"","more":"<h1 id=\"Sharded-Context-Parallelism-极致挖掘-CP-潜力\"><a href=\"#Sharded-Context-Parallelism-极致挖掘-CP-潜力\" class=\"headerlink\" title=\"Sharded Context Parallelism: 极致挖掘 CP 潜力\"></a>Sharded Context Parallelism: 极致挖掘 CP 潜力</h1><h2 id=\"1-背景与挑战\"><a href=\"#1-背景与挑战\" class=\"headerlink\" title=\"1. 背景与挑战\"></a>1. 背景与挑战</h2><h3 id=\"1-1-Context-Parallelism-的崛起\"><a href=\"#1-1-Context-Parallelism-的崛起\" class=\"headerlink\" title=\"1.1 Context Parallelism 的崛起\"></a>1.1 Context Parallelism 的崛起</h3><p>上下文并行（Context Parallelism, CP）已成为扩展长上下文（Long Context）及稀疏注意力（Sparse Attention）模型推理的关键技术。相较于传统的张量并行（TP），CP 具备显著优势（参考 <a href=\"https://mlsys.org/virtual/2025/3329\">MLSys 2025</a>）：</p>\n<ul>\n<li><strong>低延迟</strong>：通过序列维度的并行计算显著降低首字延迟（TTFT）。</li>\n<li><strong>低通信</strong>：节点间通信量远低于 TP，适合跨节点扩展。</li>\n<li><strong>分布式 KV Cache</strong>：KV 缓存容量随设备数线性扩展，有效支撑超长序列。</li>\n</ul>\n<h3 id=\"1-2-现有-CP-TP-架构的瓶颈\"><a href=\"#1-2-现有-CP-TP-架构的瓶颈\" class=\"headerlink\" title=\"1.2 现有 CP+TP 架构的瓶颈\"></a>1.2 现有 CP+TP 架构的瓶颈</h3><p>然而，当前的 CP 主流实现（如 RFC #22693）通常采用 <strong>CP+TP 混合架构</strong>。在处理 DeepSeek-V3&#x2F;V3.2 等稀疏模型时，这种架构暴露出了三大核心局限：</p>\n<h4 id=\"1-显存瓶颈：权重冗余存储\"><a href=\"#1-显存瓶颈：权重冗余存储\" class=\"headerlink\" title=\"(1) 显存瓶颈：权重冗余存储\"></a>(1) 显存瓶颈：权重冗余存储</h4><p>在 CP 组内，尽管序列被切分，但每个 Rank 仍需持有<strong>完整的权重副本</strong>（或 TP 分片）。</p>\n<ul>\n<li><strong>后果</strong>：总显存占用随 CP Rank 数线性增长，严重限制了 CP 在细粒度（如单卡单 Rank）场景下的扩展能力。</li>\n</ul>\n<h4 id=\"2-计算瓶颈：稀疏逻辑冗余\"><a href=\"#2-计算瓶颈：稀疏逻辑冗余\" class=\"headerlink\" title=\"(2) 计算瓶颈：稀疏逻辑冗余\"></a>(2) 计算瓶颈：稀疏逻辑冗余</h4><p>每个 CP Rank 内部仍需执行完整的 TP 逻辑。对于 DeepSeek DSA 等稀疏模型，<strong>Indexer 模块</strong>（负责动态选择活跃 Token）无法通过 TP 并行化。</p>\n<ul>\n<li><strong>后果</strong>：每个 Rank 必须在其本地序列上独立运行<strong>完整的 Indexer 逻辑</strong>。这导致对大量非活跃&#x2F;无关 Token 的冗余计算，且冗余量随 CP 规模线性增加。</li>\n</ul>\n<h4 id=\"3-存储瓶颈：KV-Cache-去重不彻底\"><a href=\"#3-存储瓶颈：KV-Cache-去重不彻底\" class=\"headerlink\" title=\"(3) 存储瓶颈：KV Cache 去重不彻底\"></a>(3) 存储瓶颈：KV Cache 去重不彻底</h4><p>虽然 PCP&#x2F;DCP 实现了 CP 间的 KV Cache 去重，但在 Rank 内部的 TP 设备组之间，KV Cache 仍然是<strong>完全复制</strong>的。</p>\n<hr>\n<h2 id=\"2-核心方案：Sharded-Context-Parallelism\"><a href=\"#2-核心方案：Sharded-Context-Parallelism\" class=\"headerlink\" title=\"2. 核心方案：Sharded Context Parallelism\"></a>2. 核心方案：Sharded Context Parallelism</h2><p>为了突破上述限制，我们提出了 <strong>Sharded Context Parallelism（分片上下文并行）</strong>。该方案支持<strong>单 GPU 粒度</strong>的 CP，通过极致的软硬协同设计，实现了显存、计算与通信的三重优化。</p>\n<h3 id=\"2-1-核心创新\"><a href=\"#2-1-核心创新\" class=\"headerlink\" title=\"2.1 核心创新\"></a>2.1 核心创新</h3><ol>\n<li><strong>Shard Linear 机制</strong>：借鉴 FSDP 思想，按需加载权重，彻底消除权重的冗余显存占用。</li>\n<li><strong>零冗余计算</strong>：每张卡仅计算其负责的序列片段（SeqLen），Indexer 等模块不再重复计算。</li>\n<li><strong>零通信开销</strong>：通过深度流水线优化，完全掩盖 Attention 阶段的通信延迟。</li>\n</ol>\n<h3 id=\"2-2-实验成果\"><a href=\"#2-2-实验成果\" class=\"headerlink\" title=\"2.2 实验成果\"></a>2.2 实验成果</h3><p>我们在昇腾 910C NPU 的 <code>vllm-ascend</code> 框架中实现了该方案。</p>\n<ul>\n<li><strong>吞吐提升</strong>：在 DeepSeek-v3.2 上获得 <strong>336%</strong> 的吞吐量提升。</li>\n<li><strong>长文性能</strong>：在 128K 上下文场景下，性能提升高达 <strong>500%</strong>。</li>\n<li><strong>开源贡献</strong>：<a href=\"https://github.com/vllm-project/vllm-ascend/pull/4702\">vllm-project&#x2F;vllm-ascend#4702</a></li>\n</ul>\n<hr>\n<h2 id=\"3-技术实现详解：以-DeepSeek-V3-2-为例\"><a href=\"#3-技术实现详解：以-DeepSeek-V3-2-为例\" class=\"headerlink\" title=\"3. 技术实现详解：以 DeepSeek V3.2 为例\"></a>3. 技术实现详解：以 DeepSeek V3.2 为例</h2><h3 id=\"3-1-整体架构与通信掩盖\"><a href=\"#3-1-整体架构与通信掩盖\" class=\"headerlink\" title=\"3.1 整体架构与通信掩盖\"></a>3.1 整体架构与通信掩盖</h3><p>DeepSeek V3.2 的 Sharded CP 架构设计如下图所示：</p>\n<img src=\"/images/Sharded-Context-Parallel/543207039-e199ca08-7637-4efa-8934-2946e0423e39.png\" alt=\"Architecture Overview\" style=\"zoom:50%;\" />\n\n<h4 id=\"通信消除策略\"><a href=\"#通信消除策略\" class=\"headerlink\" title=\"通信消除策略\"></a>通信消除策略</h4><p>由于 Attention 权重通常是全量或 TP 冗余存储，我们采取了以下激进策略：</p>\n<ol>\n<li><strong>消除 Output All-Reduce</strong>：利用 CP 特性，每张卡仅输出部分 Token 的结果，直接取消了 <code>o_proj</code> 后的 All-Reduce。</li>\n<li><strong>KV Cache 聚合与掩盖</strong>：<ul>\n<li>计算 Attention 需要完整的 KV。我们将主模型的 KV Cache、RoPE 以及 Indexer 模块的 K Cache 进行横向拼接。</li>\n<li>发起一次 <strong>All-Gather</strong> 操作，将其与计算密集型的 <code>q_up_proj</code> 并行执行，实现<strong>通信完全被计算掩盖</strong>。</li>\n<li><strong>显存优化</strong>：KV Cache 按层通信，用完即存入 Block 或释放，无额外显存峰值。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"MoE-部分优化\"><a href=\"#MoE-部分优化\" class=\"headerlink\" title=\"MoE 部分优化\"></a>MoE 部分优化</h4><p>对 MoE 模块同样应用序列并行（SP）。Attention 结束后，每张卡持有部分 Token 的完整结果。在进入 MoE 之前的 Quant 及 Route Logits 计算后，对结果进行 All-Gather，该过程同样通过计算掩盖实现零开销。</p>\n<h3 id=\"3-2-Shard-Linear：权重的极致分片\"><a href=\"#3-2-Shard-Linear：权重的极致分片\" class=\"headerlink\" title=\"3.2 Shard Linear：权重的极致分片\"></a>3.2 Shard Linear：权重的极致分片</h3><p>针对占用 MLA 大部分显存的 <strong>Q_proj</strong> 和 <strong>O_proj</strong>，我们引入了 <strong>Shard Linear</strong> 特性。</p>\n<h4 id=\"设计理念\"><a href=\"#设计理念\" class=\"headerlink\" title=\"设计理念\"></a>设计理念</h4><p>受 FSDP 启发，Shard Linear 改变了权重的生命周期管理：</p>\n<ol>\n<li><strong>静态存储</strong>：权重以 TP 分片形式静态存储于各卡显存。</li>\n<li><strong>动态聚合</strong>：计算前异步发起 All-Gather 获取完整权重。</li>\n<li><strong>完整计算</strong>：使用完整权重进行矩阵乘法。</li>\n</ol>\n<img src=\"/images/Sharded-Context-Parallel/522353220-6b15a757-e1ac-4d92-a03b-b7b8bf063e27.png\" alt=\"Shard Linear Concept\" style=\"zoom: 33%;\" />\n\n<h4 id=\"针对-NPU-优化的-Broadcast-机制\"><a href=\"#针对-NPU-优化的-Broadcast-机制\" class=\"headerlink\" title=\"针对 NPU 优化的 Broadcast 机制\"></a>针对 NPU 优化的 Broadcast 机制</h4><p>由于昇腾 NPU 存在私有权重格式（NZ 格式）及量化属性（Quant Scale 等），直接使用 FSDP 的 All-Gather 会导致格式失效。我们设计了基于 <strong>Broadcast</strong> 的预取方案：</p>\n<ol>\n<li><strong>层级分片（Layer Sharding）</strong>：将各层权重按 <code>Layer ID % Device Count</code> 策略分配到不同设备。</li>\n<li><strong>启动预热</strong>：每张卡额外冗余缓存前 $K$ 层的完整权重，确保首 token 推理无延迟启动。</li>\n<li><strong>异步预取（Asynchronous Prefetch）</strong>：<ul>\n<li>在 SP 第一阶段 All-Gather 完成后（进入 Attention 前），定位 $L+K$ 层权重所在的源设备。</li>\n<li>源设备发起 <strong>Broadcast</strong>，将完整权重分发至所有卡。</li>\n<li>由于 Prefill 阶段 <code>q_up_proj</code> 和 <code>FlashAttention</code> 耗时较长，Broadcast 通信可被<strong>完全掩盖</strong>。</li>\n</ul>\n</li>\n<li><strong>及时释放</strong>：前向计算完成后，立即释放该层权重。</li>\n</ol>\n<img src=\"/images/Sharded-Context-Parallel/layer_sharding.png\" alt=\"layer_sharding\" style=\"zoom:50%;\" />\n\n<blockquote>\n<p>此特性已合入 vllm-ascend 主分支：<a href=\"https://github.com/vllm-project/vllm-ascend/pull/2931\">PR #2931</a></p>\n</blockquote>\n<hr>\n<h2 id=\"4-性能提升分析⭐️\"><a href=\"#4-性能提升分析⭐️\" class=\"headerlink\" title=\"4. 性能提升分析⭐️\"></a>4. 性能提升分析⭐️</h2><p>在昇腾平台能拿到如此大的性能提升，我们自己本身也是非常惊讶，也非常兴奋，因为本来我们做prefill的优化能有10%左右的性能提升都算不错的一个关键特性了。对此我针对了性能提升做了非常详细的分析。</p>\n<p><strong>性能提升benchmark图</strong> &amp;&amp; <strong>gsm8k精度图</strong>：</p>\n<img src=\"/images/Sharded-Context-Parallel/image-20260203005548367.png\" alt=\"image-20260203005548367\" style=\"zoom:33%;\" />\n\n<img src=\"/images/Sharded-Context-Parallel/image-20260203005633972.png\" alt=\"image-20260203005633972\" style=\"zoom:33%;\" />\n\n<h3 id=\"算子性能分析：\"><a href=\"#算子性能分析：\" class=\"headerlink\" title=\"算子性能分析：\"></a>算子性能分析：</h3><p>首先看性能差异比较大的算子：</p>\n<h4 id=\"1-SparseFlashAttention\"><a href=\"#1-SparseFlashAttention\" class=\"headerlink\" title=\"1. SparseFlashAttention\"></a>1. SparseFlashAttention</h4><p><strong>profile：</strong></p>\n<p><img src=\"/images/Sharded-Context-Parallel/image-20260203005907133.png\" alt=\"image-20260203005907133\"></p>\n<p><strong>kernel_details</strong>：</p>\n<table>\n<thead>\n<tr>\n<th>方案</th>\n<th>Device_id</th>\n<th>Model ID</th>\n<th>Task ID</th>\n<th>Stream ID</th>\n<th>Name</th>\n<th>Type</th>\n<th>OP State</th>\n<th>Accelerator Core</th>\n<th>Start Time(us)</th>\n<th>Duration(us)</th>\n<th>Wait Time(us)</th>\n<th>Block Dim</th>\n<th>Mix Block Dim</th>\n<th><strong>HF32 Eligible</strong></th>\n<th><strong>Input Shapes</strong></th>\n<th><strong>Input Data Types</strong></th>\n<th><strong>Input Formats</strong></th>\n<th><strong>Output Shapes</strong></th>\n<th><strong>Output Data Types</strong></th>\n<th><strong>Output Formats</strong></th>\n<th><strong>Context ID</strong></th>\n<th><strong>aicore_time(us)</strong></th>\n<th><strong>aic_total_cycles</strong></th>\n<th><strong>aic_mac_time(us)</strong></th>\n<th><strong>aic_mac_ratio</strong></th>\n<th><strong>aic_scalar_time(us)</strong></th>\n<th><strong>aic_scalar_ratio</strong></th>\n<th><strong>aic_mte1_time(us)</strong></th>\n<th><strong>aic_mte1_ratio</strong></th>\n<th><strong>aic_mte2_time(us)</strong></th>\n<th><strong>aic_mte2_ratio</strong></th>\n<th><strong>aic_fixpipe_time(us)</strong></th>\n<th><strong>aic_fixpipe_ratio</strong></th>\n<th><strong>aic_icache_miss_rate</strong></th>\n<th><strong>aiv_time(us)</strong></th>\n<th><strong>aiv_total_cycles</strong></th>\n<th><strong>aiv_vec_time(us)</strong></th>\n<th><strong>aiv_vec_ratio</strong></th>\n<th><strong>aiv_scalar_time(us)</strong></th>\n<th><strong>aiv_scalar_ratio</strong></th>\n<th><strong>aiv_mte2_time(us)</strong></th>\n<th><strong>aiv_mte2_ratio</strong></th>\n<th><strong>aiv_mte3_time(us)</strong></th>\n<th><strong>aiv_mte3_ratio</strong></th>\n<th><strong>aiv_icache_miss_rate</strong></th>\n<th><strong>cube_utilization(%)</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>cp</strong></td>\n<td>0</td>\n<td>4294967295</td>\n<td>58111</td>\n<td>2</td>\n<td>SparseFlashAttention</td>\n<td>SparseFlashAttention</td>\n<td>dynamic</td>\n<td>MIX_AIC</td>\n<td>1764761459549479.309</td>\n<td>3524.631</td>\n<td>1.055</td>\n<td>24</td>\n<td>48</td>\n<td>NO</td>\n<td>“1024,128,512;485,128,1,512;485,128,1,512;1024,1,2048;5,128;5;5;1024,128,64;485,128,1,64”</td>\n<td>DT_BF16;DT_BF16;DT_BF16;INT32;INT32;INT32;INT32;DT_BF16;DT_BF16</td>\n<td>ND;ND;ND;ND;ND;ND;ND;ND;ND</td>\n<td>“1024,128,512”</td>\n<td>DT_BF16</td>\n<td>ND</td>\n<td>0</td>\n<td>2767.033</td>\n<td>122856248</td>\n<td>1270.05</td>\n<td>0.459</td>\n<td>1090.331</td>\n<td>0.394</td>\n<td>1124.983</td>\n<td>0.407</td>\n<td>1901.353</td>\n<td>0.687</td>\n<td>1908.977</td>\n<td>0.69</td>\n<td>0</td>\n<td>2769.781</td>\n<td>245956577</td>\n<td>802.586</td>\n<td>0.29</td>\n<td>2338.385</td>\n<td>0.844</td>\n<td>1725.753</td>\n<td>0.623</td>\n<td>714.356</td>\n<td>0.258</td>\n<td>0</td>\n<td>75.365</td>\n</tr>\n<tr>\n<td><strong>baseline</strong></td>\n<td>0</td>\n<td>4294967295</td>\n<td>32713</td>\n<td>2</td>\n<td>SparseFlashAttention</td>\n<td>SparseFlashAttention</td>\n<td>dynamic</td>\n<td>MIX_AIC</td>\n<td>1764762104173838.715</td>\n<td>39846.596</td>\n<td>1.135</td>\n<td>24</td>\n<td>48</td>\n<td>NO</td>\n<td>“16384,8,512;699,128,1,512;699,128,1,512;16384,1,2048;4,128;4;4;16384,8,64;699,128,1,64”</td>\n<td>DT_BF16;DT_BF16;DT_BF16;INT32;INT32;INT32;INT32;DT_BF16;DT_BF16</td>\n<td>ND;ND;ND;ND;ND;ND;ND;ND;ND</td>\n<td>“16384,8,512”</td>\n<td>DT_BF16</td>\n<td>ND</td>\n<td>0</td>\n<td>30812.793</td>\n<td>1368088000</td>\n<td>5191.721</td>\n<td>0.168</td>\n<td>12573.224</td>\n<td>0.408</td>\n<td>13614.999</td>\n<td>0.442</td>\n<td>24602.17</td>\n<td>0.798</td>\n<td>23509.344</td>\n<td>0.763</td>\n<td>0</td>\n<td>30813.542</td>\n<td>2736242537</td>\n<td>1104.192</td>\n<td>0.036</td>\n<td>28802.779</td>\n<td>0.935</td>\n<td>24316.9</td>\n<td>0.789</td>\n<td>5973.504</td>\n<td>0.194</td>\n<td>0</td>\n<td>74.235</td>\n</tr>\n</tbody></table>\n<p><strong>我们来看一下其中的一些关键指标</strong></p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">维度</th>\n<th align=\"left\">CP</th>\n<th align=\"left\">Baseline</th>\n<th>差异分析</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\"><strong>执行耗时 (Duration)</strong></td>\n<td align=\"left\">3.52 ms</td>\n<td align=\"left\">39.85 ms</td>\n<td>cp 快 11.3 倍</td>\n</tr>\n<tr>\n<td align=\"left\"><strong>input_shape</strong></td>\n<td align=\"left\"><code>[1024, 128, 512]...</code></td>\n<td align=\"left\"><code>[16384, 8, 512]...</code></td>\n<td>CP 方案切分 seq，但是保留完整的 head，随维度不同但是数据量相同</td>\n</tr>\n<tr>\n<td align=\"left\"><strong>output_shape</strong></td>\n<td align=\"left\"><code>[1024, 128, 512]</code></td>\n<td align=\"left\"><code>[16384, 8, 512]</code></td>\n<td>同上（这里我们可以推断 sfa 的的计算量是完全是相同的）</td>\n</tr>\n<tr>\n<td align=\"left\"><strong>cube_utilization(%)</strong></td>\n<td align=\"left\">75.365%</td>\n<td align=\"left\">74.235%</td>\n<td>利用率相近，说明计算效率相当</td>\n</tr>\n<tr>\n<td align=\"left\"><strong>aic_mte1_time</strong><br /><strong>aic_mte2_time</strong><br /><strong>aiv_mte2_time</strong><br /><strong>aiv_mte3_time</strong></td>\n<td align=\"left\">1124.98 μs<br />1901.35 μs<br />1725.75 μs<br />714.36 μs</td>\n<td align=\"left\">13614.99 μs<br />24602.17 μs<br />24316.9 μs<br />5973.5 μs</td>\n<td>基本都是 12 倍左右，mte就是 CP 方案快的关键</td>\n</tr>\n</tbody></table>\n<p>MTE 是 CP 方案中性能提升的 <strong>关键</strong></p>\n<p><strong>在 华为昇腾AI 处理器（如 Ascend 910）中，MTE 是专门负责数据搬运的硬件单元，与计算单元（如 AI Core 中的 Cube、Vector 单元）解耦并行工作。</strong></p>\n<p>由于 CP 方案显著减少了 KV Cache 的读取量，大幅降低了内存传输引擎（MTE）的负担，从而缩短了数据搬运时间。这一优化有效缓解了访存瓶颈，使得 SFA算子中的矩阵乘计算能够更高效地流水执行，最终带来整体性能的显著加速。</p>\n<p><strong>为什么 CP 能减少 kv cache 访存 ?</strong></p>\n<p>在SFA计算中，baseline 方案采用 TP：每张卡持有完整的 seqlen 的 Q，但只分配部分注意力头，因此需要与对应分片的 KV 进行矩阵乘。<br>而 CP 方案则不同：每张卡持有部分 seqlen 的 Q，但拥有全部的注意力头，并与完整的 KV Cache 进行计算。</p>\n<p>DeepSeek-V3.2 引入了 Indexer 模块，使得每个 token 仅需访问固定长度2048的 KV，而非整个 kv。在此背景下，CP 方案的优势更加凸显：由于每张卡只处理局部序列，它只需加载与该局部 Q 对应的、经 Indexer 筛选后的少量 KV，显著减少了 KV 的读取量。相比之下，baseline 方案中每张卡持有完整的 seqlen，因此需要读取大量的 kvcache，导致在 SFA 执行过程中频繁触发大规模的 MTE操作，造成严重的访存开销和流水线停顿。<br>因为我们 global 的并行配置 baseline 为 TP16，而 CP 方案为 CP16，理论上 baseline KV 读取量可能是 CP 方案的 16 倍，但是由于每个 token 的 top-k(2048)会有重复，所有 kvcache 读取量 并没有 16 倍的差距。</p>\n<h3 id=\"2-LightningIndexer-的计算\"><a href=\"#2-LightningIndexer-的计算\" class=\"headerlink\" title=\"2. LightningIndexer 的计算\"></a>2. LightningIndexer 的计算</h3><p><strong>profile：</strong></p>\n<p><img src=\"/images/Sharded-Context-Parallel/image-20260203011606196.png\" alt=\"image-20260203011606196\"></p>\n<p><strong>kernel_details</strong>：</p>\n<table>\n<thead>\n<tr>\n<th>方案</th>\n<th>Device_id</th>\n<th>Model ID</th>\n<th>Task ID</th>\n<th>Stream ID</th>\n<th>Name</th>\n<th>Type</th>\n<th>OP State</th>\n<th>Accelerator Core</th>\n<th>Start Time(us)</th>\n<th>Duration(us)</th>\n<th>Wait Time(us)</th>\n<th>Block Dim</th>\n<th>Mix Block Dim</th>\n<th>HF32 Eligible</th>\n<th>Input Shapes</th>\n<th>Input Data Types</th>\n<th>Input Formats</th>\n<th>Output Shapes</th>\n<th>Output Data Types</th>\n<th>Output Formats</th>\n<th>Context ID</th>\n<th>aicore_time(us)</th>\n<th>aic_total_cycles</th>\n<th>aic_mac_time(us)</th>\n<th>aic_mac_ratio</th>\n<th>aic_scalar_time(us)</th>\n<th>aic_scalar_ratio</th>\n<th>aic_mte1_time(us)</th>\n<th>aic_mte1_ratio</th>\n<th>aic_mte2_time(us)</th>\n<th>aic_mte2_ratio</th>\n<th>aic_fixpipe_time(us)</th>\n<th>aic_fixpipe_ratio</th>\n<th>aic_icache_miss_rate</th>\n<th>aiv_time(us)</th>\n<th>aiv_total_cycles</th>\n<th>aiv_vec_time(us)</th>\n<th>aiv_vec_ratio</th>\n<th>aiv_scalar_time(us)</th>\n<th>aiv_scalar_ratio</th>\n<th>aiv_mte2_time(us)</th>\n<th>aiv_mte2_ratio</th>\n<th>aiv_mte3_time(us)</th>\n<th>aiv_mte3_ratio</th>\n<th>aiv_icache_miss_rate</th>\n<th>cube_utilization(%)</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>cp</td>\n<td>0</td>\n<td>4294967295</td>\n<td>58109</td>\n<td>2</td>\n<td>LightningIndexer</td>\n<td>LightningIndexer</td>\n<td>dynamic</td>\n<td>MIX_AIC</td>\n<td>1764761459548934.118</td>\n<td>282.446</td>\n<td>0.789</td>\n<td>24</td>\n<td>48</td>\n<td>NO</td>\n<td>“1024,64,128;485,128,1,128;1024,64;5;5;5,128”</td>\n<td>DT_BF16;DT_BF16;DT_BF16;INT32;INT32;INT32</td>\n<td>ND;ND;ND;ND;ND;ND</td>\n<td>“1024,1,2048”</td>\n<td>INT32</td>\n<td>ND</td>\n<td>0</td>\n<td>261.516</td>\n<td>11611319</td>\n<td>84.575</td>\n<td>0.323</td>\n<td>99.695</td>\n<td>0.381</td>\n<td>70.886</td>\n<td>0.271</td>\n<td>29.714</td>\n<td>0.114</td>\n<td>139.095</td>\n<td>0.532</td>\n<td>0.005</td>\n<td>278.619</td>\n<td>24741398</td>\n<td>213.992</td>\n<td>0.768</td>\n<td>74.65</td>\n<td>0.268</td>\n<td>96.997</td>\n<td>0.348</td>\n<td>6.258</td>\n<td>0.022</td>\n<td>0.005</td>\n<td>88.886</td>\n</tr>\n<tr>\n<td>baseline</td>\n<td>0</td>\n<td>4294967295</td>\n<td>32711</td>\n<td>2</td>\n<td>LightningIndexer</td>\n<td>LightningIndexer</td>\n<td>dynamic</td>\n<td>MIX_AIC</td>\n<td>1764762104168502.129</td>\n<td>5092.241</td>\n<td>2.098</td>\n<td>24</td>\n<td>48</td>\n<td>NO</td>\n<td>“16384,64,128;699,128,1,128;16384,64;4;4;4,128”</td>\n<td>DT_BF16;DT_BF16;DT_BF16;INT32;INT32;INT32</td>\n<td>ND;ND;ND;ND;ND;ND</td>\n<td>“16384,1,2048”</td>\n<td>INT32</td>\n<td>ND</td>\n<td>0</td>\n<td>4554.882</td>\n<td>202236777</td>\n<td>1736.127</td>\n<td>0.381</td>\n<td>1781.882</td>\n<td>0.391</td>\n<td>1451.462</td>\n<td>0.319</td>\n<td>549.574</td>\n<td>0.121</td>\n<td>2590.513</td>\n<td>0.569</td>\n<td>0</td>\n<td>5085.976</td>\n<td>451634633</td>\n<td>4250.194</td>\n<td>0.836</td>\n<td>1419.064</td>\n<td>0.279</td>\n<td>1844.032</td>\n<td>0.363</td>\n<td>65.617</td>\n<td>0.013</td>\n<td>0</td>\n<td>85.87</td>\n</tr>\n</tbody></table>\n<p>**关键指标: **</p>\n<table>\n<thead>\n<tr>\n<th>维度</th>\n<th>CP</th>\n<th>baseline</th>\n<th>差异分析</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>执行耗时 (Duration)</td>\n<td>282.4us</td>\n<td>5092.2us</td>\n<td>cp 比 baseline 快 18 倍</td>\n</tr>\n<tr>\n<td>input_shape</td>\n<td>[1024,64,128]…</td>\n<td>[16384,64,128]….</td>\n<td>**关键：**<strong>维度差异 16 倍</strong></td>\n</tr>\n<tr>\n<td>output_shape</td>\n<td>[1024, 1, 2048]</td>\n<td>[16384, 1, 2048]</td>\n<td>同上（这里我们可以推断 indexer 在 CP 方案的计算量上远小于 baseline）</td>\n</tr>\n<tr>\n<td>aic_mte</td>\n<td>….</td>\n<td>….</td>\n<td>cp 远小于 baseline（20x）</td>\n</tr>\n<tr>\n<td>aiv_mte</td>\n<td>….</td>\n<td>….</td>\n<td>cp 远小于 baseline(18x)</td>\n</tr>\n</tbody></table>\n<p><strong>lightning Indexer 模块的核心收益来自于消除了</strong> 冗余计算</p>\n<p><strong>为什么 baseline 中 Indexer 模块的三个矩阵无法在 TP 维度却分？</strong></p>\n<p>因为朴素的 TP（Megatron 提出）需要两次矩阵乘来配合，也就是一次行切一次列切，但是 lightning indexer 模块中只有一次矩阵乘就需要，完全的激活去做 top-k，所以在不引入额外通信的前提下就是无法对LightningIndexer 模块的矩阵去做 TP 切分的。</p>\n<h3 id=\"3-其他优化\"><a href=\"#3-其他优化\" class=\"headerlink\" title=\"3.其他优化\"></a>3.其他优化</h3><ul>\n<li><p>消除全流程的冗余计算</p>\n</li>\n<li><p>通信上优化<br>….</p>\n</li>\n</ul>\n<h2 id=\"5-总结与展望\"><a href=\"#5-总结与展望\" class=\"headerlink\" title=\"5. 总结与展望\"></a>5. 总结与展望</h2><p>Sharded Context Parallelism 是一次将 CP 理念推向极致的尝试：</p>\n<ol>\n<li>✅ <strong>打破粒度限制</strong>：实现单卡级 CP，最大化硬件利用率。</li>\n<li>✅ <strong>打破显存限制</strong>：Shard Linear 消除权重冗余。</li>\n<li>✅ <strong>打破计算限制</strong>：彻底消除稀疏模型的 Indexer 冗余。</li>\n<li>✅ <strong>打破通信限制</strong>：通过全流程掩盖，实现 Attention 阶段“零”通信。</li>\n</ol>\n<p><strong>实测效果</strong>：DeepSeek-v3.2 吞吐量提升 <strong>336%</strong>，验证了该架构在处理复杂稀疏大模型时的卓越效能。</p>\n<p><strong>未来计划</strong>：</p>\n<ul>\n<li>进一步集成 <strong>PCP (Partial Context Parallel)</strong>，实现单卡级别的 KV Cache 物理去重。</li>\n<li>将 Sharded CP 推广至更多 Transformer 架构模型，坐等Deepseek-V4😊。</li>\n</ul>\n"},{"title":"Deepseek细粒度并行优化","date":"2025-11-15T11:52:18.000Z","updated":"2026-02-02T11:52:18.000Z","description":"讨论 Deepseek-R1 模型的细粒度张量并行优化","keywords":["张量并行","TP优化","分布式推理","通信优化","MLP切分","Deepseek","模型加速"],"_content":"# DeepSeek-R1 模型 Decode 阶段细粒度张量并行优化\n\n> 在大规模语言模型推理中，Decode 阶段的性能优化面临独特挑战：单 token 生成的 memory-bound 特性使得传统纯数据并行策略在显存占用和访存效率上存在瓶颈。 本文针对 DeepSeek-R1 模型，提出了细粒度张量并行优化方案。通过对 O_proj、LM Head、Embedding 和 Dense FFN 四个关键模块实施跨 DP 组的定制化切分策略，在昇腾平台上实现了 **9.72 GB 显存节省** 和约 **2 ms TPOT 优化**，显著提升了 Decode 节点的并发能力。所有优化已开源并合入 vllm-ascend 社区。\n\n## 1. 背景  \n\n### 1.1 PD 分离架构概述\n\n随着 Prefill-Decoding（PD）分离架构的兴起，vLLM 及其昇腾后端 vllm-ascend 正在积极推进对该架构的深度适配。PD 分离架构通过解耦 Prefill 阶段与 Decode 阶段，并针对各自的计算与通信特性进行独立优化，可以充分挖掘端到端推理性能潜力。\n\n### 1.2 分布式并行策略差异\n\n在分布式推理系统中,并行策略是实现高效 PD 分离的核心要素。以 DeepSeek 等大规模 MoE（Mixture of Experts）模型为例,通常采用**数据并行（DP）+ 张量并行（TP）+ 专家并行（EP）**的混合并行方案。然而,Prefill 与 Decode 两个阶段在计算模式、内存访问模式和通信开销方面存在显著差异,因此需要采用截然不同的并行策略设计:\n\n#### Prefill 阶段特征\n\n- **长序列处理**:输入序列长度较大（long seqlen）\n- **计算密集型**:属于 compute-bound 任务\n- **最优策略**:增大 TP 规模具有双重优势\n  - 降低单卡显存占用\n  - 将大规模计算任务分散到多张计算卡,充分发挥并行计算能力\n\n#### Decode 阶段特征\n\n- **固定序列长度**:每次处理的序列长度为 1\n- **小批量处理**:每次调度的 batch size 通常较小（数十量级）\n- **访存密集型**:呈现明显的 memory-bound 特征,主要瓶颈包括:\n  1. 计算量相对较小\n  2. 需要支持高并发推理\n- **现有策略问题**:Decode 节点通常采用**全 DP（纯数据并行）**策略\n  - 要求每张计算卡存储完整的模型权重（非 MoE 场景）\n  - 矩阵乘法运算时需读取更大的权重数据量\n  - 相比 Prefill 阶段,访存开销显著增加\n\n------\n\n## 2. 优化动机\n\n通过系统分析,我们发现 Decode 阶段的性能瓶颈主要来自以下两个方面:\n\n### 2.1 性能瓶颈分析\n\n#### 瓶颈 1: 访存开销过大\n\n- **KV Cache 访存**:频繁读取 KV Cache 带来的访存开销\n- **完整权重加载**:纯 DP 策略导致需读取完整模型权重\n- **影响**:矩阵乘法性能下降,TPOT（Time Per Output Token）增加\n\n#### 瓶颈 2: 显存占用受限\n\n- **KV Cache 空间占用**:限制了可并发处理的序列数量\n- **完整权重存储**:纯 DP 导致单卡权重负载过大\n- **影响**:无法增大 batch size,整体吞吐量受限\n\n### 2.2 优化思路:\"以通信换存储\"\n\n#### 设计理念\n\n在现代 Transformer 模型结构中,不同 Linear 层的权重规模存在显著差异,其计算强度也随之不同。在 Decode 阶段,由于输入序列长度固定为 1,计算高度受限于内存带宽（memory-bound）。此时,大规模 Linear 层会带来两方面性能瓶颈:\n\n1. **显存压力**:完整加载大权重矩阵导致单卡显存占用过高,限制 batch size 或阻碍模型部署\n2. **访存开销**:GEMM（通用矩阵乘法）操作需从 HBM（High Bandwidth Memory）加载大量权重数据,加剧内存带宽竞争,降低单步推理速度,恶化整体 TPOT\n\n#### 优化策略\n\n如图 1 所示,假设 OP2 代表一个典型的大型 Linear 层。若其张量并行策略完全遵循全局统一的纯 DP 配置,则无法有效缓解上述瓶颈。\n\n<img src=\"/images/Deepseek细粒度并行优化/image-20260202201605950.png\" alt=\"image-20260202201605950\" style=\"zoom:50%;\" />\n\n为此,我们提出对 OP2 这类关键大权重模块启用**跨 DP 并行组的细粒度张量并行（Fine-Grained Tensor Parallelism）**。如图 2 所示,通过在 DP 组之间对 OP2 的权重进行切分与分布式计算,可显著降低:\n\n- 单卡显存占用\n- GEMM 访存量\n\n代价是需要在 GEMM 前后引入对跨 DP 的激活值通信,以保证计算精度正确性。\n\n<img src=\"/images/Deepseek细粒度并行优化/image-20260202201646610.png\" alt=\"image-20260202201646610\" style=\"zoom:50%;\" />\n\n#### 预期收益\n\n- **显存优化**:降低需加载的权重大小,提高整体并发能力,增强系统吞吐\n- **GEMM 性能提升**:减少访存量,加速矩阵乘法运算,改善 TPOT 表现\n\n### 2.3 DeepSeek-R1 模型结构分析\n\n针对 DeepSeek-R1 模型,我们首先分析其模型结构及显存占用分布（参见图 3 和图 4）。\n\n<img src=\"/images/Deepseek细粒度并行优化/image-20260202201915235.png\" alt=\"image-20260202201915235\" style=\"zoom:50%;\" />\n\n<img src=\"/images/Deepseek细粒度并行优化/image-20260202201955025.png\" alt=\"image-20260202201955025\" style=\"zoom:50%;\" />\n\n#### 关键模块分析\n\n通过分析,我们识别出以下四个关键模块作为细粒度张量并行的优化对象:\n\n##### 1. O_proj（Attention 输出矩阵）\n\n- **权重规模**: 6.67 GB（占 Attention 模块 10.6 GB 显存的 62.9%）\n- **分布特征**: 分布在 61 层,单层权重约 117 MB\n- **访存特征**: 实际 GEMM 访存量为 117 MB/层,相对适中\n- **优化潜力**: 显存优化潜力大,但需权衡通信开销\n\n##### 2. LM Head（语言模型输出头）\n\n- **权重规模**: 1.72 GB\n- **访存特征**: GEMM 访存量为 1.72 GB,带来巨大访存开销\n- **优化潜力**: 高,访存密集型操作,切分收益明显\n\n##### 3. Embedding（词嵌入层）\n\n- **权重规模**: 1.72 GB\n- **计算特征**: 非 GEMM 运算,采用查表映射（table lookup）\n- **访存特征**: 引入巨大的访存开销\n- **优化潜力**: 高,通过切分可显著降低访存压力\n\n##### 4. Dense FFN（前馈神经网络）\n\n- **权重规模**: 1.11 GB（仅存在于前三层）\n- **访存特征**: 单层访存开销为 378 MB,相对较大\n- **优化潜力**: 中等,访存开销足以覆盖通信成本\n\n#### 面临的技术挑战\n\n在确定优化目标模块后,我们需要解决以下关键问题:\n\n1. **通信策略设计**\n   - 不同模块的计算特性各异（升维/降维、单层/双层 MLP、矩阵乘/查表）\n   - 需要针对性设计通信模式\n   - 需要建立通信时间的理论模型,以确保最佳通信效率\n2. **切分粒度确定**\n   - 需要考虑具体集群环境的特性\n   - 需要评估集群内部的通信效率\n   - 需要判断是否具备高速通信能力（如 NVLink、IB 等）\n3. **精度保证**\n   - TP 切分会引入 Reduce 操作\n   - 需要确保数值精度不会显著下降\n   - 需要验证最终推理结果的正确性\n\n为了探索不同场景下的切分方式,我开发了一个通用性 demo,可灵活支持各类切分策略与通信模式的组合: https://github.com/zzhx1/CustomTP_Demo\n\n------\n\n## 3. 技术方案设计\n\n基于上述分析,我们针对四个关键模块分别设计了细粒度张量并行切分策略。\n\n### 3.1 O_proj 矩阵切分方案\n\n**社区 PR**: [feat: oproj tensor parallelism in pure DP and graph-mode scenarios](https://github.com/vllm-project/vllm-ascend/pull/2167/commits/a675b1c42ac2a3e14904b2a3b52f9f5f37312ac0)\n\n#### 切分策略\n\n采用 **All-to-All + 行切分矩阵乘 + Reduce-Scatter** 的三阶段策略:\n\n1. **All-to-All**: 在 DP 组间重新分布激活值\n2. **行切分 GEMM**: 各计算卡负责权重矩阵的不同行切片\n3. **Reduce-Scatter**: 聚合并分散计算结果\n\n#### 实现流程\n\n<img src=\"/images/Deepseek细粒度并行优化/1765984854415-8c92bb5b-773d-40bf-ae91-0f3c183b4ad9.png\" alt=\"1765984854415-8c92bb5b-773d-40bf-ae91-0f3c183b4ad9\" style=\"zoom:50%;\" />\n\n**关键设计要点**:\n\n- 利用 Attention 输出的高维特征,通过行切分充分利用各计算卡\n- All-to-All 确保数据正确分布到对应的计算卡\n- Reduce-Scatter 高效完成结果聚合,避免全局通信瓶颈\n\n### 3.2 LM Head 矩阵切分方案\n\n**社区 PR**: [Feat: Add custom lmhead tensor model parallel](https://github.com/vllm-project/vllm-ascend/pull/2309)\n\n#### 切分策略\n\n采用 **All-Gather + 列切分矩阵乘 + All-to-All** 的三阶段策略:\n\n1. **All-Gather**: 收集完整的输入激活值\n2. **列切分 GEMM**: 各计算卡负责权重矩阵的不同列切片\n3. **All-to-All**: 重新分布输出结果\n\n#### 实现流程\n\n<img src=\"/images/Deepseek细粒度并行优化/1766036708163-c76d1b1a-8375-44b2-af90-51ae6bc16d0a.png\" alt=\"1766036708163-c76d1b1a-8375-44b2-af90-51ae6bc16d0a\" style=\"zoom:50%;\" />\n\n**关键设计要点**:\n\n- LM Head 执行词表映射,输出维度等于词表大小\n- 列切分使得各卡计算不同词汇的 logits\n- All-to-All 保证最终输出的正确性\n\n### 3.3 Embedding 矩阵切分方案\n\n**社区 PR**: [Feat: Add custom Embedding tensor model parallel](https://github.com/vllm-project/vllm-ascend/pull/2616)\n\n#### 切分策略\n\n采用 **All-Gather + 列切分查表 + Reduce-Scatter** 的三阶段策略:\n\n1. **All-Gather**: 收集完整的 token IDs\n2. **列切分查表**: 各计算卡负责 Embedding 表的不同列切片\n3. **Reduce-Scatter**: 聚合并分散 Embedding 向量\n\n#### 实现流程\n\n<img src=\"/images/Deepseek细粒度并行优化/1766038523899-adf5d01b-a6a4-4f79-8f71-8c8313e55ae9.png\" alt=\"1766038523899-adf5d01b-a6a4-4f79-8f71-8c8313e55ae9\" style=\"zoom:50%;\" />\n\n**关键设计要点**:\n\n- Embedding 操作为查表映射,非标准 GEMM\n- 列切分使得各卡存储 Embedding 表的不同特征维度\n- Reduce-Scatter 完成特征聚合,输出完整的 Embedding 向量\n\n### 3.4 Dense FFN（MLP）切分方案\n\n**社区 PR**: [Custom Dense FFN tensor parallelism](https://github.com/vllm-project/vllm-ascend/pull/4999)\n\n#### 切分策略\n\n针对 DeepSeek 前三层的 Dense FFN,采用 **All-Gather + 列切分 + 行切分 + Reduce-Scatter** 的四阶段策略:\n\n1. **All-Gather**: 收集完整的输入激活值\n2. **列切分 GEMM（第一层）**: 升维变换,各卡负责不同隐藏单元\n3. **行切分 GEMM（第二层）**: 降维变换,各卡负责不同输入特征\n4. **Reduce-Scatter**: 聚合并分散最终输出\n\n#### 实现流程\n\n<img src=\"/images/Deepseek细粒度并行优化/1766039139599-0e8f3bbd-7d96-4c6a-8a8f-80cade8c0bd6.png\" alt=\"1766039139599-0e8f3bbd-7d96-4c6a-8a8f-80cade8c0bd6\" style=\"zoom:50%;\" />\n\n**关键设计要点**:\n\n- FFN 包含两次矩阵乘法（升维+降维）\n- 第一层列切分:各卡计算中间隐藏层的不同部分\n- 第二层行切分:利用第一层的切分结果,减少通信\n- 仅需在首尾进行通信,中间计算完全并行\n\n------\n\n## 4. 实验验证与性能分析\n\n### 4.1 实验环境\n\n- **硬件平台**: 昇腾 A2 和 A3\n- **模型**: DeepSeek-R1\n- **测试节点**: Decode 节点\n- **TP 配置**: 细粒度切分规模为 8（TP=8）\n\n### 4.2 实验结果\n\n#### 各模块性能收益统计\n\n| 模块          | 切分配置 | 显存收益    | TPOT 收益<br>（batch=24） | 收益分析                              |\n| ------------- | -------- | ----------- | ------------------------- | ------------------------------------- |\n| **O_proj**    | TP=8     | **5.8 GB**  | **-1.5 ms**（劣化）       | 显存收益显著,但通信开销导致 TPOT 劣化 |\n| **LM Head**   | TP=8     | **1.51 GB** | **+1.2 ms**（优化）       | 访存密集型,切分显著提升性能           |\n| **Embedding** | TP=8     | **1.51 GB** | **+1.0 ms**（优化）       | 查表访存优化效果明显                  |\n| **Dense FFN** | TP=8     | **0.9 GB**  | **+1.0 ms**（优化）       | 访存优化覆盖通信成本                  |\n| **总计**      | -        | **9.72 GB** | **~+1 ms**（净优化）      | 整体显存大幅降低,TPOT 略有提升        |\n\n### 4.3 关键模块深度分析\n\n#### O_proj 模块分析\n\n**显存收益**:\n\n- 单模块收益最大,达到 5.8 GB\n- 占 Attention 模块显存的 62.9%\n\n**TPOT 劣化原因**:\n\n- 单层权重仅 117 MB,访存压力本身不高\n- TP 切分引入了两次 AllReduce 通信\n- 通信开销（~1.5 ms）无法被访存优化所抵消\n\n**适用场景**:\n\n- 显存受限场景,需要大幅降低显存占用\n- 对 TPOT 要求不极致苛刻的应用\n\n#### LM Head 模块分析\n\n**性能提升关键因素**:\n\n- 原始权重为 1.7 GB,访存密集度极高\n- 单次推理需读取完整 1.7 GB 权重\n- TP 切分显著缓解访存瓶颈\n\n**综合收益**:\n\n- 显存节省 1.51 GB\n- TPOT 优化 1.2 ms\n- 性能-显存双重收益\n\n#### Embedding 模块分析\n\n**特殊性**:\n\n- 计算方式为查表映射,而非标准 GEMM\n- 访存模式与 LM Head 类似,访存压力大\n\n**优化效果**:\n\n- 显存节省 1.51 GB（与 LM Head 对称）\n- TPOT 优化 1.0 ms\n- 查表访存优化效果显著\n\n#### Dense FFN 模块分析\n\n**权重特征**:\n\n- 单层权重体积相对较小（1.11 GB / 3 层）\n- 单层访存开销为 378 MB\n\n**优化有效性**:\n\n- 访存优化足以覆盖通信成本\n- TPOT 优化约 1.0 ms\n- 对前三层的推理性能提升明显\n\n### 4.4 整体评估\n\n#### 显存优化总结\n\n细粒度 TP 切分（TP=8）在整体上显著降低 Decode 节点显存占用:\n\n- **总显存节省**: 9.72 GB\n- **相对降幅**: 显著提升 GPU 利用率\n- **应用价值**: 可支持更大 batch size,提升系统吞吐量\n\n#### TPOT 性能总结\n\n整体 TPOT 性能略有提升:\n\n- **净优化**: ~1 ms（batch=24）\n- **关键贡献者**: LM Head（+1.2 ms）、Embedding（+1.0 ms）、Dense FFN（+1.0 ms）\n- **主要损耗**: O_proj（-1.5 ms）\n\n#### 策略建议\n\n基于实验结果,我们提出以下部署策略建议:\n\n1. **显存受限场景（推荐全部启用）**\n   - 所有四个模块均启用细粒度 TP\n   - 获得最大显存收益（9.72 GB）\n   - 接受小幅 TPOT 开销（净优化 ~1 ms 或持平）\n2. **TPOT 敏感场景（选择性启用）**\n   - 启用 LM Head + Embedding + Dense FFN\n   - 关闭 O_proj 切分\n   - 平衡显存节省（3.92 GB）与 TPOT 优化（+3.2 ms）\n3. **平衡场景（默认推荐）**\n   - 启用所有模块\n   - 在实际部署中根据具体负载动态调整\n\n------\n\n## 5. 总结与展望\n\n### 5.1 核心贡献\n\n本工作针对 DeepSeek-R1 模型 Decode 阶段的性能瓶颈,提出了细粒度张量并行优化方案:\n\n1. **系统性分析**: 识别出 O_proj、LM Head、Embedding、Dense FFN 四个关键瓶颈模块\n2. **定制化策略**: 针对不同模块的计算特性,设计差异化的 TP 切分与通信方案\n3. **显著收益**: 在昇腾 A2/A3 平台上验证,实现 9.72 GB 显存节省和 ~1 ms TPOT 净优化\n4. **开源贡献**: 所有优化方案已合入 vllm-ascend 社区\n\n### 5.2 适用场景\n\n该优化方案特别适用于以下场景:\n\n- 显存受限的大规模模型部署\n- 需要高并发支持的在线推理服务\n- PD 分离架构的 Decode 节点优化\n\n### 5.3 未来工作\n\n1. **扩展到更多模型**: 验证在其他 Transformer 架构（如Qwen、GLM）上的适用性\n2. **通信-计算融合**: 进一步优化通信与计算的重叠,降低端到端延迟\n3. **硬件适配**: 针对不同硬件平台（GPU、NPU）优化通信原语\n4. **vllm 主社区适配**\n\n\n\n------\n\n## 附录: Q&A\n\n### Q1: 为什么 O_proj 切分会导致 TPOT 劣化?\n\n**A**: O_proj 虽然权重规模大（6.67 GB），但分布在 61 层，单层仅 117 MB。在 Decode 阶段，单层 117 MB 的访存压力相对适中，无法成为显著瓶颈。然而，TP 切分引入了两次通信（前后各一次），通信开销超过了访存优化带来的收益，因此整体 TPOT 劣化。\n\n### Q2: 如何确定最优的 TP 切分粒度?\n\n**A**: 最优 TP 粒度取决于多个因素:\n\n- **集群通信带宽**: 高速互联（如 NVLink、IB）支持更大的 TP 粒度\n- **模块权重规模**: 越大的权重矩阵，越适合更大的 TP\n- **Batch size**: 更大的 batch size 可以摊销通信开销\n- **实验验证**: 建议通过 profiling 在实际环境中测试不同 TP 粒度的性能\n\n### Q3: 增大batch size 是否会进一步的劣化\n\n**A**: 理论上，batch size的增加，必然带来通信时间的增加，但是deocde 的激活值非常小，短时间无法达到通信密集，可预见的事通信时间会缓慢增加，直到达到通信密集之后，通信时间会显著增加。\n\n### Q4: 该方案是否适用于 Prefill 阶段?\n\n**A**: 不完全适用。Prefill 阶段的特征与 Decode 阶段截然不同: Prefill 是 compute-bound，适合全局大 TP，Decode 是 memory-bound，需要细粒度优化。细粒度 TP 主要针对 Decode 阶段的访存瓶颈，在 Prefill 阶段可能无法带来收益甚至引入额外开销。\n\n### Q5: 该方案是否适合混布?\n\n**A**: 混布是否开启该方案，必须考虑在prefill引入该方案造成的影响，目前不推荐o_porj和mlp切分在混布情况下使用，但是可以开启embedding和lmhead切分，这两个操作不管是prefill或者decode其激活值的大小都非常的小，并且整个模型只有一次计算，因此在混布情况下开启这两个切分是没有问题的。\n\n### Q6: 该方案在vllm-ascend中如何使用\n\n**A**: 详细请查看 https://docs.vllm.ai/projects/ascend/en/latest/user_guide/feature_guide/Fine_grained_TP.","source":"_posts/Deepseek细粒度并行优化.md","raw":"---\ntitle: Deepseek细粒度并行优化\ntags:\n  - Deep Learning\n  - LLM inference\n  - Deepseek\ndate: 2025-11-15 19:52:18\nupdated: 2026-02-02 19:52:18\ncategory: MLsys\ndescription: 讨论 Deepseek-R1 模型的细粒度张量并行优化\nkeywords:\n  - 张量并行\n  - TP优化\n  - 分布式推理\n  - 通信优化\n  - MLP切分\n  - Deepseek\n  - 模型加速\n---\n# DeepSeek-R1 模型 Decode 阶段细粒度张量并行优化\n\n> 在大规模语言模型推理中，Decode 阶段的性能优化面临独特挑战：单 token 生成的 memory-bound 特性使得传统纯数据并行策略在显存占用和访存效率上存在瓶颈。 本文针对 DeepSeek-R1 模型，提出了细粒度张量并行优化方案。通过对 O_proj、LM Head、Embedding 和 Dense FFN 四个关键模块实施跨 DP 组的定制化切分策略，在昇腾平台上实现了 **9.72 GB 显存节省** 和约 **2 ms TPOT 优化**，显著提升了 Decode 节点的并发能力。所有优化已开源并合入 vllm-ascend 社区。\n\n## 1. 背景  \n\n### 1.1 PD 分离架构概述\n\n随着 Prefill-Decoding（PD）分离架构的兴起，vLLM 及其昇腾后端 vllm-ascend 正在积极推进对该架构的深度适配。PD 分离架构通过解耦 Prefill 阶段与 Decode 阶段，并针对各自的计算与通信特性进行独立优化，可以充分挖掘端到端推理性能潜力。\n\n### 1.2 分布式并行策略差异\n\n在分布式推理系统中,并行策略是实现高效 PD 分离的核心要素。以 DeepSeek 等大规模 MoE（Mixture of Experts）模型为例,通常采用**数据并行（DP）+ 张量并行（TP）+ 专家并行（EP）**的混合并行方案。然而,Prefill 与 Decode 两个阶段在计算模式、内存访问模式和通信开销方面存在显著差异,因此需要采用截然不同的并行策略设计:\n\n#### Prefill 阶段特征\n\n- **长序列处理**:输入序列长度较大（long seqlen）\n- **计算密集型**:属于 compute-bound 任务\n- **最优策略**:增大 TP 规模具有双重优势\n  - 降低单卡显存占用\n  - 将大规模计算任务分散到多张计算卡,充分发挥并行计算能力\n\n#### Decode 阶段特征\n\n- **固定序列长度**:每次处理的序列长度为 1\n- **小批量处理**:每次调度的 batch size 通常较小（数十量级）\n- **访存密集型**:呈现明显的 memory-bound 特征,主要瓶颈包括:\n  1. 计算量相对较小\n  2. 需要支持高并发推理\n- **现有策略问题**:Decode 节点通常采用**全 DP（纯数据并行）**策略\n  - 要求每张计算卡存储完整的模型权重（非 MoE 场景）\n  - 矩阵乘法运算时需读取更大的权重数据量\n  - 相比 Prefill 阶段,访存开销显著增加\n\n------\n\n## 2. 优化动机\n\n通过系统分析,我们发现 Decode 阶段的性能瓶颈主要来自以下两个方面:\n\n### 2.1 性能瓶颈分析\n\n#### 瓶颈 1: 访存开销过大\n\n- **KV Cache 访存**:频繁读取 KV Cache 带来的访存开销\n- **完整权重加载**:纯 DP 策略导致需读取完整模型权重\n- **影响**:矩阵乘法性能下降,TPOT（Time Per Output Token）增加\n\n#### 瓶颈 2: 显存占用受限\n\n- **KV Cache 空间占用**:限制了可并发处理的序列数量\n- **完整权重存储**:纯 DP 导致单卡权重负载过大\n- **影响**:无法增大 batch size,整体吞吐量受限\n\n### 2.2 优化思路:\"以通信换存储\"\n\n#### 设计理念\n\n在现代 Transformer 模型结构中,不同 Linear 层的权重规模存在显著差异,其计算强度也随之不同。在 Decode 阶段,由于输入序列长度固定为 1,计算高度受限于内存带宽（memory-bound）。此时,大规模 Linear 层会带来两方面性能瓶颈:\n\n1. **显存压力**:完整加载大权重矩阵导致单卡显存占用过高,限制 batch size 或阻碍模型部署\n2. **访存开销**:GEMM（通用矩阵乘法）操作需从 HBM（High Bandwidth Memory）加载大量权重数据,加剧内存带宽竞争,降低单步推理速度,恶化整体 TPOT\n\n#### 优化策略\n\n如图 1 所示,假设 OP2 代表一个典型的大型 Linear 层。若其张量并行策略完全遵循全局统一的纯 DP 配置,则无法有效缓解上述瓶颈。\n\n<img src=\"/images/Deepseek细粒度并行优化/image-20260202201605950.png\" alt=\"image-20260202201605950\" style=\"zoom:50%;\" />\n\n为此,我们提出对 OP2 这类关键大权重模块启用**跨 DP 并行组的细粒度张量并行（Fine-Grained Tensor Parallelism）**。如图 2 所示,通过在 DP 组之间对 OP2 的权重进行切分与分布式计算,可显著降低:\n\n- 单卡显存占用\n- GEMM 访存量\n\n代价是需要在 GEMM 前后引入对跨 DP 的激活值通信,以保证计算精度正确性。\n\n<img src=\"/images/Deepseek细粒度并行优化/image-20260202201646610.png\" alt=\"image-20260202201646610\" style=\"zoom:50%;\" />\n\n#### 预期收益\n\n- **显存优化**:降低需加载的权重大小,提高整体并发能力,增强系统吞吐\n- **GEMM 性能提升**:减少访存量,加速矩阵乘法运算,改善 TPOT 表现\n\n### 2.3 DeepSeek-R1 模型结构分析\n\n针对 DeepSeek-R1 模型,我们首先分析其模型结构及显存占用分布（参见图 3 和图 4）。\n\n<img src=\"/images/Deepseek细粒度并行优化/image-20260202201915235.png\" alt=\"image-20260202201915235\" style=\"zoom:50%;\" />\n\n<img src=\"/images/Deepseek细粒度并行优化/image-20260202201955025.png\" alt=\"image-20260202201955025\" style=\"zoom:50%;\" />\n\n#### 关键模块分析\n\n通过分析,我们识别出以下四个关键模块作为细粒度张量并行的优化对象:\n\n##### 1. O_proj（Attention 输出矩阵）\n\n- **权重规模**: 6.67 GB（占 Attention 模块 10.6 GB 显存的 62.9%）\n- **分布特征**: 分布在 61 层,单层权重约 117 MB\n- **访存特征**: 实际 GEMM 访存量为 117 MB/层,相对适中\n- **优化潜力**: 显存优化潜力大,但需权衡通信开销\n\n##### 2. LM Head（语言模型输出头）\n\n- **权重规模**: 1.72 GB\n- **访存特征**: GEMM 访存量为 1.72 GB,带来巨大访存开销\n- **优化潜力**: 高,访存密集型操作,切分收益明显\n\n##### 3. Embedding（词嵌入层）\n\n- **权重规模**: 1.72 GB\n- **计算特征**: 非 GEMM 运算,采用查表映射（table lookup）\n- **访存特征**: 引入巨大的访存开销\n- **优化潜力**: 高,通过切分可显著降低访存压力\n\n##### 4. Dense FFN（前馈神经网络）\n\n- **权重规模**: 1.11 GB（仅存在于前三层）\n- **访存特征**: 单层访存开销为 378 MB,相对较大\n- **优化潜力**: 中等,访存开销足以覆盖通信成本\n\n#### 面临的技术挑战\n\n在确定优化目标模块后,我们需要解决以下关键问题:\n\n1. **通信策略设计**\n   - 不同模块的计算特性各异（升维/降维、单层/双层 MLP、矩阵乘/查表）\n   - 需要针对性设计通信模式\n   - 需要建立通信时间的理论模型,以确保最佳通信效率\n2. **切分粒度确定**\n   - 需要考虑具体集群环境的特性\n   - 需要评估集群内部的通信效率\n   - 需要判断是否具备高速通信能力（如 NVLink、IB 等）\n3. **精度保证**\n   - TP 切分会引入 Reduce 操作\n   - 需要确保数值精度不会显著下降\n   - 需要验证最终推理结果的正确性\n\n为了探索不同场景下的切分方式,我开发了一个通用性 demo,可灵活支持各类切分策略与通信模式的组合: https://github.com/zzhx1/CustomTP_Demo\n\n------\n\n## 3. 技术方案设计\n\n基于上述分析,我们针对四个关键模块分别设计了细粒度张量并行切分策略。\n\n### 3.1 O_proj 矩阵切分方案\n\n**社区 PR**: [feat: oproj tensor parallelism in pure DP and graph-mode scenarios](https://github.com/vllm-project/vllm-ascend/pull/2167/commits/a675b1c42ac2a3e14904b2a3b52f9f5f37312ac0)\n\n#### 切分策略\n\n采用 **All-to-All + 行切分矩阵乘 + Reduce-Scatter** 的三阶段策略:\n\n1. **All-to-All**: 在 DP 组间重新分布激活值\n2. **行切分 GEMM**: 各计算卡负责权重矩阵的不同行切片\n3. **Reduce-Scatter**: 聚合并分散计算结果\n\n#### 实现流程\n\n<img src=\"/images/Deepseek细粒度并行优化/1765984854415-8c92bb5b-773d-40bf-ae91-0f3c183b4ad9.png\" alt=\"1765984854415-8c92bb5b-773d-40bf-ae91-0f3c183b4ad9\" style=\"zoom:50%;\" />\n\n**关键设计要点**:\n\n- 利用 Attention 输出的高维特征,通过行切分充分利用各计算卡\n- All-to-All 确保数据正确分布到对应的计算卡\n- Reduce-Scatter 高效完成结果聚合,避免全局通信瓶颈\n\n### 3.2 LM Head 矩阵切分方案\n\n**社区 PR**: [Feat: Add custom lmhead tensor model parallel](https://github.com/vllm-project/vllm-ascend/pull/2309)\n\n#### 切分策略\n\n采用 **All-Gather + 列切分矩阵乘 + All-to-All** 的三阶段策略:\n\n1. **All-Gather**: 收集完整的输入激活值\n2. **列切分 GEMM**: 各计算卡负责权重矩阵的不同列切片\n3. **All-to-All**: 重新分布输出结果\n\n#### 实现流程\n\n<img src=\"/images/Deepseek细粒度并行优化/1766036708163-c76d1b1a-8375-44b2-af90-51ae6bc16d0a.png\" alt=\"1766036708163-c76d1b1a-8375-44b2-af90-51ae6bc16d0a\" style=\"zoom:50%;\" />\n\n**关键设计要点**:\n\n- LM Head 执行词表映射,输出维度等于词表大小\n- 列切分使得各卡计算不同词汇的 logits\n- All-to-All 保证最终输出的正确性\n\n### 3.3 Embedding 矩阵切分方案\n\n**社区 PR**: [Feat: Add custom Embedding tensor model parallel](https://github.com/vllm-project/vllm-ascend/pull/2616)\n\n#### 切分策略\n\n采用 **All-Gather + 列切分查表 + Reduce-Scatter** 的三阶段策略:\n\n1. **All-Gather**: 收集完整的 token IDs\n2. **列切分查表**: 各计算卡负责 Embedding 表的不同列切片\n3. **Reduce-Scatter**: 聚合并分散 Embedding 向量\n\n#### 实现流程\n\n<img src=\"/images/Deepseek细粒度并行优化/1766038523899-adf5d01b-a6a4-4f79-8f71-8c8313e55ae9.png\" alt=\"1766038523899-adf5d01b-a6a4-4f79-8f71-8c8313e55ae9\" style=\"zoom:50%;\" />\n\n**关键设计要点**:\n\n- Embedding 操作为查表映射,非标准 GEMM\n- 列切分使得各卡存储 Embedding 表的不同特征维度\n- Reduce-Scatter 完成特征聚合,输出完整的 Embedding 向量\n\n### 3.4 Dense FFN（MLP）切分方案\n\n**社区 PR**: [Custom Dense FFN tensor parallelism](https://github.com/vllm-project/vllm-ascend/pull/4999)\n\n#### 切分策略\n\n针对 DeepSeek 前三层的 Dense FFN,采用 **All-Gather + 列切分 + 行切分 + Reduce-Scatter** 的四阶段策略:\n\n1. **All-Gather**: 收集完整的输入激活值\n2. **列切分 GEMM（第一层）**: 升维变换,各卡负责不同隐藏单元\n3. **行切分 GEMM（第二层）**: 降维变换,各卡负责不同输入特征\n4. **Reduce-Scatter**: 聚合并分散最终输出\n\n#### 实现流程\n\n<img src=\"/images/Deepseek细粒度并行优化/1766039139599-0e8f3bbd-7d96-4c6a-8a8f-80cade8c0bd6.png\" alt=\"1766039139599-0e8f3bbd-7d96-4c6a-8a8f-80cade8c0bd6\" style=\"zoom:50%;\" />\n\n**关键设计要点**:\n\n- FFN 包含两次矩阵乘法（升维+降维）\n- 第一层列切分:各卡计算中间隐藏层的不同部分\n- 第二层行切分:利用第一层的切分结果,减少通信\n- 仅需在首尾进行通信,中间计算完全并行\n\n------\n\n## 4. 实验验证与性能分析\n\n### 4.1 实验环境\n\n- **硬件平台**: 昇腾 A2 和 A3\n- **模型**: DeepSeek-R1\n- **测试节点**: Decode 节点\n- **TP 配置**: 细粒度切分规模为 8（TP=8）\n\n### 4.2 实验结果\n\n#### 各模块性能收益统计\n\n| 模块          | 切分配置 | 显存收益    | TPOT 收益<br>（batch=24） | 收益分析                              |\n| ------------- | -------- | ----------- | ------------------------- | ------------------------------------- |\n| **O_proj**    | TP=8     | **5.8 GB**  | **-1.5 ms**（劣化）       | 显存收益显著,但通信开销导致 TPOT 劣化 |\n| **LM Head**   | TP=8     | **1.51 GB** | **+1.2 ms**（优化）       | 访存密集型,切分显著提升性能           |\n| **Embedding** | TP=8     | **1.51 GB** | **+1.0 ms**（优化）       | 查表访存优化效果明显                  |\n| **Dense FFN** | TP=8     | **0.9 GB**  | **+1.0 ms**（优化）       | 访存优化覆盖通信成本                  |\n| **总计**      | -        | **9.72 GB** | **~+1 ms**（净优化）      | 整体显存大幅降低,TPOT 略有提升        |\n\n### 4.3 关键模块深度分析\n\n#### O_proj 模块分析\n\n**显存收益**:\n\n- 单模块收益最大,达到 5.8 GB\n- 占 Attention 模块显存的 62.9%\n\n**TPOT 劣化原因**:\n\n- 单层权重仅 117 MB,访存压力本身不高\n- TP 切分引入了两次 AllReduce 通信\n- 通信开销（~1.5 ms）无法被访存优化所抵消\n\n**适用场景**:\n\n- 显存受限场景,需要大幅降低显存占用\n- 对 TPOT 要求不极致苛刻的应用\n\n#### LM Head 模块分析\n\n**性能提升关键因素**:\n\n- 原始权重为 1.7 GB,访存密集度极高\n- 单次推理需读取完整 1.7 GB 权重\n- TP 切分显著缓解访存瓶颈\n\n**综合收益**:\n\n- 显存节省 1.51 GB\n- TPOT 优化 1.2 ms\n- 性能-显存双重收益\n\n#### Embedding 模块分析\n\n**特殊性**:\n\n- 计算方式为查表映射,而非标准 GEMM\n- 访存模式与 LM Head 类似,访存压力大\n\n**优化效果**:\n\n- 显存节省 1.51 GB（与 LM Head 对称）\n- TPOT 优化 1.0 ms\n- 查表访存优化效果显著\n\n#### Dense FFN 模块分析\n\n**权重特征**:\n\n- 单层权重体积相对较小（1.11 GB / 3 层）\n- 单层访存开销为 378 MB\n\n**优化有效性**:\n\n- 访存优化足以覆盖通信成本\n- TPOT 优化约 1.0 ms\n- 对前三层的推理性能提升明显\n\n### 4.4 整体评估\n\n#### 显存优化总结\n\n细粒度 TP 切分（TP=8）在整体上显著降低 Decode 节点显存占用:\n\n- **总显存节省**: 9.72 GB\n- **相对降幅**: 显著提升 GPU 利用率\n- **应用价值**: 可支持更大 batch size,提升系统吞吐量\n\n#### TPOT 性能总结\n\n整体 TPOT 性能略有提升:\n\n- **净优化**: ~1 ms（batch=24）\n- **关键贡献者**: LM Head（+1.2 ms）、Embedding（+1.0 ms）、Dense FFN（+1.0 ms）\n- **主要损耗**: O_proj（-1.5 ms）\n\n#### 策略建议\n\n基于实验结果,我们提出以下部署策略建议:\n\n1. **显存受限场景（推荐全部启用）**\n   - 所有四个模块均启用细粒度 TP\n   - 获得最大显存收益（9.72 GB）\n   - 接受小幅 TPOT 开销（净优化 ~1 ms 或持平）\n2. **TPOT 敏感场景（选择性启用）**\n   - 启用 LM Head + Embedding + Dense FFN\n   - 关闭 O_proj 切分\n   - 平衡显存节省（3.92 GB）与 TPOT 优化（+3.2 ms）\n3. **平衡场景（默认推荐）**\n   - 启用所有模块\n   - 在实际部署中根据具体负载动态调整\n\n------\n\n## 5. 总结与展望\n\n### 5.1 核心贡献\n\n本工作针对 DeepSeek-R1 模型 Decode 阶段的性能瓶颈,提出了细粒度张量并行优化方案:\n\n1. **系统性分析**: 识别出 O_proj、LM Head、Embedding、Dense FFN 四个关键瓶颈模块\n2. **定制化策略**: 针对不同模块的计算特性,设计差异化的 TP 切分与通信方案\n3. **显著收益**: 在昇腾 A2/A3 平台上验证,实现 9.72 GB 显存节省和 ~1 ms TPOT 净优化\n4. **开源贡献**: 所有优化方案已合入 vllm-ascend 社区\n\n### 5.2 适用场景\n\n该优化方案特别适用于以下场景:\n\n- 显存受限的大规模模型部署\n- 需要高并发支持的在线推理服务\n- PD 分离架构的 Decode 节点优化\n\n### 5.3 未来工作\n\n1. **扩展到更多模型**: 验证在其他 Transformer 架构（如Qwen、GLM）上的适用性\n2. **通信-计算融合**: 进一步优化通信与计算的重叠,降低端到端延迟\n3. **硬件适配**: 针对不同硬件平台（GPU、NPU）优化通信原语\n4. **vllm 主社区适配**\n\n\n\n------\n\n## 附录: Q&A\n\n### Q1: 为什么 O_proj 切分会导致 TPOT 劣化?\n\n**A**: O_proj 虽然权重规模大（6.67 GB），但分布在 61 层，单层仅 117 MB。在 Decode 阶段，单层 117 MB 的访存压力相对适中，无法成为显著瓶颈。然而，TP 切分引入了两次通信（前后各一次），通信开销超过了访存优化带来的收益，因此整体 TPOT 劣化。\n\n### Q2: 如何确定最优的 TP 切分粒度?\n\n**A**: 最优 TP 粒度取决于多个因素:\n\n- **集群通信带宽**: 高速互联（如 NVLink、IB）支持更大的 TP 粒度\n- **模块权重规模**: 越大的权重矩阵，越适合更大的 TP\n- **Batch size**: 更大的 batch size 可以摊销通信开销\n- **实验验证**: 建议通过 profiling 在实际环境中测试不同 TP 粒度的性能\n\n### Q3: 增大batch size 是否会进一步的劣化\n\n**A**: 理论上，batch size的增加，必然带来通信时间的增加，但是deocde 的激活值非常小，短时间无法达到通信密集，可预见的事通信时间会缓慢增加，直到达到通信密集之后，通信时间会显著增加。\n\n### Q4: 该方案是否适用于 Prefill 阶段?\n\n**A**: 不完全适用。Prefill 阶段的特征与 Decode 阶段截然不同: Prefill 是 compute-bound，适合全局大 TP，Decode 是 memory-bound，需要细粒度优化。细粒度 TP 主要针对 Decode 阶段的访存瓶颈，在 Prefill 阶段可能无法带来收益甚至引入额外开销。\n\n### Q5: 该方案是否适合混布?\n\n**A**: 混布是否开启该方案，必须考虑在prefill引入该方案造成的影响，目前不推荐o_porj和mlp切分在混布情况下使用，但是可以开启embedding和lmhead切分，这两个操作不管是prefill或者decode其激活值的大小都非常的小，并且整个模型只有一次计算，因此在混布情况下开启这两个切分是没有问题的。\n\n### Q6: 该方案在vllm-ascend中如何使用\n\n**A**: 详细请查看 https://docs.vllm.ai/projects/ascend/en/latest/user_guide/feature_guide/Fine_grained_TP.","slug":"Deepseek细粒度并行优化","published":1,"comments":1,"layout":"post","photos":[],"_id":"cuidW-85cENBSdM3YwmniaYgO","content":"<h1 id=\"DeepSeek-R1-模型-Decode-阶段细粒度张量并行优化\"><a href=\"#DeepSeek-R1-模型-Decode-阶段细粒度张量并行优化\" class=\"headerlink\" title=\"DeepSeek-R1 模型 Decode 阶段细粒度张量并行优化\"></a>DeepSeek-R1 模型 Decode 阶段细粒度张量并行优化</h1><blockquote>\n<p>在大规模语言模型推理中，Decode 阶段的性能优化面临独特挑战：单 token 生成的 memory-bound 特性使得传统纯数据并行策略在显存占用和访存效率上存在瓶颈。 本文针对 DeepSeek-R1 模型，提出了细粒度张量并行优化方案。通过对 O_proj、LM Head、Embedding 和 Dense FFN 四个关键模块实施跨 DP 组的定制化切分策略，在昇腾平台上实现了 <strong>9.72 GB 显存节省</strong> 和约 <strong>2 ms TPOT 优化</strong>，显著提升了 Decode 节点的并发能力。所有优化已开源并合入 vllm-ascend 社区。</p>\n</blockquote>\n<h2 id=\"1-背景\"><a href=\"#1-背景\" class=\"headerlink\" title=\"1. 背景\"></a>1. 背景</h2><h3 id=\"1-1-PD-分离架构概述\"><a href=\"#1-1-PD-分离架构概述\" class=\"headerlink\" title=\"1.1 PD 分离架构概述\"></a>1.1 PD 分离架构概述</h3><p>随着 Prefill-Decoding（PD）分离架构的兴起，vLLM 及其昇腾后端 vllm-ascend 正在积极推进对该架构的深度适配。PD 分离架构通过解耦 Prefill 阶段与 Decode 阶段，并针对各自的计算与通信特性进行独立优化，可以充分挖掘端到端推理性能潜力。</p>\n<h3 id=\"1-2-分布式并行策略差异\"><a href=\"#1-2-分布式并行策略差异\" class=\"headerlink\" title=\"1.2 分布式并行策略差异\"></a>1.2 分布式并行策略差异</h3><p>在分布式推理系统中,并行策略是实现高效 PD 分离的核心要素。以 DeepSeek 等大规模 MoE（Mixture of Experts）模型为例,通常采用**数据并行（DP）+ 张量并行（TP）+ 专家并行（EP）**的混合并行方案。然而,Prefill 与 Decode 两个阶段在计算模式、内存访问模式和通信开销方面存在显著差异,因此需要采用截然不同的并行策略设计:</p>\n<h4 id=\"Prefill-阶段特征\"><a href=\"#Prefill-阶段特征\" class=\"headerlink\" title=\"Prefill 阶段特征\"></a>Prefill 阶段特征</h4><ul>\n<li><strong>长序列处理</strong>:输入序列长度较大（long seqlen）</li>\n<li><strong>计算密集型</strong>:属于 compute-bound 任务</li>\n<li><strong>最优策略</strong>:增大 TP 规模具有双重优势<ul>\n<li>降低单卡显存占用</li>\n<li>将大规模计算任务分散到多张计算卡,充分发挥并行计算能力</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"Decode-阶段特征\"><a href=\"#Decode-阶段特征\" class=\"headerlink\" title=\"Decode 阶段特征\"></a>Decode 阶段特征</h4><ul>\n<li><strong>固定序列长度</strong>:每次处理的序列长度为 1</li>\n<li><strong>小批量处理</strong>:每次调度的 batch size 通常较小（数十量级）</li>\n<li><strong>访存密集型</strong>:呈现明显的 memory-bound 特征,主要瓶颈包括:<ol>\n<li>计算量相对较小</li>\n<li>需要支持高并发推理</li>\n</ol>\n</li>\n<li><strong>现有策略问题</strong>:Decode 节点通常采用**全 DP（纯数据并行）**策略<ul>\n<li>要求每张计算卡存储完整的模型权重（非 MoE 场景）</li>\n<li>矩阵乘法运算时需读取更大的权重数据量</li>\n<li>相比 Prefill 阶段,访存开销显著增加</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h2 id=\"2-优化动机\"><a href=\"#2-优化动机\" class=\"headerlink\" title=\"2. 优化动机\"></a>2. 优化动机</h2><p>通过系统分析,我们发现 Decode 阶段的性能瓶颈主要来自以下两个方面:</p>\n<h3 id=\"2-1-性能瓶颈分析\"><a href=\"#2-1-性能瓶颈分析\" class=\"headerlink\" title=\"2.1 性能瓶颈分析\"></a>2.1 性能瓶颈分析</h3><h4 id=\"瓶颈-1-访存开销过大\"><a href=\"#瓶颈-1-访存开销过大\" class=\"headerlink\" title=\"瓶颈 1: 访存开销过大\"></a>瓶颈 1: 访存开销过大</h4><ul>\n<li><strong>KV Cache 访存</strong>:频繁读取 KV Cache 带来的访存开销</li>\n<li><strong>完整权重加载</strong>:纯 DP 策略导致需读取完整模型权重</li>\n<li><strong>影响</strong>:矩阵乘法性能下降,TPOT（Time Per Output Token）增加</li>\n</ul>\n<h4 id=\"瓶颈-2-显存占用受限\"><a href=\"#瓶颈-2-显存占用受限\" class=\"headerlink\" title=\"瓶颈 2: 显存占用受限\"></a>瓶颈 2: 显存占用受限</h4><ul>\n<li><strong>KV Cache 空间占用</strong>:限制了可并发处理的序列数量</li>\n<li><strong>完整权重存储</strong>:纯 DP 导致单卡权重负载过大</li>\n<li><strong>影响</strong>:无法增大 batch size,整体吞吐量受限</li>\n</ul>\n<h3 id=\"2-2-优化思路-”以通信换存储”\"><a href=\"#2-2-优化思路-”以通信换存储”\" class=\"headerlink\" title=\"2.2 优化思路:”以通信换存储”\"></a>2.2 优化思路:”以通信换存储”</h3><h4 id=\"设计理念\"><a href=\"#设计理念\" class=\"headerlink\" title=\"设计理念\"></a>设计理念</h4><p>在现代 Transformer 模型结构中,不同 Linear 层的权重规模存在显著差异,其计算强度也随之不同。在 Decode 阶段,由于输入序列长度固定为 1,计算高度受限于内存带宽（memory-bound）。此时,大规模 Linear 层会带来两方面性能瓶颈:</p>\n<ol>\n<li><strong>显存压力</strong>:完整加载大权重矩阵导致单卡显存占用过高,限制 batch size 或阻碍模型部署</li>\n<li><strong>访存开销</strong>:GEMM（通用矩阵乘法）操作需从 HBM（High Bandwidth Memory）加载大量权重数据,加剧内存带宽竞争,降低单步推理速度,恶化整体 TPOT</li>\n</ol>\n<h4 id=\"优化策略\"><a href=\"#优化策略\" class=\"headerlink\" title=\"优化策略\"></a>优化策略</h4><p>如图 1 所示,假设 OP2 代表一个典型的大型 Linear 层。若其张量并行策略完全遵循全局统一的纯 DP 配置,则无法有效缓解上述瓶颈。</p>\n<img src=\"/images/Deepseek细粒度并行优化/image-20260202201605950.png\" alt=\"image-20260202201605950\" style=\"zoom:50%;\" />\n\n<p>为此,我们提出对 OP2 这类关键大权重模块启用<strong>跨 DP 并行组的细粒度张量并行（Fine-Grained Tensor Parallelism）</strong>。如图 2 所示,通过在 DP 组之间对 OP2 的权重进行切分与分布式计算,可显著降低:</p>\n<ul>\n<li>单卡显存占用</li>\n<li>GEMM 访存量</li>\n</ul>\n<p>代价是需要在 GEMM 前后引入对跨 DP 的激活值通信,以保证计算精度正确性。</p>\n<img src=\"/images/Deepseek细粒度并行优化/image-20260202201646610.png\" alt=\"image-20260202201646610\" style=\"zoom:50%;\" />\n\n<h4 id=\"预期收益\"><a href=\"#预期收益\" class=\"headerlink\" title=\"预期收益\"></a>预期收益</h4><ul>\n<li><strong>显存优化</strong>:降低需加载的权重大小,提高整体并发能力,增强系统吞吐</li>\n<li><strong>GEMM 性能提升</strong>:减少访存量,加速矩阵乘法运算,改善 TPOT 表现</li>\n</ul>\n<h3 id=\"2-3-DeepSeek-R1-模型结构分析\"><a href=\"#2-3-DeepSeek-R1-模型结构分析\" class=\"headerlink\" title=\"2.3 DeepSeek-R1 模型结构分析\"></a>2.3 DeepSeek-R1 模型结构分析</h3><p>针对 DeepSeek-R1 模型,我们首先分析其模型结构及显存占用分布（参见图 3 和图 4）。</p>\n<img src=\"/images/Deepseek细粒度并行优化/image-20260202201915235.png\" alt=\"image-20260202201915235\" style=\"zoom:50%;\" />\n\n<img src=\"/images/Deepseek细粒度并行优化/image-20260202201955025.png\" alt=\"image-20260202201955025\" style=\"zoom:50%;\" />\n\n<h4 id=\"关键模块分析\"><a href=\"#关键模块分析\" class=\"headerlink\" title=\"关键模块分析\"></a>关键模块分析</h4><p>通过分析,我们识别出以下四个关键模块作为细粒度张量并行的优化对象:</p>\n<h5 id=\"1-O-proj（Attention-输出矩阵）\"><a href=\"#1-O-proj（Attention-输出矩阵）\" class=\"headerlink\" title=\"1. O_proj（Attention 输出矩阵）\"></a>1. O_proj（Attention 输出矩阵）</h5><ul>\n<li><strong>权重规模</strong>: 6.67 GB（占 Attention 模块 10.6 GB 显存的 62.9%）</li>\n<li><strong>分布特征</strong>: 分布在 61 层,单层权重约 117 MB</li>\n<li><strong>访存特征</strong>: 实际 GEMM 访存量为 117 MB&#x2F;层,相对适中</li>\n<li><strong>优化潜力</strong>: 显存优化潜力大,但需权衡通信开销</li>\n</ul>\n<h5 id=\"2-LM-Head（语言模型输出头）\"><a href=\"#2-LM-Head（语言模型输出头）\" class=\"headerlink\" title=\"2. LM Head（语言模型输出头）\"></a>2. LM Head（语言模型输出头）</h5><ul>\n<li><strong>权重规模</strong>: 1.72 GB</li>\n<li><strong>访存特征</strong>: GEMM 访存量为 1.72 GB,带来巨大访存开销</li>\n<li><strong>优化潜力</strong>: 高,访存密集型操作,切分收益明显</li>\n</ul>\n<h5 id=\"3-Embedding（词嵌入层）\"><a href=\"#3-Embedding（词嵌入层）\" class=\"headerlink\" title=\"3. Embedding（词嵌入层）\"></a>3. Embedding（词嵌入层）</h5><ul>\n<li><strong>权重规模</strong>: 1.72 GB</li>\n<li><strong>计算特征</strong>: 非 GEMM 运算,采用查表映射（table lookup）</li>\n<li><strong>访存特征</strong>: 引入巨大的访存开销</li>\n<li><strong>优化潜力</strong>: 高,通过切分可显著降低访存压力</li>\n</ul>\n<h5 id=\"4-Dense-FFN（前馈神经网络）\"><a href=\"#4-Dense-FFN（前馈神经网络）\" class=\"headerlink\" title=\"4. Dense FFN（前馈神经网络）\"></a>4. Dense FFN（前馈神经网络）</h5><ul>\n<li><strong>权重规模</strong>: 1.11 GB（仅存在于前三层）</li>\n<li><strong>访存特征</strong>: 单层访存开销为 378 MB,相对较大</li>\n<li><strong>优化潜力</strong>: 中等,访存开销足以覆盖通信成本</li>\n</ul>\n<h4 id=\"面临的技术挑战\"><a href=\"#面临的技术挑战\" class=\"headerlink\" title=\"面临的技术挑战\"></a>面临的技术挑战</h4><p>在确定优化目标模块后,我们需要解决以下关键问题:</p>\n<ol>\n<li><strong>通信策略设计</strong><ul>\n<li>不同模块的计算特性各异（升维&#x2F;降维、单层&#x2F;双层 MLP、矩阵乘&#x2F;查表）</li>\n<li>需要针对性设计通信模式</li>\n<li>需要建立通信时间的理论模型,以确保最佳通信效率</li>\n</ul>\n</li>\n<li><strong>切分粒度确定</strong><ul>\n<li>需要考虑具体集群环境的特性</li>\n<li>需要评估集群内部的通信效率</li>\n<li>需要判断是否具备高速通信能力（如 NVLink、IB 等）</li>\n</ul>\n</li>\n<li><strong>精度保证</strong><ul>\n<li>TP 切分会引入 Reduce 操作</li>\n<li>需要确保数值精度不会显著下降</li>\n<li>需要验证最终推理结果的正确性</li>\n</ul>\n</li>\n</ol>\n<p>为了探索不同场景下的切分方式,我开发了一个通用性 demo,可灵活支持各类切分策略与通信模式的组合: <a href=\"https://github.com/zzhx1/CustomTP_Demo\">https://github.com/zzhx1/CustomTP_Demo</a></p>\n<hr>\n<h2 id=\"3-技术方案设计\"><a href=\"#3-技术方案设计\" class=\"headerlink\" title=\"3. 技术方案设计\"></a>3. 技术方案设计</h2><p>基于上述分析,我们针对四个关键模块分别设计了细粒度张量并行切分策略。</p>\n<h3 id=\"3-1-O-proj-矩阵切分方案\"><a href=\"#3-1-O-proj-矩阵切分方案\" class=\"headerlink\" title=\"3.1 O_proj 矩阵切分方案\"></a>3.1 O_proj 矩阵切分方案</h3><p><strong>社区 PR</strong>: <a href=\"https://github.com/vllm-project/vllm-ascend/pull/2167/commits/a675b1c42ac2a3e14904b2a3b52f9f5f37312ac0\">feat: oproj tensor parallelism in pure DP and graph-mode scenarios</a></p>\n<h4 id=\"切分策略\"><a href=\"#切分策略\" class=\"headerlink\" title=\"切分策略\"></a>切分策略</h4><p>采用 <strong>All-to-All + 行切分矩阵乘 + Reduce-Scatter</strong> 的三阶段策略:</p>\n<ol>\n<li><strong>All-to-All</strong>: 在 DP 组间重新分布激活值</li>\n<li><strong>行切分 GEMM</strong>: 各计算卡负责权重矩阵的不同行切片</li>\n<li><strong>Reduce-Scatter</strong>: 聚合并分散计算结果</li>\n</ol>\n<h4 id=\"实现流程\"><a href=\"#实现流程\" class=\"headerlink\" title=\"实现流程\"></a>实现流程</h4><img src=\"/images/Deepseek细粒度并行优化/1765984854415-8c92bb5b-773d-40bf-ae91-0f3c183b4ad9.png\" alt=\"1765984854415-8c92bb5b-773d-40bf-ae91-0f3c183b4ad9\" style=\"zoom:50%;\" />\n\n<p><strong>关键设计要点</strong>:</p>\n<ul>\n<li>利用 Attention 输出的高维特征,通过行切分充分利用各计算卡</li>\n<li>All-to-All 确保数据正确分布到对应的计算卡</li>\n<li>Reduce-Scatter 高效完成结果聚合,避免全局通信瓶颈</li>\n</ul>\n<h3 id=\"3-2-LM-Head-矩阵切分方案\"><a href=\"#3-2-LM-Head-矩阵切分方案\" class=\"headerlink\" title=\"3.2 LM Head 矩阵切分方案\"></a>3.2 LM Head 矩阵切分方案</h3><p><strong>社区 PR</strong>: <a href=\"https://github.com/vllm-project/vllm-ascend/pull/2309\">Feat: Add custom lmhead tensor model parallel</a></p>\n<h4 id=\"切分策略-1\"><a href=\"#切分策略-1\" class=\"headerlink\" title=\"切分策略\"></a>切分策略</h4><p>采用 <strong>All-Gather + 列切分矩阵乘 + All-to-All</strong> 的三阶段策略:</p>\n<ol>\n<li><strong>All-Gather</strong>: 收集完整的输入激活值</li>\n<li><strong>列切分 GEMM</strong>: 各计算卡负责权重矩阵的不同列切片</li>\n<li><strong>All-to-All</strong>: 重新分布输出结果</li>\n</ol>\n<h4 id=\"实现流程-1\"><a href=\"#实现流程-1\" class=\"headerlink\" title=\"实现流程\"></a>实现流程</h4><img src=\"/images/Deepseek细粒度并行优化/1766036708163-c76d1b1a-8375-44b2-af90-51ae6bc16d0a.png\" alt=\"1766036708163-c76d1b1a-8375-44b2-af90-51ae6bc16d0a\" style=\"zoom:50%;\" />\n\n<p><strong>关键设计要点</strong>:</p>\n<ul>\n<li>LM Head 执行词表映射,输出维度等于词表大小</li>\n<li>列切分使得各卡计算不同词汇的 logits</li>\n<li>All-to-All 保证最终输出的正确性</li>\n</ul>\n<h3 id=\"3-3-Embedding-矩阵切分方案\"><a href=\"#3-3-Embedding-矩阵切分方案\" class=\"headerlink\" title=\"3.3 Embedding 矩阵切分方案\"></a>3.3 Embedding 矩阵切分方案</h3><p><strong>社区 PR</strong>: <a href=\"https://github.com/vllm-project/vllm-ascend/pull/2616\">Feat: Add custom Embedding tensor model parallel</a></p>\n<h4 id=\"切分策略-2\"><a href=\"#切分策略-2\" class=\"headerlink\" title=\"切分策略\"></a>切分策略</h4><p>采用 <strong>All-Gather + 列切分查表 + Reduce-Scatter</strong> 的三阶段策略:</p>\n<ol>\n<li><strong>All-Gather</strong>: 收集完整的 token IDs</li>\n<li><strong>列切分查表</strong>: 各计算卡负责 Embedding 表的不同列切片</li>\n<li><strong>Reduce-Scatter</strong>: 聚合并分散 Embedding 向量</li>\n</ol>\n<h4 id=\"实现流程-2\"><a href=\"#实现流程-2\" class=\"headerlink\" title=\"实现流程\"></a>实现流程</h4><img src=\"/images/Deepseek细粒度并行优化/1766038523899-adf5d01b-a6a4-4f79-8f71-8c8313e55ae9.png\" alt=\"1766038523899-adf5d01b-a6a4-4f79-8f71-8c8313e55ae9\" style=\"zoom:50%;\" />\n\n<p><strong>关键设计要点</strong>:</p>\n<ul>\n<li>Embedding 操作为查表映射,非标准 GEMM</li>\n<li>列切分使得各卡存储 Embedding 表的不同特征维度</li>\n<li>Reduce-Scatter 完成特征聚合,输出完整的 Embedding 向量</li>\n</ul>\n<h3 id=\"3-4-Dense-FFN（MLP）切分方案\"><a href=\"#3-4-Dense-FFN（MLP）切分方案\" class=\"headerlink\" title=\"3.4 Dense FFN（MLP）切分方案\"></a>3.4 Dense FFN（MLP）切分方案</h3><p><strong>社区 PR</strong>: <a href=\"https://github.com/vllm-project/vllm-ascend/pull/4999\">Custom Dense FFN tensor parallelism</a></p>\n<h4 id=\"切分策略-3\"><a href=\"#切分策略-3\" class=\"headerlink\" title=\"切分策略\"></a>切分策略</h4><p>针对 DeepSeek 前三层的 Dense FFN,采用 <strong>All-Gather + 列切分 + 行切分 + Reduce-Scatter</strong> 的四阶段策略:</p>\n<ol>\n<li><strong>All-Gather</strong>: 收集完整的输入激活值</li>\n<li><strong>列切分 GEMM（第一层）</strong>: 升维变换,各卡负责不同隐藏单元</li>\n<li><strong>行切分 GEMM（第二层）</strong>: 降维变换,各卡负责不同输入特征</li>\n<li><strong>Reduce-Scatter</strong>: 聚合并分散最终输出</li>\n</ol>\n<h4 id=\"实现流程-3\"><a href=\"#实现流程-3\" class=\"headerlink\" title=\"实现流程\"></a>实现流程</h4><img src=\"/images/Deepseek细粒度并行优化/1766039139599-0e8f3bbd-7d96-4c6a-8a8f-80cade8c0bd6.png\" alt=\"1766039139599-0e8f3bbd-7d96-4c6a-8a8f-80cade8c0bd6\" style=\"zoom:50%;\" />\n\n<p><strong>关键设计要点</strong>:</p>\n<ul>\n<li>FFN 包含两次矩阵乘法（升维+降维）</li>\n<li>第一层列切分:各卡计算中间隐藏层的不同部分</li>\n<li>第二层行切分:利用第一层的切分结果,减少通信</li>\n<li>仅需在首尾进行通信,中间计算完全并行</li>\n</ul>\n<hr>\n<h2 id=\"4-实验验证与性能分析\"><a href=\"#4-实验验证与性能分析\" class=\"headerlink\" title=\"4. 实验验证与性能分析\"></a>4. 实验验证与性能分析</h2><h3 id=\"4-1-实验环境\"><a href=\"#4-1-实验环境\" class=\"headerlink\" title=\"4.1 实验环境\"></a>4.1 实验环境</h3><ul>\n<li><strong>硬件平台</strong>: 昇腾 A2 和 A3</li>\n<li><strong>模型</strong>: DeepSeek-R1</li>\n<li><strong>测试节点</strong>: Decode 节点</li>\n<li><strong>TP 配置</strong>: 细粒度切分规模为 8（TP&#x3D;8）</li>\n</ul>\n<h3 id=\"4-2-实验结果\"><a href=\"#4-2-实验结果\" class=\"headerlink\" title=\"4.2 实验结果\"></a>4.2 实验结果</h3><h4 id=\"各模块性能收益统计\"><a href=\"#各模块性能收益统计\" class=\"headerlink\" title=\"各模块性能收益统计\"></a>各模块性能收益统计</h4><table>\n<thead>\n<tr>\n<th>模块</th>\n<th>切分配置</th>\n<th>显存收益</th>\n<th>TPOT 收益<br>（batch&#x3D;24）</th>\n<th>收益分析</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>O_proj</strong></td>\n<td>TP&#x3D;8</td>\n<td><strong>5.8 GB</strong></td>\n<td><strong>-1.5 ms</strong>（劣化）</td>\n<td>显存收益显著,但通信开销导致 TPOT 劣化</td>\n</tr>\n<tr>\n<td><strong>LM Head</strong></td>\n<td>TP&#x3D;8</td>\n<td><strong>1.51 GB</strong></td>\n<td><strong>+1.2 ms</strong>（优化）</td>\n<td>访存密集型,切分显著提升性能</td>\n</tr>\n<tr>\n<td><strong>Embedding</strong></td>\n<td>TP&#x3D;8</td>\n<td><strong>1.51 GB</strong></td>\n<td><strong>+1.0 ms</strong>（优化）</td>\n<td>查表访存优化效果明显</td>\n</tr>\n<tr>\n<td><strong>Dense FFN</strong></td>\n<td>TP&#x3D;8</td>\n<td><strong>0.9 GB</strong></td>\n<td><strong>+1.0 ms</strong>（优化）</td>\n<td>访存优化覆盖通信成本</td>\n</tr>\n<tr>\n<td><strong>总计</strong></td>\n<td>-</td>\n<td><strong>9.72 GB</strong></td>\n<td><strong>~+1 ms</strong>（净优化）</td>\n<td>整体显存大幅降低,TPOT 略有提升</td>\n</tr>\n</tbody></table>\n<h3 id=\"4-3-关键模块深度分析\"><a href=\"#4-3-关键模块深度分析\" class=\"headerlink\" title=\"4.3 关键模块深度分析\"></a>4.3 关键模块深度分析</h3><h4 id=\"O-proj-模块分析\"><a href=\"#O-proj-模块分析\" class=\"headerlink\" title=\"O_proj 模块分析\"></a>O_proj 模块分析</h4><p><strong>显存收益</strong>:</p>\n<ul>\n<li>单模块收益最大,达到 5.8 GB</li>\n<li>占 Attention 模块显存的 62.9%</li>\n</ul>\n<p><strong>TPOT 劣化原因</strong>:</p>\n<ul>\n<li>单层权重仅 117 MB,访存压力本身不高</li>\n<li>TP 切分引入了两次 AllReduce 通信</li>\n<li>通信开销（~1.5 ms）无法被访存优化所抵消</li>\n</ul>\n<p><strong>适用场景</strong>:</p>\n<ul>\n<li>显存受限场景,需要大幅降低显存占用</li>\n<li>对 TPOT 要求不极致苛刻的应用</li>\n</ul>\n<h4 id=\"LM-Head-模块分析\"><a href=\"#LM-Head-模块分析\" class=\"headerlink\" title=\"LM Head 模块分析\"></a>LM Head 模块分析</h4><p><strong>性能提升关键因素</strong>:</p>\n<ul>\n<li>原始权重为 1.7 GB,访存密集度极高</li>\n<li>单次推理需读取完整 1.7 GB 权重</li>\n<li>TP 切分显著缓解访存瓶颈</li>\n</ul>\n<p><strong>综合收益</strong>:</p>\n<ul>\n<li>显存节省 1.51 GB</li>\n<li>TPOT 优化 1.2 ms</li>\n<li>性能-显存双重收益</li>\n</ul>\n<h4 id=\"Embedding-模块分析\"><a href=\"#Embedding-模块分析\" class=\"headerlink\" title=\"Embedding 模块分析\"></a>Embedding 模块分析</h4><p><strong>特殊性</strong>:</p>\n<ul>\n<li>计算方式为查表映射,而非标准 GEMM</li>\n<li>访存模式与 LM Head 类似,访存压力大</li>\n</ul>\n<p><strong>优化效果</strong>:</p>\n<ul>\n<li>显存节省 1.51 GB（与 LM Head 对称）</li>\n<li>TPOT 优化 1.0 ms</li>\n<li>查表访存优化效果显著</li>\n</ul>\n<h4 id=\"Dense-FFN-模块分析\"><a href=\"#Dense-FFN-模块分析\" class=\"headerlink\" title=\"Dense FFN 模块分析\"></a>Dense FFN 模块分析</h4><p><strong>权重特征</strong>:</p>\n<ul>\n<li>单层权重体积相对较小（1.11 GB &#x2F; 3 层）</li>\n<li>单层访存开销为 378 MB</li>\n</ul>\n<p><strong>优化有效性</strong>:</p>\n<ul>\n<li>访存优化足以覆盖通信成本</li>\n<li>TPOT 优化约 1.0 ms</li>\n<li>对前三层的推理性能提升明显</li>\n</ul>\n<h3 id=\"4-4-整体评估\"><a href=\"#4-4-整体评估\" class=\"headerlink\" title=\"4.4 整体评估\"></a>4.4 整体评估</h3><h4 id=\"显存优化总结\"><a href=\"#显存优化总结\" class=\"headerlink\" title=\"显存优化总结\"></a>显存优化总结</h4><p>细粒度 TP 切分（TP&#x3D;8）在整体上显著降低 Decode 节点显存占用:</p>\n<ul>\n<li><strong>总显存节省</strong>: 9.72 GB</li>\n<li><strong>相对降幅</strong>: 显著提升 GPU 利用率</li>\n<li><strong>应用价值</strong>: 可支持更大 batch size,提升系统吞吐量</li>\n</ul>\n<h4 id=\"TPOT-性能总结\"><a href=\"#TPOT-性能总结\" class=\"headerlink\" title=\"TPOT 性能总结\"></a>TPOT 性能总结</h4><p>整体 TPOT 性能略有提升:</p>\n<ul>\n<li><strong>净优化</strong>: ~1 ms（batch&#x3D;24）</li>\n<li><strong>关键贡献者</strong>: LM Head（+1.2 ms）、Embedding（+1.0 ms）、Dense FFN（+1.0 ms）</li>\n<li><strong>主要损耗</strong>: O_proj（-1.5 ms）</li>\n</ul>\n<h4 id=\"策略建议\"><a href=\"#策略建议\" class=\"headerlink\" title=\"策略建议\"></a>策略建议</h4><p>基于实验结果,我们提出以下部署策略建议:</p>\n<ol>\n<li><strong>显存受限场景（推荐全部启用）</strong><ul>\n<li>所有四个模块均启用细粒度 TP</li>\n<li>获得最大显存收益（9.72 GB）</li>\n<li>接受小幅 TPOT 开销（净优化 ~1 ms 或持平）</li>\n</ul>\n</li>\n<li><strong>TPOT 敏感场景（选择性启用）</strong><ul>\n<li>启用 LM Head + Embedding + Dense FFN</li>\n<li>关闭 O_proj 切分</li>\n<li>平衡显存节省（3.92 GB）与 TPOT 优化（+3.2 ms）</li>\n</ul>\n</li>\n<li><strong>平衡场景（默认推荐）</strong><ul>\n<li>启用所有模块</li>\n<li>在实际部署中根据具体负载动态调整</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h2 id=\"5-总结与展望\"><a href=\"#5-总结与展望\" class=\"headerlink\" title=\"5. 总结与展望\"></a>5. 总结与展望</h2><h3 id=\"5-1-核心贡献\"><a href=\"#5-1-核心贡献\" class=\"headerlink\" title=\"5.1 核心贡献\"></a>5.1 核心贡献</h3><p>本工作针对 DeepSeek-R1 模型 Decode 阶段的性能瓶颈,提出了细粒度张量并行优化方案:</p>\n<ol>\n<li><strong>系统性分析</strong>: 识别出 O_proj、LM Head、Embedding、Dense FFN 四个关键瓶颈模块</li>\n<li><strong>定制化策略</strong>: 针对不同模块的计算特性,设计差异化的 TP 切分与通信方案</li>\n<li><strong>显著收益</strong>: 在昇腾 A2&#x2F;A3 平台上验证,实现 9.72 GB 显存节省和 ~1 ms TPOT 净优化</li>\n<li><strong>开源贡献</strong>: 所有优化方案已合入 vllm-ascend 社区</li>\n</ol>\n<h3 id=\"5-2-适用场景\"><a href=\"#5-2-适用场景\" class=\"headerlink\" title=\"5.2 适用场景\"></a>5.2 适用场景</h3><p>该优化方案特别适用于以下场景:</p>\n<ul>\n<li>显存受限的大规模模型部署</li>\n<li>需要高并发支持的在线推理服务</li>\n<li>PD 分离架构的 Decode 节点优化</li>\n</ul>\n<h3 id=\"5-3-未来工作\"><a href=\"#5-3-未来工作\" class=\"headerlink\" title=\"5.3 未来工作\"></a>5.3 未来工作</h3><ol>\n<li><strong>扩展到更多模型</strong>: 验证在其他 Transformer 架构（如Qwen、GLM）上的适用性</li>\n<li><strong>通信-计算融合</strong>: 进一步优化通信与计算的重叠,降低端到端延迟</li>\n<li><strong>硬件适配</strong>: 针对不同硬件平台（GPU、NPU）优化通信原语</li>\n<li><strong>vllm 主社区适配</strong></li>\n</ol>\n<hr>\n<h2 id=\"附录-Q-A\"><a href=\"#附录-Q-A\" class=\"headerlink\" title=\"附录: Q&amp;A\"></a>附录: Q&amp;A</h2><h3 id=\"Q1-为什么-O-proj-切分会导致-TPOT-劣化\"><a href=\"#Q1-为什么-O-proj-切分会导致-TPOT-劣化\" class=\"headerlink\" title=\"Q1: 为什么 O_proj 切分会导致 TPOT 劣化?\"></a>Q1: 为什么 O_proj 切分会导致 TPOT 劣化?</h3><p><strong>A</strong>: O_proj 虽然权重规模大（6.67 GB），但分布在 61 层，单层仅 117 MB。在 Decode 阶段，单层 117 MB 的访存压力相对适中，无法成为显著瓶颈。然而，TP 切分引入了两次通信（前后各一次），通信开销超过了访存优化带来的收益，因此整体 TPOT 劣化。</p>\n<h3 id=\"Q2-如何确定最优的-TP-切分粒度\"><a href=\"#Q2-如何确定最优的-TP-切分粒度\" class=\"headerlink\" title=\"Q2: 如何确定最优的 TP 切分粒度?\"></a>Q2: 如何确定最优的 TP 切分粒度?</h3><p><strong>A</strong>: 最优 TP 粒度取决于多个因素:</p>\n<ul>\n<li><strong>集群通信带宽</strong>: 高速互联（如 NVLink、IB）支持更大的 TP 粒度</li>\n<li><strong>模块权重规模</strong>: 越大的权重矩阵，越适合更大的 TP</li>\n<li><strong>Batch size</strong>: 更大的 batch size 可以摊销通信开销</li>\n<li><strong>实验验证</strong>: 建议通过 profiling 在实际环境中测试不同 TP 粒度的性能</li>\n</ul>\n<h3 id=\"Q3-增大batch-size-是否会进一步的劣化\"><a href=\"#Q3-增大batch-size-是否会进一步的劣化\" class=\"headerlink\" title=\"Q3: 增大batch size 是否会进一步的劣化\"></a>Q3: 增大batch size 是否会进一步的劣化</h3><p><strong>A</strong>: 理论上，batch size的增加，必然带来通信时间的增加，但是deocde 的激活值非常小，短时间无法达到通信密集，可预见的事通信时间会缓慢增加，直到达到通信密集之后，通信时间会显著增加。</p>\n<h3 id=\"Q4-该方案是否适用于-Prefill-阶段\"><a href=\"#Q4-该方案是否适用于-Prefill-阶段\" class=\"headerlink\" title=\"Q4: 该方案是否适用于 Prefill 阶段?\"></a>Q4: 该方案是否适用于 Prefill 阶段?</h3><p><strong>A</strong>: 不完全适用。Prefill 阶段的特征与 Decode 阶段截然不同: Prefill 是 compute-bound，适合全局大 TP，Decode 是 memory-bound，需要细粒度优化。细粒度 TP 主要针对 Decode 阶段的访存瓶颈，在 Prefill 阶段可能无法带来收益甚至引入额外开销。</p>\n<h3 id=\"Q5-该方案是否适合混布\"><a href=\"#Q5-该方案是否适合混布\" class=\"headerlink\" title=\"Q5: 该方案是否适合混布?\"></a>Q5: 该方案是否适合混布?</h3><p><strong>A</strong>: 混布是否开启该方案，必须考虑在prefill引入该方案造成的影响，目前不推荐o_porj和mlp切分在混布情况下使用，但是可以开启embedding和lmhead切分，这两个操作不管是prefill或者decode其激活值的大小都非常的小，并且整个模型只有一次计算，因此在混布情况下开启这两个切分是没有问题的。</p>\n<h3 id=\"Q6-该方案在vllm-ascend中如何使用\"><a href=\"#Q6-该方案在vllm-ascend中如何使用\" class=\"headerlink\" title=\"Q6: 该方案在vllm-ascend中如何使用\"></a>Q6: 该方案在vllm-ascend中如何使用</h3><p><strong>A</strong>: 详细请查看 <a href=\"https://docs.vllm.ai/projects/ascend/en/latest/user_guide/feature_guide/Fine_grained_TP\">https://docs.vllm.ai/projects/ascend/en/latest/user_guide/feature_guide/Fine_grained_TP</a>.</p>\n","excerpt":"","more":"<h1 id=\"DeepSeek-R1-模型-Decode-阶段细粒度张量并行优化\"><a href=\"#DeepSeek-R1-模型-Decode-阶段细粒度张量并行优化\" class=\"headerlink\" title=\"DeepSeek-R1 模型 Decode 阶段细粒度张量并行优化\"></a>DeepSeek-R1 模型 Decode 阶段细粒度张量并行优化</h1><blockquote>\n<p>在大规模语言模型推理中，Decode 阶段的性能优化面临独特挑战：单 token 生成的 memory-bound 特性使得传统纯数据并行策略在显存占用和访存效率上存在瓶颈。 本文针对 DeepSeek-R1 模型，提出了细粒度张量并行优化方案。通过对 O_proj、LM Head、Embedding 和 Dense FFN 四个关键模块实施跨 DP 组的定制化切分策略，在昇腾平台上实现了 <strong>9.72 GB 显存节省</strong> 和约 <strong>2 ms TPOT 优化</strong>，显著提升了 Decode 节点的并发能力。所有优化已开源并合入 vllm-ascend 社区。</p>\n</blockquote>\n<h2 id=\"1-背景\"><a href=\"#1-背景\" class=\"headerlink\" title=\"1. 背景\"></a>1. 背景</h2><h3 id=\"1-1-PD-分离架构概述\"><a href=\"#1-1-PD-分离架构概述\" class=\"headerlink\" title=\"1.1 PD 分离架构概述\"></a>1.1 PD 分离架构概述</h3><p>随着 Prefill-Decoding（PD）分离架构的兴起，vLLM 及其昇腾后端 vllm-ascend 正在积极推进对该架构的深度适配。PD 分离架构通过解耦 Prefill 阶段与 Decode 阶段，并针对各自的计算与通信特性进行独立优化，可以充分挖掘端到端推理性能潜力。</p>\n<h3 id=\"1-2-分布式并行策略差异\"><a href=\"#1-2-分布式并行策略差异\" class=\"headerlink\" title=\"1.2 分布式并行策略差异\"></a>1.2 分布式并行策略差异</h3><p>在分布式推理系统中,并行策略是实现高效 PD 分离的核心要素。以 DeepSeek 等大规模 MoE（Mixture of Experts）模型为例,通常采用**数据并行（DP）+ 张量并行（TP）+ 专家并行（EP）**的混合并行方案。然而,Prefill 与 Decode 两个阶段在计算模式、内存访问模式和通信开销方面存在显著差异,因此需要采用截然不同的并行策略设计:</p>\n<h4 id=\"Prefill-阶段特征\"><a href=\"#Prefill-阶段特征\" class=\"headerlink\" title=\"Prefill 阶段特征\"></a>Prefill 阶段特征</h4><ul>\n<li><strong>长序列处理</strong>:输入序列长度较大（long seqlen）</li>\n<li><strong>计算密集型</strong>:属于 compute-bound 任务</li>\n<li><strong>最优策略</strong>:增大 TP 规模具有双重优势<ul>\n<li>降低单卡显存占用</li>\n<li>将大规模计算任务分散到多张计算卡,充分发挥并行计算能力</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"Decode-阶段特征\"><a href=\"#Decode-阶段特征\" class=\"headerlink\" title=\"Decode 阶段特征\"></a>Decode 阶段特征</h4><ul>\n<li><strong>固定序列长度</strong>:每次处理的序列长度为 1</li>\n<li><strong>小批量处理</strong>:每次调度的 batch size 通常较小（数十量级）</li>\n<li><strong>访存密集型</strong>:呈现明显的 memory-bound 特征,主要瓶颈包括:<ol>\n<li>计算量相对较小</li>\n<li>需要支持高并发推理</li>\n</ol>\n</li>\n<li><strong>现有策略问题</strong>:Decode 节点通常采用**全 DP（纯数据并行）**策略<ul>\n<li>要求每张计算卡存储完整的模型权重（非 MoE 场景）</li>\n<li>矩阵乘法运算时需读取更大的权重数据量</li>\n<li>相比 Prefill 阶段,访存开销显著增加</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h2 id=\"2-优化动机\"><a href=\"#2-优化动机\" class=\"headerlink\" title=\"2. 优化动机\"></a>2. 优化动机</h2><p>通过系统分析,我们发现 Decode 阶段的性能瓶颈主要来自以下两个方面:</p>\n<h3 id=\"2-1-性能瓶颈分析\"><a href=\"#2-1-性能瓶颈分析\" class=\"headerlink\" title=\"2.1 性能瓶颈分析\"></a>2.1 性能瓶颈分析</h3><h4 id=\"瓶颈-1-访存开销过大\"><a href=\"#瓶颈-1-访存开销过大\" class=\"headerlink\" title=\"瓶颈 1: 访存开销过大\"></a>瓶颈 1: 访存开销过大</h4><ul>\n<li><strong>KV Cache 访存</strong>:频繁读取 KV Cache 带来的访存开销</li>\n<li><strong>完整权重加载</strong>:纯 DP 策略导致需读取完整模型权重</li>\n<li><strong>影响</strong>:矩阵乘法性能下降,TPOT（Time Per Output Token）增加</li>\n</ul>\n<h4 id=\"瓶颈-2-显存占用受限\"><a href=\"#瓶颈-2-显存占用受限\" class=\"headerlink\" title=\"瓶颈 2: 显存占用受限\"></a>瓶颈 2: 显存占用受限</h4><ul>\n<li><strong>KV Cache 空间占用</strong>:限制了可并发处理的序列数量</li>\n<li><strong>完整权重存储</strong>:纯 DP 导致单卡权重负载过大</li>\n<li><strong>影响</strong>:无法增大 batch size,整体吞吐量受限</li>\n</ul>\n<h3 id=\"2-2-优化思路-”以通信换存储”\"><a href=\"#2-2-优化思路-”以通信换存储”\" class=\"headerlink\" title=\"2.2 优化思路:”以通信换存储”\"></a>2.2 优化思路:”以通信换存储”</h3><h4 id=\"设计理念\"><a href=\"#设计理念\" class=\"headerlink\" title=\"设计理念\"></a>设计理念</h4><p>在现代 Transformer 模型结构中,不同 Linear 层的权重规模存在显著差异,其计算强度也随之不同。在 Decode 阶段,由于输入序列长度固定为 1,计算高度受限于内存带宽（memory-bound）。此时,大规模 Linear 层会带来两方面性能瓶颈:</p>\n<ol>\n<li><strong>显存压力</strong>:完整加载大权重矩阵导致单卡显存占用过高,限制 batch size 或阻碍模型部署</li>\n<li><strong>访存开销</strong>:GEMM（通用矩阵乘法）操作需从 HBM（High Bandwidth Memory）加载大量权重数据,加剧内存带宽竞争,降低单步推理速度,恶化整体 TPOT</li>\n</ol>\n<h4 id=\"优化策略\"><a href=\"#优化策略\" class=\"headerlink\" title=\"优化策略\"></a>优化策略</h4><p>如图 1 所示,假设 OP2 代表一个典型的大型 Linear 层。若其张量并行策略完全遵循全局统一的纯 DP 配置,则无法有效缓解上述瓶颈。</p>\n<img src=\"/images/Deepseek细粒度并行优化/image-20260202201605950.png\" alt=\"image-20260202201605950\" style=\"zoom:50%;\" />\n\n<p>为此,我们提出对 OP2 这类关键大权重模块启用<strong>跨 DP 并行组的细粒度张量并行（Fine-Grained Tensor Parallelism）</strong>。如图 2 所示,通过在 DP 组之间对 OP2 的权重进行切分与分布式计算,可显著降低:</p>\n<ul>\n<li>单卡显存占用</li>\n<li>GEMM 访存量</li>\n</ul>\n<p>代价是需要在 GEMM 前后引入对跨 DP 的激活值通信,以保证计算精度正确性。</p>\n<img src=\"/images/Deepseek细粒度并行优化/image-20260202201646610.png\" alt=\"image-20260202201646610\" style=\"zoom:50%;\" />\n\n<h4 id=\"预期收益\"><a href=\"#预期收益\" class=\"headerlink\" title=\"预期收益\"></a>预期收益</h4><ul>\n<li><strong>显存优化</strong>:降低需加载的权重大小,提高整体并发能力,增强系统吞吐</li>\n<li><strong>GEMM 性能提升</strong>:减少访存量,加速矩阵乘法运算,改善 TPOT 表现</li>\n</ul>\n<h3 id=\"2-3-DeepSeek-R1-模型结构分析\"><a href=\"#2-3-DeepSeek-R1-模型结构分析\" class=\"headerlink\" title=\"2.3 DeepSeek-R1 模型结构分析\"></a>2.3 DeepSeek-R1 模型结构分析</h3><p>针对 DeepSeek-R1 模型,我们首先分析其模型结构及显存占用分布（参见图 3 和图 4）。</p>\n<img src=\"/images/Deepseek细粒度并行优化/image-20260202201915235.png\" alt=\"image-20260202201915235\" style=\"zoom:50%;\" />\n\n<img src=\"/images/Deepseek细粒度并行优化/image-20260202201955025.png\" alt=\"image-20260202201955025\" style=\"zoom:50%;\" />\n\n<h4 id=\"关键模块分析\"><a href=\"#关键模块分析\" class=\"headerlink\" title=\"关键模块分析\"></a>关键模块分析</h4><p>通过分析,我们识别出以下四个关键模块作为细粒度张量并行的优化对象:</p>\n<h5 id=\"1-O-proj（Attention-输出矩阵）\"><a href=\"#1-O-proj（Attention-输出矩阵）\" class=\"headerlink\" title=\"1. O_proj（Attention 输出矩阵）\"></a>1. O_proj（Attention 输出矩阵）</h5><ul>\n<li><strong>权重规模</strong>: 6.67 GB（占 Attention 模块 10.6 GB 显存的 62.9%）</li>\n<li><strong>分布特征</strong>: 分布在 61 层,单层权重约 117 MB</li>\n<li><strong>访存特征</strong>: 实际 GEMM 访存量为 117 MB&#x2F;层,相对适中</li>\n<li><strong>优化潜力</strong>: 显存优化潜力大,但需权衡通信开销</li>\n</ul>\n<h5 id=\"2-LM-Head（语言模型输出头）\"><a href=\"#2-LM-Head（语言模型输出头）\" class=\"headerlink\" title=\"2. LM Head（语言模型输出头）\"></a>2. LM Head（语言模型输出头）</h5><ul>\n<li><strong>权重规模</strong>: 1.72 GB</li>\n<li><strong>访存特征</strong>: GEMM 访存量为 1.72 GB,带来巨大访存开销</li>\n<li><strong>优化潜力</strong>: 高,访存密集型操作,切分收益明显</li>\n</ul>\n<h5 id=\"3-Embedding（词嵌入层）\"><a href=\"#3-Embedding（词嵌入层）\" class=\"headerlink\" title=\"3. Embedding（词嵌入层）\"></a>3. Embedding（词嵌入层）</h5><ul>\n<li><strong>权重规模</strong>: 1.72 GB</li>\n<li><strong>计算特征</strong>: 非 GEMM 运算,采用查表映射（table lookup）</li>\n<li><strong>访存特征</strong>: 引入巨大的访存开销</li>\n<li><strong>优化潜力</strong>: 高,通过切分可显著降低访存压力</li>\n</ul>\n<h5 id=\"4-Dense-FFN（前馈神经网络）\"><a href=\"#4-Dense-FFN（前馈神经网络）\" class=\"headerlink\" title=\"4. Dense FFN（前馈神经网络）\"></a>4. Dense FFN（前馈神经网络）</h5><ul>\n<li><strong>权重规模</strong>: 1.11 GB（仅存在于前三层）</li>\n<li><strong>访存特征</strong>: 单层访存开销为 378 MB,相对较大</li>\n<li><strong>优化潜力</strong>: 中等,访存开销足以覆盖通信成本</li>\n</ul>\n<h4 id=\"面临的技术挑战\"><a href=\"#面临的技术挑战\" class=\"headerlink\" title=\"面临的技术挑战\"></a>面临的技术挑战</h4><p>在确定优化目标模块后,我们需要解决以下关键问题:</p>\n<ol>\n<li><strong>通信策略设计</strong><ul>\n<li>不同模块的计算特性各异（升维&#x2F;降维、单层&#x2F;双层 MLP、矩阵乘&#x2F;查表）</li>\n<li>需要针对性设计通信模式</li>\n<li>需要建立通信时间的理论模型,以确保最佳通信效率</li>\n</ul>\n</li>\n<li><strong>切分粒度确定</strong><ul>\n<li>需要考虑具体集群环境的特性</li>\n<li>需要评估集群内部的通信效率</li>\n<li>需要判断是否具备高速通信能力（如 NVLink、IB 等）</li>\n</ul>\n</li>\n<li><strong>精度保证</strong><ul>\n<li>TP 切分会引入 Reduce 操作</li>\n<li>需要确保数值精度不会显著下降</li>\n<li>需要验证最终推理结果的正确性</li>\n</ul>\n</li>\n</ol>\n<p>为了探索不同场景下的切分方式,我开发了一个通用性 demo,可灵活支持各类切分策略与通信模式的组合: <a href=\"https://github.com/zzhx1/CustomTP_Demo\">https://github.com/zzhx1/CustomTP_Demo</a></p>\n<hr>\n<h2 id=\"3-技术方案设计\"><a href=\"#3-技术方案设计\" class=\"headerlink\" title=\"3. 技术方案设计\"></a>3. 技术方案设计</h2><p>基于上述分析,我们针对四个关键模块分别设计了细粒度张量并行切分策略。</p>\n<h3 id=\"3-1-O-proj-矩阵切分方案\"><a href=\"#3-1-O-proj-矩阵切分方案\" class=\"headerlink\" title=\"3.1 O_proj 矩阵切分方案\"></a>3.1 O_proj 矩阵切分方案</h3><p><strong>社区 PR</strong>: <a href=\"https://github.com/vllm-project/vllm-ascend/pull/2167/commits/a675b1c42ac2a3e14904b2a3b52f9f5f37312ac0\">feat: oproj tensor parallelism in pure DP and graph-mode scenarios</a></p>\n<h4 id=\"切分策略\"><a href=\"#切分策略\" class=\"headerlink\" title=\"切分策略\"></a>切分策略</h4><p>采用 <strong>All-to-All + 行切分矩阵乘 + Reduce-Scatter</strong> 的三阶段策略:</p>\n<ol>\n<li><strong>All-to-All</strong>: 在 DP 组间重新分布激活值</li>\n<li><strong>行切分 GEMM</strong>: 各计算卡负责权重矩阵的不同行切片</li>\n<li><strong>Reduce-Scatter</strong>: 聚合并分散计算结果</li>\n</ol>\n<h4 id=\"实现流程\"><a href=\"#实现流程\" class=\"headerlink\" title=\"实现流程\"></a>实现流程</h4><img src=\"/images/Deepseek细粒度并行优化/1765984854415-8c92bb5b-773d-40bf-ae91-0f3c183b4ad9.png\" alt=\"1765984854415-8c92bb5b-773d-40bf-ae91-0f3c183b4ad9\" style=\"zoom:50%;\" />\n\n<p><strong>关键设计要点</strong>:</p>\n<ul>\n<li>利用 Attention 输出的高维特征,通过行切分充分利用各计算卡</li>\n<li>All-to-All 确保数据正确分布到对应的计算卡</li>\n<li>Reduce-Scatter 高效完成结果聚合,避免全局通信瓶颈</li>\n</ul>\n<h3 id=\"3-2-LM-Head-矩阵切分方案\"><a href=\"#3-2-LM-Head-矩阵切分方案\" class=\"headerlink\" title=\"3.2 LM Head 矩阵切分方案\"></a>3.2 LM Head 矩阵切分方案</h3><p><strong>社区 PR</strong>: <a href=\"https://github.com/vllm-project/vllm-ascend/pull/2309\">Feat: Add custom lmhead tensor model parallel</a></p>\n<h4 id=\"切分策略-1\"><a href=\"#切分策略-1\" class=\"headerlink\" title=\"切分策略\"></a>切分策略</h4><p>采用 <strong>All-Gather + 列切分矩阵乘 + All-to-All</strong> 的三阶段策略:</p>\n<ol>\n<li><strong>All-Gather</strong>: 收集完整的输入激活值</li>\n<li><strong>列切分 GEMM</strong>: 各计算卡负责权重矩阵的不同列切片</li>\n<li><strong>All-to-All</strong>: 重新分布输出结果</li>\n</ol>\n<h4 id=\"实现流程-1\"><a href=\"#实现流程-1\" class=\"headerlink\" title=\"实现流程\"></a>实现流程</h4><img src=\"/images/Deepseek细粒度并行优化/1766036708163-c76d1b1a-8375-44b2-af90-51ae6bc16d0a.png\" alt=\"1766036708163-c76d1b1a-8375-44b2-af90-51ae6bc16d0a\" style=\"zoom:50%;\" />\n\n<p><strong>关键设计要点</strong>:</p>\n<ul>\n<li>LM Head 执行词表映射,输出维度等于词表大小</li>\n<li>列切分使得各卡计算不同词汇的 logits</li>\n<li>All-to-All 保证最终输出的正确性</li>\n</ul>\n<h3 id=\"3-3-Embedding-矩阵切分方案\"><a href=\"#3-3-Embedding-矩阵切分方案\" class=\"headerlink\" title=\"3.3 Embedding 矩阵切分方案\"></a>3.3 Embedding 矩阵切分方案</h3><p><strong>社区 PR</strong>: <a href=\"https://github.com/vllm-project/vllm-ascend/pull/2616\">Feat: Add custom Embedding tensor model parallel</a></p>\n<h4 id=\"切分策略-2\"><a href=\"#切分策略-2\" class=\"headerlink\" title=\"切分策略\"></a>切分策略</h4><p>采用 <strong>All-Gather + 列切分查表 + Reduce-Scatter</strong> 的三阶段策略:</p>\n<ol>\n<li><strong>All-Gather</strong>: 收集完整的 token IDs</li>\n<li><strong>列切分查表</strong>: 各计算卡负责 Embedding 表的不同列切片</li>\n<li><strong>Reduce-Scatter</strong>: 聚合并分散 Embedding 向量</li>\n</ol>\n<h4 id=\"实现流程-2\"><a href=\"#实现流程-2\" class=\"headerlink\" title=\"实现流程\"></a>实现流程</h4><img src=\"/images/Deepseek细粒度并行优化/1766038523899-adf5d01b-a6a4-4f79-8f71-8c8313e55ae9.png\" alt=\"1766038523899-adf5d01b-a6a4-4f79-8f71-8c8313e55ae9\" style=\"zoom:50%;\" />\n\n<p><strong>关键设计要点</strong>:</p>\n<ul>\n<li>Embedding 操作为查表映射,非标准 GEMM</li>\n<li>列切分使得各卡存储 Embedding 表的不同特征维度</li>\n<li>Reduce-Scatter 完成特征聚合,输出完整的 Embedding 向量</li>\n</ul>\n<h3 id=\"3-4-Dense-FFN（MLP）切分方案\"><a href=\"#3-4-Dense-FFN（MLP）切分方案\" class=\"headerlink\" title=\"3.4 Dense FFN（MLP）切分方案\"></a>3.4 Dense FFN（MLP）切分方案</h3><p><strong>社区 PR</strong>: <a href=\"https://github.com/vllm-project/vllm-ascend/pull/4999\">Custom Dense FFN tensor parallelism</a></p>\n<h4 id=\"切分策略-3\"><a href=\"#切分策略-3\" class=\"headerlink\" title=\"切分策略\"></a>切分策略</h4><p>针对 DeepSeek 前三层的 Dense FFN,采用 <strong>All-Gather + 列切分 + 行切分 + Reduce-Scatter</strong> 的四阶段策略:</p>\n<ol>\n<li><strong>All-Gather</strong>: 收集完整的输入激活值</li>\n<li><strong>列切分 GEMM（第一层）</strong>: 升维变换,各卡负责不同隐藏单元</li>\n<li><strong>行切分 GEMM（第二层）</strong>: 降维变换,各卡负责不同输入特征</li>\n<li><strong>Reduce-Scatter</strong>: 聚合并分散最终输出</li>\n</ol>\n<h4 id=\"实现流程-3\"><a href=\"#实现流程-3\" class=\"headerlink\" title=\"实现流程\"></a>实现流程</h4><img src=\"/images/Deepseek细粒度并行优化/1766039139599-0e8f3bbd-7d96-4c6a-8a8f-80cade8c0bd6.png\" alt=\"1766039139599-0e8f3bbd-7d96-4c6a-8a8f-80cade8c0bd6\" style=\"zoom:50%;\" />\n\n<p><strong>关键设计要点</strong>:</p>\n<ul>\n<li>FFN 包含两次矩阵乘法（升维+降维）</li>\n<li>第一层列切分:各卡计算中间隐藏层的不同部分</li>\n<li>第二层行切分:利用第一层的切分结果,减少通信</li>\n<li>仅需在首尾进行通信,中间计算完全并行</li>\n</ul>\n<hr>\n<h2 id=\"4-实验验证与性能分析\"><a href=\"#4-实验验证与性能分析\" class=\"headerlink\" title=\"4. 实验验证与性能分析\"></a>4. 实验验证与性能分析</h2><h3 id=\"4-1-实验环境\"><a href=\"#4-1-实验环境\" class=\"headerlink\" title=\"4.1 实验环境\"></a>4.1 实验环境</h3><ul>\n<li><strong>硬件平台</strong>: 昇腾 A2 和 A3</li>\n<li><strong>模型</strong>: DeepSeek-R1</li>\n<li><strong>测试节点</strong>: Decode 节点</li>\n<li><strong>TP 配置</strong>: 细粒度切分规模为 8（TP&#x3D;8）</li>\n</ul>\n<h3 id=\"4-2-实验结果\"><a href=\"#4-2-实验结果\" class=\"headerlink\" title=\"4.2 实验结果\"></a>4.2 实验结果</h3><h4 id=\"各模块性能收益统计\"><a href=\"#各模块性能收益统计\" class=\"headerlink\" title=\"各模块性能收益统计\"></a>各模块性能收益统计</h4><table>\n<thead>\n<tr>\n<th>模块</th>\n<th>切分配置</th>\n<th>显存收益</th>\n<th>TPOT 收益<br>（batch&#x3D;24）</th>\n<th>收益分析</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>O_proj</strong></td>\n<td>TP&#x3D;8</td>\n<td><strong>5.8 GB</strong></td>\n<td><strong>-1.5 ms</strong>（劣化）</td>\n<td>显存收益显著,但通信开销导致 TPOT 劣化</td>\n</tr>\n<tr>\n<td><strong>LM Head</strong></td>\n<td>TP&#x3D;8</td>\n<td><strong>1.51 GB</strong></td>\n<td><strong>+1.2 ms</strong>（优化）</td>\n<td>访存密集型,切分显著提升性能</td>\n</tr>\n<tr>\n<td><strong>Embedding</strong></td>\n<td>TP&#x3D;8</td>\n<td><strong>1.51 GB</strong></td>\n<td><strong>+1.0 ms</strong>（优化）</td>\n<td>查表访存优化效果明显</td>\n</tr>\n<tr>\n<td><strong>Dense FFN</strong></td>\n<td>TP&#x3D;8</td>\n<td><strong>0.9 GB</strong></td>\n<td><strong>+1.0 ms</strong>（优化）</td>\n<td>访存优化覆盖通信成本</td>\n</tr>\n<tr>\n<td><strong>总计</strong></td>\n<td>-</td>\n<td><strong>9.72 GB</strong></td>\n<td><strong>~+1 ms</strong>（净优化）</td>\n<td>整体显存大幅降低,TPOT 略有提升</td>\n</tr>\n</tbody></table>\n<h3 id=\"4-3-关键模块深度分析\"><a href=\"#4-3-关键模块深度分析\" class=\"headerlink\" title=\"4.3 关键模块深度分析\"></a>4.3 关键模块深度分析</h3><h4 id=\"O-proj-模块分析\"><a href=\"#O-proj-模块分析\" class=\"headerlink\" title=\"O_proj 模块分析\"></a>O_proj 模块分析</h4><p><strong>显存收益</strong>:</p>\n<ul>\n<li>单模块收益最大,达到 5.8 GB</li>\n<li>占 Attention 模块显存的 62.9%</li>\n</ul>\n<p><strong>TPOT 劣化原因</strong>:</p>\n<ul>\n<li>单层权重仅 117 MB,访存压力本身不高</li>\n<li>TP 切分引入了两次 AllReduce 通信</li>\n<li>通信开销（~1.5 ms）无法被访存优化所抵消</li>\n</ul>\n<p><strong>适用场景</strong>:</p>\n<ul>\n<li>显存受限场景,需要大幅降低显存占用</li>\n<li>对 TPOT 要求不极致苛刻的应用</li>\n</ul>\n<h4 id=\"LM-Head-模块分析\"><a href=\"#LM-Head-模块分析\" class=\"headerlink\" title=\"LM Head 模块分析\"></a>LM Head 模块分析</h4><p><strong>性能提升关键因素</strong>:</p>\n<ul>\n<li>原始权重为 1.7 GB,访存密集度极高</li>\n<li>单次推理需读取完整 1.7 GB 权重</li>\n<li>TP 切分显著缓解访存瓶颈</li>\n</ul>\n<p><strong>综合收益</strong>:</p>\n<ul>\n<li>显存节省 1.51 GB</li>\n<li>TPOT 优化 1.2 ms</li>\n<li>性能-显存双重收益</li>\n</ul>\n<h4 id=\"Embedding-模块分析\"><a href=\"#Embedding-模块分析\" class=\"headerlink\" title=\"Embedding 模块分析\"></a>Embedding 模块分析</h4><p><strong>特殊性</strong>:</p>\n<ul>\n<li>计算方式为查表映射,而非标准 GEMM</li>\n<li>访存模式与 LM Head 类似,访存压力大</li>\n</ul>\n<p><strong>优化效果</strong>:</p>\n<ul>\n<li>显存节省 1.51 GB（与 LM Head 对称）</li>\n<li>TPOT 优化 1.0 ms</li>\n<li>查表访存优化效果显著</li>\n</ul>\n<h4 id=\"Dense-FFN-模块分析\"><a href=\"#Dense-FFN-模块分析\" class=\"headerlink\" title=\"Dense FFN 模块分析\"></a>Dense FFN 模块分析</h4><p><strong>权重特征</strong>:</p>\n<ul>\n<li>单层权重体积相对较小（1.11 GB &#x2F; 3 层）</li>\n<li>单层访存开销为 378 MB</li>\n</ul>\n<p><strong>优化有效性</strong>:</p>\n<ul>\n<li>访存优化足以覆盖通信成本</li>\n<li>TPOT 优化约 1.0 ms</li>\n<li>对前三层的推理性能提升明显</li>\n</ul>\n<h3 id=\"4-4-整体评估\"><a href=\"#4-4-整体评估\" class=\"headerlink\" title=\"4.4 整体评估\"></a>4.4 整体评估</h3><h4 id=\"显存优化总结\"><a href=\"#显存优化总结\" class=\"headerlink\" title=\"显存优化总结\"></a>显存优化总结</h4><p>细粒度 TP 切分（TP&#x3D;8）在整体上显著降低 Decode 节点显存占用:</p>\n<ul>\n<li><strong>总显存节省</strong>: 9.72 GB</li>\n<li><strong>相对降幅</strong>: 显著提升 GPU 利用率</li>\n<li><strong>应用价值</strong>: 可支持更大 batch size,提升系统吞吐量</li>\n</ul>\n<h4 id=\"TPOT-性能总结\"><a href=\"#TPOT-性能总结\" class=\"headerlink\" title=\"TPOT 性能总结\"></a>TPOT 性能总结</h4><p>整体 TPOT 性能略有提升:</p>\n<ul>\n<li><strong>净优化</strong>: ~1 ms（batch&#x3D;24）</li>\n<li><strong>关键贡献者</strong>: LM Head（+1.2 ms）、Embedding（+1.0 ms）、Dense FFN（+1.0 ms）</li>\n<li><strong>主要损耗</strong>: O_proj（-1.5 ms）</li>\n</ul>\n<h4 id=\"策略建议\"><a href=\"#策略建议\" class=\"headerlink\" title=\"策略建议\"></a>策略建议</h4><p>基于实验结果,我们提出以下部署策略建议:</p>\n<ol>\n<li><strong>显存受限场景（推荐全部启用）</strong><ul>\n<li>所有四个模块均启用细粒度 TP</li>\n<li>获得最大显存收益（9.72 GB）</li>\n<li>接受小幅 TPOT 开销（净优化 ~1 ms 或持平）</li>\n</ul>\n</li>\n<li><strong>TPOT 敏感场景（选择性启用）</strong><ul>\n<li>启用 LM Head + Embedding + Dense FFN</li>\n<li>关闭 O_proj 切分</li>\n<li>平衡显存节省（3.92 GB）与 TPOT 优化（+3.2 ms）</li>\n</ul>\n</li>\n<li><strong>平衡场景（默认推荐）</strong><ul>\n<li>启用所有模块</li>\n<li>在实际部署中根据具体负载动态调整</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h2 id=\"5-总结与展望\"><a href=\"#5-总结与展望\" class=\"headerlink\" title=\"5. 总结与展望\"></a>5. 总结与展望</h2><h3 id=\"5-1-核心贡献\"><a href=\"#5-1-核心贡献\" class=\"headerlink\" title=\"5.1 核心贡献\"></a>5.1 核心贡献</h3><p>本工作针对 DeepSeek-R1 模型 Decode 阶段的性能瓶颈,提出了细粒度张量并行优化方案:</p>\n<ol>\n<li><strong>系统性分析</strong>: 识别出 O_proj、LM Head、Embedding、Dense FFN 四个关键瓶颈模块</li>\n<li><strong>定制化策略</strong>: 针对不同模块的计算特性,设计差异化的 TP 切分与通信方案</li>\n<li><strong>显著收益</strong>: 在昇腾 A2&#x2F;A3 平台上验证,实现 9.72 GB 显存节省和 ~1 ms TPOT 净优化</li>\n<li><strong>开源贡献</strong>: 所有优化方案已合入 vllm-ascend 社区</li>\n</ol>\n<h3 id=\"5-2-适用场景\"><a href=\"#5-2-适用场景\" class=\"headerlink\" title=\"5.2 适用场景\"></a>5.2 适用场景</h3><p>该优化方案特别适用于以下场景:</p>\n<ul>\n<li>显存受限的大规模模型部署</li>\n<li>需要高并发支持的在线推理服务</li>\n<li>PD 分离架构的 Decode 节点优化</li>\n</ul>\n<h3 id=\"5-3-未来工作\"><a href=\"#5-3-未来工作\" class=\"headerlink\" title=\"5.3 未来工作\"></a>5.3 未来工作</h3><ol>\n<li><strong>扩展到更多模型</strong>: 验证在其他 Transformer 架构（如Qwen、GLM）上的适用性</li>\n<li><strong>通信-计算融合</strong>: 进一步优化通信与计算的重叠,降低端到端延迟</li>\n<li><strong>硬件适配</strong>: 针对不同硬件平台（GPU、NPU）优化通信原语</li>\n<li><strong>vllm 主社区适配</strong></li>\n</ol>\n<hr>\n<h2 id=\"附录-Q-A\"><a href=\"#附录-Q-A\" class=\"headerlink\" title=\"附录: Q&amp;A\"></a>附录: Q&amp;A</h2><h3 id=\"Q1-为什么-O-proj-切分会导致-TPOT-劣化\"><a href=\"#Q1-为什么-O-proj-切分会导致-TPOT-劣化\" class=\"headerlink\" title=\"Q1: 为什么 O_proj 切分会导致 TPOT 劣化?\"></a>Q1: 为什么 O_proj 切分会导致 TPOT 劣化?</h3><p><strong>A</strong>: O_proj 虽然权重规模大（6.67 GB），但分布在 61 层，单层仅 117 MB。在 Decode 阶段，单层 117 MB 的访存压力相对适中，无法成为显著瓶颈。然而，TP 切分引入了两次通信（前后各一次），通信开销超过了访存优化带来的收益，因此整体 TPOT 劣化。</p>\n<h3 id=\"Q2-如何确定最优的-TP-切分粒度\"><a href=\"#Q2-如何确定最优的-TP-切分粒度\" class=\"headerlink\" title=\"Q2: 如何确定最优的 TP 切分粒度?\"></a>Q2: 如何确定最优的 TP 切分粒度?</h3><p><strong>A</strong>: 最优 TP 粒度取决于多个因素:</p>\n<ul>\n<li><strong>集群通信带宽</strong>: 高速互联（如 NVLink、IB）支持更大的 TP 粒度</li>\n<li><strong>模块权重规模</strong>: 越大的权重矩阵，越适合更大的 TP</li>\n<li><strong>Batch size</strong>: 更大的 batch size 可以摊销通信开销</li>\n<li><strong>实验验证</strong>: 建议通过 profiling 在实际环境中测试不同 TP 粒度的性能</li>\n</ul>\n<h3 id=\"Q3-增大batch-size-是否会进一步的劣化\"><a href=\"#Q3-增大batch-size-是否会进一步的劣化\" class=\"headerlink\" title=\"Q3: 增大batch size 是否会进一步的劣化\"></a>Q3: 增大batch size 是否会进一步的劣化</h3><p><strong>A</strong>: 理论上，batch size的增加，必然带来通信时间的增加，但是deocde 的激活值非常小，短时间无法达到通信密集，可预见的事通信时间会缓慢增加，直到达到通信密集之后，通信时间会显著增加。</p>\n<h3 id=\"Q4-该方案是否适用于-Prefill-阶段\"><a href=\"#Q4-该方案是否适用于-Prefill-阶段\" class=\"headerlink\" title=\"Q4: 该方案是否适用于 Prefill 阶段?\"></a>Q4: 该方案是否适用于 Prefill 阶段?</h3><p><strong>A</strong>: 不完全适用。Prefill 阶段的特征与 Decode 阶段截然不同: Prefill 是 compute-bound，适合全局大 TP，Decode 是 memory-bound，需要细粒度优化。细粒度 TP 主要针对 Decode 阶段的访存瓶颈，在 Prefill 阶段可能无法带来收益甚至引入额外开销。</p>\n<h3 id=\"Q5-该方案是否适合混布\"><a href=\"#Q5-该方案是否适合混布\" class=\"headerlink\" title=\"Q5: 该方案是否适合混布?\"></a>Q5: 该方案是否适合混布?</h3><p><strong>A</strong>: 混布是否开启该方案，必须考虑在prefill引入该方案造成的影响，目前不推荐o_porj和mlp切分在混布情况下使用，但是可以开启embedding和lmhead切分，这两个操作不管是prefill或者decode其激活值的大小都非常的小，并且整个模型只有一次计算，因此在混布情况下开启这两个切分是没有问题的。</p>\n<h3 id=\"Q6-该方案在vllm-ascend中如何使用\"><a href=\"#Q6-该方案在vllm-ascend中如何使用\" class=\"headerlink\" title=\"Q6: 该方案在vllm-ascend中如何使用\"></a>Q6: 该方案在vllm-ascend中如何使用</h3><p><strong>A</strong>: 详细请查看 <a href=\"https://docs.vllm.ai/projects/ascend/en/latest/user_guide/feature_guide/Fine_grained_TP\">https://docs.vllm.ai/projects/ascend/en/latest/user_guide/feature_guide/Fine_grained_TP</a>.</p>\n"},{"title":"Clash-CLI 部署与跨机器代理使用全指南","date":"2025-09-07T16:00:00.000Z","updated":"2026-01-14T16:00:00.000Z","_content":"本文详细讲解 `clash-cli` 工具的安装、云服务器代理配置，以及本地机器如何一键复用云服务器的代理服务，全程附实操命令和避坑要点。\n\n## 一、Clash-CLI 安装（云服务器端）\n`clash-cli` 是 Clash 代理的命令行管理工具，支持快速安装、更新订阅、启停代理，推荐在 Linux 云服务器（如阿里云/腾讯云）部署。\n\n### 方式一：Python 包安装（推荐，易维护）\n```bash\n# 1. 安装 clash-cli 核心工具（确保服务器已安装 Python/pip）\npip install clash-cli\n\n# 2. 初始化（解决 sudo 权限问题，非必需但建议执行）\nclash-cli init\n\n# 3. 安装 Clash 系统服务（需 sudo 权限，生成 systemd 服务）\nsudo clash-cli install\n\n# 4. 启动代理（验证安装）\nclash-cli on\n```\n\n### 方式二：Shell 脚本安装（传统方式，兼容低版本系统）\n```bash\ngit clone --branch main --depth 1 https://github.com/whillhill/clash-cli.git \\\n  && cd clash-cli \\\n  && sudo bash install.sh\n```\n\n## 二、Clash-CLI 基础使用（云服务器端）\n### 1. 订阅管理（核心：更新代理节点）\n```bash\n# 首次更新：使用自定义订阅链接\nclash-cli update https://your-subscription-url.com\n\n# 后续更新：复用上次的订阅链接（无需重复输入）\nclash-cli update\n\n# 查看更新日志（确认订阅是否生效）\nclash-cli update log\n```\n\n### 2. 代理服务启停与状态查看\n```bash\n# 启动代理服务\nclash-cli on\n\n# 停止代理服务\nclash-cli off\n\n# 查看服务状态（关键：确认 mihomo.service 是否运行）\nclash-cli status\n```\n> 正常状态示例：\n> ```\n> ● mihomo.service - mihomo Daemon, A[nother] Clash Kernel.\n>    Loaded: loaded (/etc/systemd/system/mihomo.service; enabled; vendor preset: enabled)\n>    Active: active (running) since Mon 2025-01-27 10:30:15 CST; 2h 15min ago\n> ```\n\n## 三、云服务器代理配置（允许本地访问）\n默认情况下 Clash 仅监听本机（127.0.0.1），需修改配置开启局域网访问，并添加认证防止滥用。\n\n### 1. 确认端口监听状态\n```bash\n# 查看 7890 端口监听范围（默认是 127.0.0.1，仅本机可访问）\nsudo netstat -tulpn | grep 7890\n```\n\n### 2. 修改 Clash 配置文件\n#### 步骤1：找到配置文件路径\n通过 `clash-cli status` 输出找到配置文件（示例：`/opt/clash/runtime.yaml`）。\n\n#### 步骤2：编辑配置文件\n```bash\nsudo vim /opt/clash/runtime.yaml\n```\n修改以下核心配置（添加局域网访问+用户认证）：\n```yaml\n# 允许局域网访问（关键：开启后本地机器才能连接）\nallow-lan: true\n\n# 用户认证（必填！防止代理暴露公网被他人滥用）\nauthentication:\n  - \"user:123123\" # 格式：\"用户名:密码\"，可自定义\n\n# 端口配置（默认 7890，无需修改）\nport: 7890\nsocks-port: 7891\nredir-port: 7892\n```\n\n#### 步骤3：重启服务使配置生效\n```bash\nsudo systemctl restart mihomo\n# 验证端口监听（显示 :::7890 表示监听所有IP）\nsudo netstat -tulpn | grep 7890\n```\n> 正常输出示例：\n> ```\n> tcp6       0      0 :::7890                 :::*                    LISTEN      57850/mihomo\n> udp6       0      0 :::7890                 :::*                                57850/mihomo\n> ```\n\n### 3. 开放云服务器端口（必做！）\n登录云服务器控制台（如阿里云/腾讯云），在「安全组」中放行 7890 端口（TCP/UDP 协议），否则本地无法连接。\n\n## 四、本地机器使用云服务器代理\n### 1. 验证代理连通性\n先通过 `curl` 测试是否能正常访问外网（替换为你的服务器IP/账号密码）：\n```bash\n# 测试访问 Google，验证代理是否生效\ncurl -x http://user:123123@xxx.xxx.xxx.xx:7890 https://google.com -v\n```\n> 成功标志：返回 `301 Moved` 或 Google 页面内容，无连接超时/拒绝错误。\n\n### 2. 一键代理脚本（本地快捷使用）\n编写脚本 `proxyctl`，实现「一键开启/关闭/查看代理」，无需手动输配置。\n\n#### 步骤1：创建脚本文件\n```bash\nvim /home/zzhxx/workspace/tools/proxyctl\n```\n粘贴以下内容（已适配你的配置，可直接用）：\n```bash\n#!/bin/bash\nset -e # 遇到错误立即退出\n\n# ========== 自定义配置（替换为自己的信息）==========\nPROXY_USER=\"user\"\nPROXY_PASS=\"123123\"\nPROXY_IP=\"xxx.xxx.xxx.xx\"\nPROXY_PORT=\"7890\"\n# ================================================\n\nPROXY_URL=\"http://${PROXY_USER}:${PROXY_PASS}@${PROXY_IP}:${PROXY_PORT}\"\n\n# 执行逻辑\ncase \"$1\" in\n    on)\n        # 开启代理：清空旧变量 + 设置新变量\n        unset HTTPS_PROXY HTTP_PROXY ALL_PROXY\n        export HTTPS_PROXY=\"${PROXY_URL}\"\n        export HTTP_PROXY=\"${PROXY_URL}\"\n        export ALL_PROXY=\"${PROXY_URL}\"\n        echo -e \"\\033[32m✅ 代理已开启\\033[0m\"\n        echo \"当前代理配置：${PROXY_URL}\"\n        ;;\n    off)\n        # 关闭代理：清空所有代理变量\n        unset HTTPS_PROXY HTTP_PROXY ALL_PROXY\n        echo -e \"\\033[31m❌ 代理已关闭\\033[0m\"\n        ;;\n    status)\n        # 查看当前代理状态\n        echo -e \"📌 当前代理状态：\"\n        echo \"HTTPS_PROXY: ${HTTPS_PROXY:-未设置}\"\n        echo \"HTTP_PROXY: ${HTTP_PROXY:-未设置}\"\n        echo \"ALL_PROXY: ${ALL_PROXY:-未设置}\"\n        ;;\n    test)\n        # 新增：测试代理连通性\n        echo -e \"🔍 测试代理连通性...\"\n        if curl -s -x \"${PROXY_URL}\" https://google.com > /dev/null; then\n            echo -e \"\\033[32m✅ 代理可用\\033[0m\"\n        else\n            echo -e \"\\033[31m❌ 代理不可用\\033[0m\"\n            exit 1\n        fi\n        ;;\n    *)\n        # 帮助信息\n        echo -e \"📚 用法：\"\n        echo \"  proxyctl on      - 开启代理\"\n        echo \"  proxyctl off     - 关闭代理\"\n        echo \"  proxyctl status  - 查看代理状态\"\n        echo \"  proxyctl test    - 测试代理连通性\"\n        ;;\nesac\n```\n\n#### 步骤2：添加执行权限\n```bash\nchmod +x /home/zzhxx/workspace/tools/proxyctl\n```\n\n#### 步骤3：设置别名（永久生效）\n```bash\n# 临时生效（当前终端）\nalias proxyctl=\"sh /home/zzhxx/workspace/tools/proxyctl\"\n\n# 永久生效（所有终端），添加到 ~/.bashrc 或 ~/.zshrc\necho \"alias proxyctl='/home/zzhxx/workspace/tools/proxyctl'\" >> ~/.bashrc\nsource ~/.bashrc\n```\n\n#### 步骤4：使用示例\n```bash\n# 开启代理\nproxyctl on\n\n# 查看状态\nproxyctl status\n\n# 测试连通性\nproxyctl test\n\n# 关闭代理\nproxyctl off\n```\n\n### 3. 额外实用脚本（可选）\n停止并删除 Docker 容器的快捷脚本（补充）：\n```bash\n#!/bin/bash\n# 检查参数是否传入\nif [ -z \"$1\" ]; then\n    echo -e \"\\033[31m❌ 请传入容器名/ID\\033[0m\"\n    echo \"用法：docker-rm 容器名/ID\"\n    exit 1\nfi\n\nname=$1\necho -e \"🔧 停止并删除容器：${name}\"\ndocker stop ${name} && docker rm ${name}\necho -e \"\\033[32m✅ 操作完成\\033[0m\"\n```\n\n## 五、避坑要点\n1. **权限问题**：修改 Clash 配置文件需 `sudo`，否则保存失败；\n2. **安全风险**：开启 `allow-lan: true` 后必须加 `authentication`，否则代理可能被全网滥用；\n3. **端口放行**：云服务器安全组未开 7890 端口，本地会提示「连接拒绝」；\n4. **脚本生效**：设置别名后需 `source ~/.bashrc`，否则新终端不生效；\n5. **代理范围**：脚本仅对当前终端生效，如需全局代理需配置系统网络。\n\n---\n\n### 总结\n1. 核心流程：云服务器安装 `clash-cli` → 配置局域网访问+认证 → 开放端口 → 本地用脚本一键复用；\n2. 关键避坑：开启局域网访问必须加用户认证，云服务器安全组需放行 7890 端口；\n3. 效率优化：本地脚本实现「开启/关闭/测试」一体化，无需重复输入复杂代理地址。\n","source":"_posts/hello-world.md","raw":"---\ntitle: Clash-CLI 部署与跨机器代理使用全指南\ndate: 2025-09-08\nupdated: 2026-01-15\ntags:\n  - Clash\n  - 代理配置\n  - Linux\n  - 命令行工具\n  - 网络工具\ncategory: 技术教程\n---\n本文详细讲解 `clash-cli` 工具的安装、云服务器代理配置，以及本地机器如何一键复用云服务器的代理服务，全程附实操命令和避坑要点。\n\n## 一、Clash-CLI 安装（云服务器端）\n`clash-cli` 是 Clash 代理的命令行管理工具，支持快速安装、更新订阅、启停代理，推荐在 Linux 云服务器（如阿里云/腾讯云）部署。\n\n### 方式一：Python 包安装（推荐，易维护）\n```bash\n# 1. 安装 clash-cli 核心工具（确保服务器已安装 Python/pip）\npip install clash-cli\n\n# 2. 初始化（解决 sudo 权限问题，非必需但建议执行）\nclash-cli init\n\n# 3. 安装 Clash 系统服务（需 sudo 权限，生成 systemd 服务）\nsudo clash-cli install\n\n# 4. 启动代理（验证安装）\nclash-cli on\n```\n\n### 方式二：Shell 脚本安装（传统方式，兼容低版本系统）\n```bash\ngit clone --branch main --depth 1 https://github.com/whillhill/clash-cli.git \\\n  && cd clash-cli \\\n  && sudo bash install.sh\n```\n\n## 二、Clash-CLI 基础使用（云服务器端）\n### 1. 订阅管理（核心：更新代理节点）\n```bash\n# 首次更新：使用自定义订阅链接\nclash-cli update https://your-subscription-url.com\n\n# 后续更新：复用上次的订阅链接（无需重复输入）\nclash-cli update\n\n# 查看更新日志（确认订阅是否生效）\nclash-cli update log\n```\n\n### 2. 代理服务启停与状态查看\n```bash\n# 启动代理服务\nclash-cli on\n\n# 停止代理服务\nclash-cli off\n\n# 查看服务状态（关键：确认 mihomo.service 是否运行）\nclash-cli status\n```\n> 正常状态示例：\n> ```\n> ● mihomo.service - mihomo Daemon, A[nother] Clash Kernel.\n>    Loaded: loaded (/etc/systemd/system/mihomo.service; enabled; vendor preset: enabled)\n>    Active: active (running) since Mon 2025-01-27 10:30:15 CST; 2h 15min ago\n> ```\n\n## 三、云服务器代理配置（允许本地访问）\n默认情况下 Clash 仅监听本机（127.0.0.1），需修改配置开启局域网访问，并添加认证防止滥用。\n\n### 1. 确认端口监听状态\n```bash\n# 查看 7890 端口监听范围（默认是 127.0.0.1，仅本机可访问）\nsudo netstat -tulpn | grep 7890\n```\n\n### 2. 修改 Clash 配置文件\n#### 步骤1：找到配置文件路径\n通过 `clash-cli status` 输出找到配置文件（示例：`/opt/clash/runtime.yaml`）。\n\n#### 步骤2：编辑配置文件\n```bash\nsudo vim /opt/clash/runtime.yaml\n```\n修改以下核心配置（添加局域网访问+用户认证）：\n```yaml\n# 允许局域网访问（关键：开启后本地机器才能连接）\nallow-lan: true\n\n# 用户认证（必填！防止代理暴露公网被他人滥用）\nauthentication:\n  - \"user:123123\" # 格式：\"用户名:密码\"，可自定义\n\n# 端口配置（默认 7890，无需修改）\nport: 7890\nsocks-port: 7891\nredir-port: 7892\n```\n\n#### 步骤3：重启服务使配置生效\n```bash\nsudo systemctl restart mihomo\n# 验证端口监听（显示 :::7890 表示监听所有IP）\nsudo netstat -tulpn | grep 7890\n```\n> 正常输出示例：\n> ```\n> tcp6       0      0 :::7890                 :::*                    LISTEN      57850/mihomo\n> udp6       0      0 :::7890                 :::*                                57850/mihomo\n> ```\n\n### 3. 开放云服务器端口（必做！）\n登录云服务器控制台（如阿里云/腾讯云），在「安全组」中放行 7890 端口（TCP/UDP 协议），否则本地无法连接。\n\n## 四、本地机器使用云服务器代理\n### 1. 验证代理连通性\n先通过 `curl` 测试是否能正常访问外网（替换为你的服务器IP/账号密码）：\n```bash\n# 测试访问 Google，验证代理是否生效\ncurl -x http://user:123123@xxx.xxx.xxx.xx:7890 https://google.com -v\n```\n> 成功标志：返回 `301 Moved` 或 Google 页面内容，无连接超时/拒绝错误。\n\n### 2. 一键代理脚本（本地快捷使用）\n编写脚本 `proxyctl`，实现「一键开启/关闭/查看代理」，无需手动输配置。\n\n#### 步骤1：创建脚本文件\n```bash\nvim /home/zzhxx/workspace/tools/proxyctl\n```\n粘贴以下内容（已适配你的配置，可直接用）：\n```bash\n#!/bin/bash\nset -e # 遇到错误立即退出\n\n# ========== 自定义配置（替换为自己的信息）==========\nPROXY_USER=\"user\"\nPROXY_PASS=\"123123\"\nPROXY_IP=\"xxx.xxx.xxx.xx\"\nPROXY_PORT=\"7890\"\n# ================================================\n\nPROXY_URL=\"http://${PROXY_USER}:${PROXY_PASS}@${PROXY_IP}:${PROXY_PORT}\"\n\n# 执行逻辑\ncase \"$1\" in\n    on)\n        # 开启代理：清空旧变量 + 设置新变量\n        unset HTTPS_PROXY HTTP_PROXY ALL_PROXY\n        export HTTPS_PROXY=\"${PROXY_URL}\"\n        export HTTP_PROXY=\"${PROXY_URL}\"\n        export ALL_PROXY=\"${PROXY_URL}\"\n        echo -e \"\\033[32m✅ 代理已开启\\033[0m\"\n        echo \"当前代理配置：${PROXY_URL}\"\n        ;;\n    off)\n        # 关闭代理：清空所有代理变量\n        unset HTTPS_PROXY HTTP_PROXY ALL_PROXY\n        echo -e \"\\033[31m❌ 代理已关闭\\033[0m\"\n        ;;\n    status)\n        # 查看当前代理状态\n        echo -e \"📌 当前代理状态：\"\n        echo \"HTTPS_PROXY: ${HTTPS_PROXY:-未设置}\"\n        echo \"HTTP_PROXY: ${HTTP_PROXY:-未设置}\"\n        echo \"ALL_PROXY: ${ALL_PROXY:-未设置}\"\n        ;;\n    test)\n        # 新增：测试代理连通性\n        echo -e \"🔍 测试代理连通性...\"\n        if curl -s -x \"${PROXY_URL}\" https://google.com > /dev/null; then\n            echo -e \"\\033[32m✅ 代理可用\\033[0m\"\n        else\n            echo -e \"\\033[31m❌ 代理不可用\\033[0m\"\n            exit 1\n        fi\n        ;;\n    *)\n        # 帮助信息\n        echo -e \"📚 用法：\"\n        echo \"  proxyctl on      - 开启代理\"\n        echo \"  proxyctl off     - 关闭代理\"\n        echo \"  proxyctl status  - 查看代理状态\"\n        echo \"  proxyctl test    - 测试代理连通性\"\n        ;;\nesac\n```\n\n#### 步骤2：添加执行权限\n```bash\nchmod +x /home/zzhxx/workspace/tools/proxyctl\n```\n\n#### 步骤3：设置别名（永久生效）\n```bash\n# 临时生效（当前终端）\nalias proxyctl=\"sh /home/zzhxx/workspace/tools/proxyctl\"\n\n# 永久生效（所有终端），添加到 ~/.bashrc 或 ~/.zshrc\necho \"alias proxyctl='/home/zzhxx/workspace/tools/proxyctl'\" >> ~/.bashrc\nsource ~/.bashrc\n```\n\n#### 步骤4：使用示例\n```bash\n# 开启代理\nproxyctl on\n\n# 查看状态\nproxyctl status\n\n# 测试连通性\nproxyctl test\n\n# 关闭代理\nproxyctl off\n```\n\n### 3. 额外实用脚本（可选）\n停止并删除 Docker 容器的快捷脚本（补充）：\n```bash\n#!/bin/bash\n# 检查参数是否传入\nif [ -z \"$1\" ]; then\n    echo -e \"\\033[31m❌ 请传入容器名/ID\\033[0m\"\n    echo \"用法：docker-rm 容器名/ID\"\n    exit 1\nfi\n\nname=$1\necho -e \"🔧 停止并删除容器：${name}\"\ndocker stop ${name} && docker rm ${name}\necho -e \"\\033[32m✅ 操作完成\\033[0m\"\n```\n\n## 五、避坑要点\n1. **权限问题**：修改 Clash 配置文件需 `sudo`，否则保存失败；\n2. **安全风险**：开启 `allow-lan: true` 后必须加 `authentication`，否则代理可能被全网滥用；\n3. **端口放行**：云服务器安全组未开 7890 端口，本地会提示「连接拒绝」；\n4. **脚本生效**：设置别名后需 `source ~/.bashrc`，否则新终端不生效；\n5. **代理范围**：脚本仅对当前终端生效，如需全局代理需配置系统网络。\n\n---\n\n### 总结\n1. 核心流程：云服务器安装 `clash-cli` → 配置局域网访问+认证 → 开放端口 → 本地用脚本一键复用；\n2. 关键避坑：开启局域网访问必须加用户认证，云服务器安全组需放行 7890 端口；\n3. 效率优化：本地脚本实现「开启/关闭/测试」一体化，无需重复输入复杂代理地址。\n","slug":"hello-world","published":1,"comments":1,"layout":"post","photos":[],"_id":"cuidbGd9C9Lf2EyejajXVOyaY","content":"<p>本文详细讲解 <code>clash-cli</code> 工具的安装、云服务器代理配置，以及本地机器如何一键复用云服务器的代理服务，全程附实操命令和避坑要点。</p>\n<h2 id=\"一、Clash-CLI-安装（云服务器端）\"><a href=\"#一、Clash-CLI-安装（云服务器端）\" class=\"headerlink\" title=\"一、Clash-CLI 安装（云服务器端）\"></a>一、Clash-CLI 安装（云服务器端）</h2><p><code>clash-cli</code> 是 Clash 代理的命令行管理工具，支持快速安装、更新订阅、启停代理，推荐在 Linux 云服务器（如阿里云&#x2F;腾讯云）部署。</p>\n<h3 id=\"方式一：Python-包安装（推荐，易维护）\"><a href=\"#方式一：Python-包安装（推荐，易维护）\" class=\"headerlink\" title=\"方式一：Python 包安装（推荐，易维护）\"></a>方式一：Python 包安装（推荐，易维护）</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 1. 安装 clash-cli 核心工具（确保服务器已安装 Python/pip）</span></span><br><span class=\"line\">pip install clash-cli</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2. 初始化（解决 sudo 权限问题，非必需但建议执行）</span></span><br><span class=\"line\">clash-cli init</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 3. 安装 Clash 系统服务（需 sudo 权限，生成 systemd 服务）</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> clash-cli install</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 4. 启动代理（验证安装）</span></span><br><span class=\"line\">clash-cli on</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"方式二：Shell-脚本安装（传统方式，兼容低版本系统）\"><a href=\"#方式二：Shell-脚本安装（传统方式，兼容低版本系统）\" class=\"headerlink\" title=\"方式二：Shell 脚本安装（传统方式，兼容低版本系统）\"></a>方式二：Shell 脚本安装（传统方式，兼容低版本系统）</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">clone</span> --branch main --depth 1 https://github.com/whillhill/clash-cli.git \\</span><br><span class=\"line\">  &amp;&amp; <span class=\"built_in\">cd</span> clash-cli \\</span><br><span class=\"line\">  &amp;&amp; <span class=\"built_in\">sudo</span> bash install.sh</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"二、Clash-CLI-基础使用（云服务器端）\"><a href=\"#二、Clash-CLI-基础使用（云服务器端）\" class=\"headerlink\" title=\"二、Clash-CLI 基础使用（云服务器端）\"></a>二、Clash-CLI 基础使用（云服务器端）</h2><h3 id=\"1-订阅管理（核心：更新代理节点）\"><a href=\"#1-订阅管理（核心：更新代理节点）\" class=\"headerlink\" title=\"1. 订阅管理（核心：更新代理节点）\"></a>1. 订阅管理（核心：更新代理节点）</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 首次更新：使用自定义订阅链接</span></span><br><span class=\"line\">clash-cli update https://your-subscription-url.com</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 后续更新：复用上次的订阅链接（无需重复输入）</span></span><br><span class=\"line\">clash-cli update</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 查看更新日志（确认订阅是否生效）</span></span><br><span class=\"line\">clash-cli update <span class=\"built_in\">log</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"2-代理服务启停与状态查看\"><a href=\"#2-代理服务启停与状态查看\" class=\"headerlink\" title=\"2. 代理服务启停与状态查看\"></a>2. 代理服务启停与状态查看</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 启动代理服务</span></span><br><span class=\"line\">clash-cli on</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 停止代理服务</span></span><br><span class=\"line\">clash-cli off</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 查看服务状态（关键：确认 mihomo.service 是否运行）</span></span><br><span class=\"line\">clash-cli status</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>正常状态示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">● mihomo.service - mihomo Daemon, A[nother] Clash Kernel.</span><br><span class=\"line\">   Loaded: loaded (/etc/systemd/system/mihomo.service; enabled; vendor preset: enabled)</span><br><span class=\"line\">   Active: active (running) since Mon 2025-01-27 10:30:15 CST; 2h 15min ago</span><br></pre></td></tr></table></figure></blockquote>\n<h2 id=\"三、云服务器代理配置（允许本地访问）\"><a href=\"#三、云服务器代理配置（允许本地访问）\" class=\"headerlink\" title=\"三、云服务器代理配置（允许本地访问）\"></a>三、云服务器代理配置（允许本地访问）</h2><p>默认情况下 Clash 仅监听本机（127.0.0.1），需修改配置开启局域网访问，并添加认证防止滥用。</p>\n<h3 id=\"1-确认端口监听状态\"><a href=\"#1-确认端口监听状态\" class=\"headerlink\" title=\"1. 确认端口监听状态\"></a>1. 确认端口监听状态</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看 7890 端口监听范围（默认是 127.0.0.1，仅本机可访问）</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> netstat -tulpn | grep 7890</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"2-修改-Clash-配置文件\"><a href=\"#2-修改-Clash-配置文件\" class=\"headerlink\" title=\"2. 修改 Clash 配置文件\"></a>2. 修改 Clash 配置文件</h3><h4 id=\"步骤1：找到配置文件路径\"><a href=\"#步骤1：找到配置文件路径\" class=\"headerlink\" title=\"步骤1：找到配置文件路径\"></a>步骤1：找到配置文件路径</h4><p>通过 <code>clash-cli status</code> 输出找到配置文件（示例：<code>/opt/clash/runtime.yaml</code>）。</p>\n<h4 id=\"步骤2：编辑配置文件\"><a href=\"#步骤2：编辑配置文件\" class=\"headerlink\" title=\"步骤2：编辑配置文件\"></a>步骤2：编辑配置文件</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> vim /opt/clash/runtime.yaml</span><br></pre></td></tr></table></figure>\n<p>修改以下核心配置（添加局域网访问+用户认证）：</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 允许局域网访问（关键：开启后本地机器才能连接）</span></span><br><span class=\"line\"><span class=\"attr\">allow-lan:</span> <span class=\"literal\">true</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 用户认证（必填！防止代理暴露公网被他人滥用）</span></span><br><span class=\"line\"><span class=\"attr\">authentication:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">&quot;user:123123&quot;</span> <span class=\"comment\"># 格式：&quot;用户名:密码&quot;，可自定义</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 端口配置（默认 7890，无需修改）</span></span><br><span class=\"line\"><span class=\"attr\">port:</span> <span class=\"number\">7890</span></span><br><span class=\"line\"><span class=\"attr\">socks-port:</span> <span class=\"number\">7891</span></span><br><span class=\"line\"><span class=\"attr\">redir-port:</span> <span class=\"number\">7892</span></span><br></pre></td></tr></table></figure>\n\n<h4 id=\"步骤3：重启服务使配置生效\"><a href=\"#步骤3：重启服务使配置生效\" class=\"headerlink\" title=\"步骤3：重启服务使配置生效\"></a>步骤3：重启服务使配置生效</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> systemctl restart mihomo</span><br><span class=\"line\"><span class=\"comment\"># 验证端口监听（显示 :::7890 表示监听所有IP）</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> netstat -tulpn | grep 7890</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>正常输出示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tcp6       0      0 :::7890                 :::*                    LISTEN      57850/mihomo</span><br><span class=\"line\">udp6       0      0 :::7890                 :::*                                57850/mihomo</span><br></pre></td></tr></table></figure></blockquote>\n<h3 id=\"3-开放云服务器端口（必做！）\"><a href=\"#3-开放云服务器端口（必做！）\" class=\"headerlink\" title=\"3. 开放云服务器端口（必做！）\"></a>3. 开放云服务器端口（必做！）</h3><p>登录云服务器控制台（如阿里云&#x2F;腾讯云），在「安全组」中放行 7890 端口（TCP&#x2F;UDP 协议），否则本地无法连接。</p>\n<h2 id=\"四、本地机器使用云服务器代理\"><a href=\"#四、本地机器使用云服务器代理\" class=\"headerlink\" title=\"四、本地机器使用云服务器代理\"></a>四、本地机器使用云服务器代理</h2><h3 id=\"1-验证代理连通性\"><a href=\"#1-验证代理连通性\" class=\"headerlink\" title=\"1. 验证代理连通性\"></a>1. 验证代理连通性</h3><p>先通过 <code>curl</code> 测试是否能正常访问外网（替换为你的服务器IP&#x2F;账号密码）：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 测试访问 Google，验证代理是否生效</span></span><br><span class=\"line\">curl -x http://user:123123@xxx.xxx.xxx.xx:7890 https://google.com -v</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>成功标志：返回 <code>301 Moved</code> 或 Google 页面内容，无连接超时&#x2F;拒绝错误。</p>\n</blockquote>\n<h3 id=\"2-一键代理脚本（本地快捷使用）\"><a href=\"#2-一键代理脚本（本地快捷使用）\" class=\"headerlink\" title=\"2. 一键代理脚本（本地快捷使用）\"></a>2. 一键代理脚本（本地快捷使用）</h3><p>编写脚本 <code>proxyctl</code>，实现「一键开启&#x2F;关闭&#x2F;查看代理」，无需手动输配置。</p>\n<h4 id=\"步骤1：创建脚本文件\"><a href=\"#步骤1：创建脚本文件\" class=\"headerlink\" title=\"步骤1：创建脚本文件\"></a>步骤1：创建脚本文件</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim /home/zzhxx/workspace/tools/proxyctl</span><br></pre></td></tr></table></figure>\n<p>粘贴以下内容（已适配你的配置，可直接用）：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#!/bin/bash</span></span><br><span class=\"line\"><span class=\"built_in\">set</span> -e <span class=\"comment\"># 遇到错误立即退出</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ========== 自定义配置（替换为自己的信息）==========</span></span><br><span class=\"line\">PROXY_USER=<span class=\"string\">&quot;user&quot;</span></span><br><span class=\"line\">PROXY_PASS=<span class=\"string\">&quot;123123&quot;</span></span><br><span class=\"line\">PROXY_IP=<span class=\"string\">&quot;xxx.xxx.xxx.xx&quot;</span></span><br><span class=\"line\">PROXY_PORT=<span class=\"string\">&quot;7890&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># ================================================</span></span><br><span class=\"line\"></span><br><span class=\"line\">PROXY_URL=<span class=\"string\">&quot;http://<span class=\"variable\">$&#123;PROXY_USER&#125;</span>:<span class=\"variable\">$&#123;PROXY_PASS&#125;</span>@<span class=\"variable\">$&#123;PROXY_IP&#125;</span>:<span class=\"variable\">$&#123;PROXY_PORT&#125;</span>&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 执行逻辑</span></span><br><span class=\"line\"><span class=\"keyword\">case</span> <span class=\"string\">&quot;<span class=\"variable\">$1</span>&quot;</span> <span class=\"keyword\">in</span></span><br><span class=\"line\">    on)</span><br><span class=\"line\">        <span class=\"comment\"># 开启代理：清空旧变量 + 设置新变量</span></span><br><span class=\"line\">        <span class=\"built_in\">unset</span> HTTPS_PROXY HTTP_PROXY ALL_PROXY</span><br><span class=\"line\">        <span class=\"built_in\">export</span> HTTPS_PROXY=<span class=\"string\">&quot;<span class=\"variable\">$&#123;PROXY_URL&#125;</span>&quot;</span></span><br><span class=\"line\">        <span class=\"built_in\">export</span> HTTP_PROXY=<span class=\"string\">&quot;<span class=\"variable\">$&#123;PROXY_URL&#125;</span>&quot;</span></span><br><span class=\"line\">        <span class=\"built_in\">export</span> ALL_PROXY=<span class=\"string\">&quot;<span class=\"variable\">$&#123;PROXY_URL&#125;</span>&quot;</span></span><br><span class=\"line\">        <span class=\"built_in\">echo</span> -e <span class=\"string\">&quot;\\033[32m✅ 代理已开启\\033[0m&quot;</span></span><br><span class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">&quot;当前代理配置：<span class=\"variable\">$&#123;PROXY_URL&#125;</span>&quot;</span></span><br><span class=\"line\">        ;;</span><br><span class=\"line\">    off)</span><br><span class=\"line\">        <span class=\"comment\"># 关闭代理：清空所有代理变量</span></span><br><span class=\"line\">        <span class=\"built_in\">unset</span> HTTPS_PROXY HTTP_PROXY ALL_PROXY</span><br><span class=\"line\">        <span class=\"built_in\">echo</span> -e <span class=\"string\">&quot;\\033[31m❌ 代理已关闭\\033[0m&quot;</span></span><br><span class=\"line\">        ;;</span><br><span class=\"line\">    status)</span><br><span class=\"line\">        <span class=\"comment\"># 查看当前代理状态</span></span><br><span class=\"line\">        <span class=\"built_in\">echo</span> -e <span class=\"string\">&quot;📌 当前代理状态：&quot;</span></span><br><span class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">&quot;HTTPS_PROXY: <span class=\"variable\">$&#123;HTTPS_PROXY:-未设置&#125;</span>&quot;</span></span><br><span class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">&quot;HTTP_PROXY: <span class=\"variable\">$&#123;HTTP_PROXY:-未设置&#125;</span>&quot;</span></span><br><span class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">&quot;ALL_PROXY: <span class=\"variable\">$&#123;ALL_PROXY:-未设置&#125;</span>&quot;</span></span><br><span class=\"line\">        ;;</span><br><span class=\"line\">    <span class=\"built_in\">test</span>)</span><br><span class=\"line\">        <span class=\"comment\"># 新增：测试代理连通性</span></span><br><span class=\"line\">        <span class=\"built_in\">echo</span> -e <span class=\"string\">&quot;🔍 测试代理连通性...&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> curl -s -x <span class=\"string\">&quot;<span class=\"variable\">$&#123;PROXY_URL&#125;</span>&quot;</span> https://google.com &gt; /dev/null; <span class=\"keyword\">then</span></span><br><span class=\"line\">            <span class=\"built_in\">echo</span> -e <span class=\"string\">&quot;\\033[32m✅ 代理可用\\033[0m&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">            <span class=\"built_in\">echo</span> -e <span class=\"string\">&quot;\\033[31m❌ 代理不可用\\033[0m&quot;</span></span><br><span class=\"line\">            <span class=\"built_in\">exit</span> 1</span><br><span class=\"line\">        <span class=\"keyword\">fi</span></span><br><span class=\"line\">        ;;</span><br><span class=\"line\">    *)</span><br><span class=\"line\">        <span class=\"comment\"># 帮助信息</span></span><br><span class=\"line\">        <span class=\"built_in\">echo</span> -e <span class=\"string\">&quot;📚 用法：&quot;</span></span><br><span class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">&quot;  proxyctl on      - 开启代理&quot;</span></span><br><span class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">&quot;  proxyctl off     - 关闭代理&quot;</span></span><br><span class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">&quot;  proxyctl status  - 查看代理状态&quot;</span></span><br><span class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">&quot;  proxyctl test    - 测试代理连通性&quot;</span></span><br><span class=\"line\">        ;;</span><br><span class=\"line\"><span class=\"keyword\">esac</span></span><br></pre></td></tr></table></figure>\n\n<h4 id=\"步骤2：添加执行权限\"><a href=\"#步骤2：添加执行权限\" class=\"headerlink\" title=\"步骤2：添加执行权限\"></a>步骤2：添加执行权限</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">chmod</span> +x /home/zzhxx/workspace/tools/proxyctl</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"步骤3：设置别名（永久生效）\"><a href=\"#步骤3：设置别名（永久生效）\" class=\"headerlink\" title=\"步骤3：设置别名（永久生效）\"></a>步骤3：设置别名（永久生效）</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 临时生效（当前终端）</span></span><br><span class=\"line\"><span class=\"built_in\">alias</span> proxyctl=<span class=\"string\">&quot;sh /home/zzhxx/workspace/tools/proxyctl&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 永久生效（所有终端），添加到 ~/.bashrc 或 ~/.zshrc</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&quot;alias proxyctl=&#x27;/home/zzhxx/workspace/tools/proxyctl&#x27;&quot;</span> &gt;&gt; ~/.bashrc</span><br><span class=\"line\"><span class=\"built_in\">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"步骤4：使用示例\"><a href=\"#步骤4：使用示例\" class=\"headerlink\" title=\"步骤4：使用示例\"></a>步骤4：使用示例</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 开启代理</span></span><br><span class=\"line\">proxyctl on</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 查看状态</span></span><br><span class=\"line\">proxyctl status</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 测试连通性</span></span><br><span class=\"line\">proxyctl <span class=\"built_in\">test</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 关闭代理</span></span><br><span class=\"line\">proxyctl off</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"3-额外实用脚本（可选）\"><a href=\"#3-额外实用脚本（可选）\" class=\"headerlink\" title=\"3. 额外实用脚本（可选）\"></a>3. 额外实用脚本（可选）</h3><p>停止并删除 Docker 容器的快捷脚本（补充）：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#!/bin/bash</span></span><br><span class=\"line\"><span class=\"comment\"># 检查参数是否传入</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> [ -z <span class=\"string\">&quot;<span class=\"variable\">$1</span>&quot;</span> ]; <span class=\"keyword\">then</span></span><br><span class=\"line\">    <span class=\"built_in\">echo</span> -e <span class=\"string\">&quot;\\033[31m❌ 请传入容器名/ID\\033[0m&quot;</span></span><br><span class=\"line\">    <span class=\"built_in\">echo</span> <span class=\"string\">&quot;用法：docker-rm 容器名/ID&quot;</span></span><br><span class=\"line\">    <span class=\"built_in\">exit</span> 1</span><br><span class=\"line\"><span class=\"keyword\">fi</span></span><br><span class=\"line\"></span><br><span class=\"line\">name=<span class=\"variable\">$1</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> -e <span class=\"string\">&quot;🔧 停止并删除容器：<span class=\"variable\">$&#123;name&#125;</span>&quot;</span></span><br><span class=\"line\">docker stop <span class=\"variable\">$&#123;name&#125;</span> &amp;&amp; docker <span class=\"built_in\">rm</span> <span class=\"variable\">$&#123;name&#125;</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> -e <span class=\"string\">&quot;\\033[32m✅ 操作完成\\033[0m&quot;</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"五、避坑要点\"><a href=\"#五、避坑要点\" class=\"headerlink\" title=\"五、避坑要点\"></a>五、避坑要点</h2><ol>\n<li><strong>权限问题</strong>：修改 Clash 配置文件需 <code>sudo</code>，否则保存失败；</li>\n<li><strong>安全风险</strong>：开启 <code>allow-lan: true</code> 后必须加 <code>authentication</code>，否则代理可能被全网滥用；</li>\n<li><strong>端口放行</strong>：云服务器安全组未开 7890 端口，本地会提示「连接拒绝」；</li>\n<li><strong>脚本生效</strong>：设置别名后需 <code>source ~/.bashrc</code>，否则新终端不生效；</li>\n<li><strong>代理范围</strong>：脚本仅对当前终端生效，如需全局代理需配置系统网络。</li>\n</ol>\n<hr>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><ol>\n<li>核心流程：云服务器安装 <code>clash-cli</code> → 配置局域网访问+认证 → 开放端口 → 本地用脚本一键复用；</li>\n<li>关键避坑：开启局域网访问必须加用户认证，云服务器安全组需放行 7890 端口；</li>\n<li>效率优化：本地脚本实现「开启&#x2F;关闭&#x2F;测试」一体化，无需重复输入复杂代理地址。</li>\n</ol>\n","excerpt":"","more":"<p>本文详细讲解 <code>clash-cli</code> 工具的安装、云服务器代理配置，以及本地机器如何一键复用云服务器的代理服务，全程附实操命令和避坑要点。</p>\n<h2 id=\"一、Clash-CLI-安装（云服务器端）\"><a href=\"#一、Clash-CLI-安装（云服务器端）\" class=\"headerlink\" title=\"一、Clash-CLI 安装（云服务器端）\"></a>一、Clash-CLI 安装（云服务器端）</h2><p><code>clash-cli</code> 是 Clash 代理的命令行管理工具，支持快速安装、更新订阅、启停代理，推荐在 Linux 云服务器（如阿里云&#x2F;腾讯云）部署。</p>\n<h3 id=\"方式一：Python-包安装（推荐，易维护）\"><a href=\"#方式一：Python-包安装（推荐，易维护）\" class=\"headerlink\" title=\"方式一：Python 包安装（推荐，易维护）\"></a>方式一：Python 包安装（推荐，易维护）</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 1. 安装 clash-cli 核心工具（确保服务器已安装 Python/pip）</span></span><br><span class=\"line\">pip install clash-cli</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2. 初始化（解决 sudo 权限问题，非必需但建议执行）</span></span><br><span class=\"line\">clash-cli init</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 3. 安装 Clash 系统服务（需 sudo 权限，生成 systemd 服务）</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> clash-cli install</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 4. 启动代理（验证安装）</span></span><br><span class=\"line\">clash-cli on</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"方式二：Shell-脚本安装（传统方式，兼容低版本系统）\"><a href=\"#方式二：Shell-脚本安装（传统方式，兼容低版本系统）\" class=\"headerlink\" title=\"方式二：Shell 脚本安装（传统方式，兼容低版本系统）\"></a>方式二：Shell 脚本安装（传统方式，兼容低版本系统）</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">clone</span> --branch main --depth 1 https://github.com/whillhill/clash-cli.git \\</span><br><span class=\"line\">  &amp;&amp; <span class=\"built_in\">cd</span> clash-cli \\</span><br><span class=\"line\">  &amp;&amp; <span class=\"built_in\">sudo</span> bash install.sh</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"二、Clash-CLI-基础使用（云服务器端）\"><a href=\"#二、Clash-CLI-基础使用（云服务器端）\" class=\"headerlink\" title=\"二、Clash-CLI 基础使用（云服务器端）\"></a>二、Clash-CLI 基础使用（云服务器端）</h2><h3 id=\"1-订阅管理（核心：更新代理节点）\"><a href=\"#1-订阅管理（核心：更新代理节点）\" class=\"headerlink\" title=\"1. 订阅管理（核心：更新代理节点）\"></a>1. 订阅管理（核心：更新代理节点）</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 首次更新：使用自定义订阅链接</span></span><br><span class=\"line\">clash-cli update https://your-subscription-url.com</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 后续更新：复用上次的订阅链接（无需重复输入）</span></span><br><span class=\"line\">clash-cli update</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 查看更新日志（确认订阅是否生效）</span></span><br><span class=\"line\">clash-cli update <span class=\"built_in\">log</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"2-代理服务启停与状态查看\"><a href=\"#2-代理服务启停与状态查看\" class=\"headerlink\" title=\"2. 代理服务启停与状态查看\"></a>2. 代理服务启停与状态查看</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 启动代理服务</span></span><br><span class=\"line\">clash-cli on</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 停止代理服务</span></span><br><span class=\"line\">clash-cli off</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 查看服务状态（关键：确认 mihomo.service 是否运行）</span></span><br><span class=\"line\">clash-cli status</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>正常状态示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">● mihomo.service - mihomo Daemon, A[nother] Clash Kernel.</span><br><span class=\"line\">   Loaded: loaded (/etc/systemd/system/mihomo.service; enabled; vendor preset: enabled)</span><br><span class=\"line\">   Active: active (running) since Mon 2025-01-27 10:30:15 CST; 2h 15min ago</span><br></pre></td></tr></table></figure></blockquote>\n<h2 id=\"三、云服务器代理配置（允许本地访问）\"><a href=\"#三、云服务器代理配置（允许本地访问）\" class=\"headerlink\" title=\"三、云服务器代理配置（允许本地访问）\"></a>三、云服务器代理配置（允许本地访问）</h2><p>默认情况下 Clash 仅监听本机（127.0.0.1），需修改配置开启局域网访问，并添加认证防止滥用。</p>\n<h3 id=\"1-确认端口监听状态\"><a href=\"#1-确认端口监听状态\" class=\"headerlink\" title=\"1. 确认端口监听状态\"></a>1. 确认端口监听状态</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看 7890 端口监听范围（默认是 127.0.0.1，仅本机可访问）</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> netstat -tulpn | grep 7890</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"2-修改-Clash-配置文件\"><a href=\"#2-修改-Clash-配置文件\" class=\"headerlink\" title=\"2. 修改 Clash 配置文件\"></a>2. 修改 Clash 配置文件</h3><h4 id=\"步骤1：找到配置文件路径\"><a href=\"#步骤1：找到配置文件路径\" class=\"headerlink\" title=\"步骤1：找到配置文件路径\"></a>步骤1：找到配置文件路径</h4><p>通过 <code>clash-cli status</code> 输出找到配置文件（示例：<code>/opt/clash/runtime.yaml</code>）。</p>\n<h4 id=\"步骤2：编辑配置文件\"><a href=\"#步骤2：编辑配置文件\" class=\"headerlink\" title=\"步骤2：编辑配置文件\"></a>步骤2：编辑配置文件</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> vim /opt/clash/runtime.yaml</span><br></pre></td></tr></table></figure>\n<p>修改以下核心配置（添加局域网访问+用户认证）：</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 允许局域网访问（关键：开启后本地机器才能连接）</span></span><br><span class=\"line\"><span class=\"attr\">allow-lan:</span> <span class=\"literal\">true</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 用户认证（必填！防止代理暴露公网被他人滥用）</span></span><br><span class=\"line\"><span class=\"attr\">authentication:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">&quot;user:123123&quot;</span> <span class=\"comment\"># 格式：&quot;用户名:密码&quot;，可自定义</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 端口配置（默认 7890，无需修改）</span></span><br><span class=\"line\"><span class=\"attr\">port:</span> <span class=\"number\">7890</span></span><br><span class=\"line\"><span class=\"attr\">socks-port:</span> <span class=\"number\">7891</span></span><br><span class=\"line\"><span class=\"attr\">redir-port:</span> <span class=\"number\">7892</span></span><br></pre></td></tr></table></figure>\n\n<h4 id=\"步骤3：重启服务使配置生效\"><a href=\"#步骤3：重启服务使配置生效\" class=\"headerlink\" title=\"步骤3：重启服务使配置生效\"></a>步骤3：重启服务使配置生效</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> systemctl restart mihomo</span><br><span class=\"line\"><span class=\"comment\"># 验证端口监听（显示 :::7890 表示监听所有IP）</span></span><br><span class=\"line\"><span class=\"built_in\">sudo</span> netstat -tulpn | grep 7890</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>正常输出示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tcp6       0      0 :::7890                 :::*                    LISTEN      57850/mihomo</span><br><span class=\"line\">udp6       0      0 :::7890                 :::*                                57850/mihomo</span><br></pre></td></tr></table></figure></blockquote>\n<h3 id=\"3-开放云服务器端口（必做！）\"><a href=\"#3-开放云服务器端口（必做！）\" class=\"headerlink\" title=\"3. 开放云服务器端口（必做！）\"></a>3. 开放云服务器端口（必做！）</h3><p>登录云服务器控制台（如阿里云&#x2F;腾讯云），在「安全组」中放行 7890 端口（TCP&#x2F;UDP 协议），否则本地无法连接。</p>\n<h2 id=\"四、本地机器使用云服务器代理\"><a href=\"#四、本地机器使用云服务器代理\" class=\"headerlink\" title=\"四、本地机器使用云服务器代理\"></a>四、本地机器使用云服务器代理</h2><h3 id=\"1-验证代理连通性\"><a href=\"#1-验证代理连通性\" class=\"headerlink\" title=\"1. 验证代理连通性\"></a>1. 验证代理连通性</h3><p>先通过 <code>curl</code> 测试是否能正常访问外网（替换为你的服务器IP&#x2F;账号密码）：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 测试访问 Google，验证代理是否生效</span></span><br><span class=\"line\">curl -x http://user:123123@xxx.xxx.xxx.xx:7890 https://google.com -v</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>成功标志：返回 <code>301 Moved</code> 或 Google 页面内容，无连接超时&#x2F;拒绝错误。</p>\n</blockquote>\n<h3 id=\"2-一键代理脚本（本地快捷使用）\"><a href=\"#2-一键代理脚本（本地快捷使用）\" class=\"headerlink\" title=\"2. 一键代理脚本（本地快捷使用）\"></a>2. 一键代理脚本（本地快捷使用）</h3><p>编写脚本 <code>proxyctl</code>，实现「一键开启&#x2F;关闭&#x2F;查看代理」，无需手动输配置。</p>\n<h4 id=\"步骤1：创建脚本文件\"><a href=\"#步骤1：创建脚本文件\" class=\"headerlink\" title=\"步骤1：创建脚本文件\"></a>步骤1：创建脚本文件</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim /home/zzhxx/workspace/tools/proxyctl</span><br></pre></td></tr></table></figure>\n<p>粘贴以下内容（已适配你的配置，可直接用）：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#!/bin/bash</span></span><br><span class=\"line\"><span class=\"built_in\">set</span> -e <span class=\"comment\"># 遇到错误立即退出</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ========== 自定义配置（替换为自己的信息）==========</span></span><br><span class=\"line\">PROXY_USER=<span class=\"string\">&quot;user&quot;</span></span><br><span class=\"line\">PROXY_PASS=<span class=\"string\">&quot;123123&quot;</span></span><br><span class=\"line\">PROXY_IP=<span class=\"string\">&quot;xxx.xxx.xxx.xx&quot;</span></span><br><span class=\"line\">PROXY_PORT=<span class=\"string\">&quot;7890&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># ================================================</span></span><br><span class=\"line\"></span><br><span class=\"line\">PROXY_URL=<span class=\"string\">&quot;http://<span class=\"variable\">$&#123;PROXY_USER&#125;</span>:<span class=\"variable\">$&#123;PROXY_PASS&#125;</span>@<span class=\"variable\">$&#123;PROXY_IP&#125;</span>:<span class=\"variable\">$&#123;PROXY_PORT&#125;</span>&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 执行逻辑</span></span><br><span class=\"line\"><span class=\"keyword\">case</span> <span class=\"string\">&quot;<span class=\"variable\">$1</span>&quot;</span> <span class=\"keyword\">in</span></span><br><span class=\"line\">    on)</span><br><span class=\"line\">        <span class=\"comment\"># 开启代理：清空旧变量 + 设置新变量</span></span><br><span class=\"line\">        <span class=\"built_in\">unset</span> HTTPS_PROXY HTTP_PROXY ALL_PROXY</span><br><span class=\"line\">        <span class=\"built_in\">export</span> HTTPS_PROXY=<span class=\"string\">&quot;<span class=\"variable\">$&#123;PROXY_URL&#125;</span>&quot;</span></span><br><span class=\"line\">        <span class=\"built_in\">export</span> HTTP_PROXY=<span class=\"string\">&quot;<span class=\"variable\">$&#123;PROXY_URL&#125;</span>&quot;</span></span><br><span class=\"line\">        <span class=\"built_in\">export</span> ALL_PROXY=<span class=\"string\">&quot;<span class=\"variable\">$&#123;PROXY_URL&#125;</span>&quot;</span></span><br><span class=\"line\">        <span class=\"built_in\">echo</span> -e <span class=\"string\">&quot;\\033[32m✅ 代理已开启\\033[0m&quot;</span></span><br><span class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">&quot;当前代理配置：<span class=\"variable\">$&#123;PROXY_URL&#125;</span>&quot;</span></span><br><span class=\"line\">        ;;</span><br><span class=\"line\">    off)</span><br><span class=\"line\">        <span class=\"comment\"># 关闭代理：清空所有代理变量</span></span><br><span class=\"line\">        <span class=\"built_in\">unset</span> HTTPS_PROXY HTTP_PROXY ALL_PROXY</span><br><span class=\"line\">        <span class=\"built_in\">echo</span> -e <span class=\"string\">&quot;\\033[31m❌ 代理已关闭\\033[0m&quot;</span></span><br><span class=\"line\">        ;;</span><br><span class=\"line\">    status)</span><br><span class=\"line\">        <span class=\"comment\"># 查看当前代理状态</span></span><br><span class=\"line\">        <span class=\"built_in\">echo</span> -e <span class=\"string\">&quot;📌 当前代理状态：&quot;</span></span><br><span class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">&quot;HTTPS_PROXY: <span class=\"variable\">$&#123;HTTPS_PROXY:-未设置&#125;</span>&quot;</span></span><br><span class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">&quot;HTTP_PROXY: <span class=\"variable\">$&#123;HTTP_PROXY:-未设置&#125;</span>&quot;</span></span><br><span class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">&quot;ALL_PROXY: <span class=\"variable\">$&#123;ALL_PROXY:-未设置&#125;</span>&quot;</span></span><br><span class=\"line\">        ;;</span><br><span class=\"line\">    <span class=\"built_in\">test</span>)</span><br><span class=\"line\">        <span class=\"comment\"># 新增：测试代理连通性</span></span><br><span class=\"line\">        <span class=\"built_in\">echo</span> -e <span class=\"string\">&quot;🔍 测试代理连通性...&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> curl -s -x <span class=\"string\">&quot;<span class=\"variable\">$&#123;PROXY_URL&#125;</span>&quot;</span> https://google.com &gt; /dev/null; <span class=\"keyword\">then</span></span><br><span class=\"line\">            <span class=\"built_in\">echo</span> -e <span class=\"string\">&quot;\\033[32m✅ 代理可用\\033[0m&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">            <span class=\"built_in\">echo</span> -e <span class=\"string\">&quot;\\033[31m❌ 代理不可用\\033[0m&quot;</span></span><br><span class=\"line\">            <span class=\"built_in\">exit</span> 1</span><br><span class=\"line\">        <span class=\"keyword\">fi</span></span><br><span class=\"line\">        ;;</span><br><span class=\"line\">    *)</span><br><span class=\"line\">        <span class=\"comment\"># 帮助信息</span></span><br><span class=\"line\">        <span class=\"built_in\">echo</span> -e <span class=\"string\">&quot;📚 用法：&quot;</span></span><br><span class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">&quot;  proxyctl on      - 开启代理&quot;</span></span><br><span class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">&quot;  proxyctl off     - 关闭代理&quot;</span></span><br><span class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">&quot;  proxyctl status  - 查看代理状态&quot;</span></span><br><span class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">&quot;  proxyctl test    - 测试代理连通性&quot;</span></span><br><span class=\"line\">        ;;</span><br><span class=\"line\"><span class=\"keyword\">esac</span></span><br></pre></td></tr></table></figure>\n\n<h4 id=\"步骤2：添加执行权限\"><a href=\"#步骤2：添加执行权限\" class=\"headerlink\" title=\"步骤2：添加执行权限\"></a>步骤2：添加执行权限</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">chmod</span> +x /home/zzhxx/workspace/tools/proxyctl</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"步骤3：设置别名（永久生效）\"><a href=\"#步骤3：设置别名（永久生效）\" class=\"headerlink\" title=\"步骤3：设置别名（永久生效）\"></a>步骤3：设置别名（永久生效）</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 临时生效（当前终端）</span></span><br><span class=\"line\"><span class=\"built_in\">alias</span> proxyctl=<span class=\"string\">&quot;sh /home/zzhxx/workspace/tools/proxyctl&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 永久生效（所有终端），添加到 ~/.bashrc 或 ~/.zshrc</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">&quot;alias proxyctl=&#x27;/home/zzhxx/workspace/tools/proxyctl&#x27;&quot;</span> &gt;&gt; ~/.bashrc</span><br><span class=\"line\"><span class=\"built_in\">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"步骤4：使用示例\"><a href=\"#步骤4：使用示例\" class=\"headerlink\" title=\"步骤4：使用示例\"></a>步骤4：使用示例</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 开启代理</span></span><br><span class=\"line\">proxyctl on</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 查看状态</span></span><br><span class=\"line\">proxyctl status</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 测试连通性</span></span><br><span class=\"line\">proxyctl <span class=\"built_in\">test</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 关闭代理</span></span><br><span class=\"line\">proxyctl off</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"3-额外实用脚本（可选）\"><a href=\"#3-额外实用脚本（可选）\" class=\"headerlink\" title=\"3. 额外实用脚本（可选）\"></a>3. 额外实用脚本（可选）</h3><p>停止并删除 Docker 容器的快捷脚本（补充）：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#!/bin/bash</span></span><br><span class=\"line\"><span class=\"comment\"># 检查参数是否传入</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> [ -z <span class=\"string\">&quot;<span class=\"variable\">$1</span>&quot;</span> ]; <span class=\"keyword\">then</span></span><br><span class=\"line\">    <span class=\"built_in\">echo</span> -e <span class=\"string\">&quot;\\033[31m❌ 请传入容器名/ID\\033[0m&quot;</span></span><br><span class=\"line\">    <span class=\"built_in\">echo</span> <span class=\"string\">&quot;用法：docker-rm 容器名/ID&quot;</span></span><br><span class=\"line\">    <span class=\"built_in\">exit</span> 1</span><br><span class=\"line\"><span class=\"keyword\">fi</span></span><br><span class=\"line\"></span><br><span class=\"line\">name=<span class=\"variable\">$1</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> -e <span class=\"string\">&quot;🔧 停止并删除容器：<span class=\"variable\">$&#123;name&#125;</span>&quot;</span></span><br><span class=\"line\">docker stop <span class=\"variable\">$&#123;name&#125;</span> &amp;&amp; docker <span class=\"built_in\">rm</span> <span class=\"variable\">$&#123;name&#125;</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> -e <span class=\"string\">&quot;\\033[32m✅ 操作完成\\033[0m&quot;</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"五、避坑要点\"><a href=\"#五、避坑要点\" class=\"headerlink\" title=\"五、避坑要点\"></a>五、避坑要点</h2><ol>\n<li><strong>权限问题</strong>：修改 Clash 配置文件需 <code>sudo</code>，否则保存失败；</li>\n<li><strong>安全风险</strong>：开启 <code>allow-lan: true</code> 后必须加 <code>authentication</code>，否则代理可能被全网滥用；</li>\n<li><strong>端口放行</strong>：云服务器安全组未开 7890 端口，本地会提示「连接拒绝」；</li>\n<li><strong>脚本生效</strong>：设置别名后需 <code>source ~/.bashrc</code>，否则新终端不生效；</li>\n<li><strong>代理范围</strong>：脚本仅对当前终端生效，如需全局代理需配置系统网络。</li>\n</ol>\n<hr>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><ol>\n<li>核心流程：云服务器安装 <code>clash-cli</code> → 配置局域网访问+认证 → 开放端口 → 本地用脚本一键复用；</li>\n<li>关键避坑：开启局域网访问必须加用户认证，云服务器安全组需放行 7890 端口；</li>\n<li>效率优化：本地脚本实现「开启&#x2F;关闭&#x2F;测试」一体化，无需重复输入复杂代理地址。</li>\n</ol>\n"},{"title":"Kubernetes 调度器原理与自定义插件开发实践","date":"2024-05-14T16:00:00.000Z","updated":"2025-11-14T16:00:00.000Z","description":"详细介绍 Kubernetes 调度器的原理和自定义插件开发实践，帮助读者理解和掌握 Kubernetes 集群资源调度的机制。","keywords":"k8s, scheduler, 调度器, 原理, 自定义插件, 开发实践","_content":"\n## 一、背景介绍\n\n`kube-scheduler` 是 Kubernetes 集群的核心组件之一，主要负责集群资源的调度功能。它通过特定的调度算法和策略，将 Pod 分配到最优的工作节点（Node）上，从而实现集群资源的合理利用和充分分配，这也是我们选择使用 Kubernetes 的重要理由之一。\n\n默认情况下，`kube-scheduler` 提供的原生调度器能够满足绝大多数业务场景，确保 Pod 被分配到资源充足的节点运行。但在实际的生产环境中，业务逻辑往往更加复杂。例如，我们可能需要将某类 Pod 严格限制在特定的节点上运行，或者某些节点只能用于运行特定类型的应用。为了满足这些精细化的需求，我们需要深入理解 Kubernetes 的调度机制，并掌握编写自定义调度插件（Scheduling Plugins）的能力。\n\n## 二、Kubernetes Pod 部署流程\n\n![Pod 部署流程](/images/k8s-scheduler/image-20260202015836525.png)\n\nKubernetes 中 Pod 的总体部署流程如图所示，大致包含以下步骤：\n\n1.  **提交请求**：用户编写好 YAML 配置文件，向 `kube-apiserver` 提交创建请求。\n2.  **准入控制**：`kube-apiserver` 接收到请求后，首先通过 Webhooks 和 Controllers 进行一系列校验（准入控制）。\n3.  **生成 Pod 对象**：校验通过后，`kube-apiserver` 在集群中生成一个 Pod 对象。此时，该 Pod 的 `nodeName` 字段为空，状态（Phase）为 `Pending`。\n4.  **调度过程**：\n    *   `kube-scheduler` 通过 Watch 机制监听到集群中出现了 `nodeName` 为空的 Pod，将其标记为“未调度”状态。\n    *   调度器对该 Pod 执行一系列调度算法，包括过滤（Filter）和打分（Score）。\n    *   选出最合适的节点后，调度器将该节点的名称绑定到 Pod 的 `spec.nodeName` 上，完成调度并更新数据到 API Server。\n5.  **节点执行**：\n    *   目标节点上的 `kubelet` 监听到该 Pod 被分配给自己。\n    *   `kubelet` 开始执行容器创建、存储挂载、网络配置等操作。\n    *   所有资源准备就绪后，Pod 状态更新为 `Running`，至此，一个完整的调度部署过程结束。\n\n![调度流程概览](/images/k8s-scheduler/image-20260202015902141.png)\n\n## 三、调度流程概览\n\n![调度详细流程](/images/k8s-scheduler/image-20260202015909730.png)\n\n调度器的核心工作流程涉及多个组件的协同，主要包括输入源、策略控制、数据缓存和核心算法流水线。\n\n### 1. 输入来源与配置\n*   **FlagSet / File**：通过命令行参数或配置文件指定调度器参数。\n*   **ConfigMap**：存储非敏感的配置数据，用于动态调整。\n\n### 2. 调度策略 (Policy)\n*   **过滤器 (Predicates)**：快速筛选出符合硬性条件的节点。\n*   **打分器 (Priorities)**：对筛选后的节点进行优先级打分。\n*   **扩展调度器 (Extenders)**：支持外部自定义的 HTTP 回调式调度策略。\n*   **插件扩展点 (Plugins)**：当前主流的 Scheduler Framework 扩展机制。\n\n### 3. 数据缓存 (Informer)\n调度器启动时，通过 Kubernetes 的 Informer 机制（List+Watch）从 `kube-apiserver` 获取 Pods、Nodes、PV、PVC 等数据，并将这些数据预处理后存储在调度器的本地 Cache 中，以提高调度性能。\n\n### 4. 调度算法流水线 (Algorithm)\n调度工作流主要由三个并发线程模型组成：\n\n*   **Scheduler Thread（调度主线程）**：\n    核心调度逻辑在此执行，大致流程为：`PreFilter` -> `Filter` -> `PostFilter` -> `Score` -> `Reserve`。\n    *   **Filter**：筛选符合 Pod Spec 要求的节点。\n    *   **Score**：对筛选出的节点进行打分排序。\n    *   **Reserve**：将 Pod 与最优节点的关联信息写入 NodeCache（内存态预占），让后续等待调度的 Pod 能感知到资源已被占用。\n\n*   **Wait Thread（等待线程）**：\n    用于处理需等待的关联资源。例如等待 PVC 对应的 PV 创建成功，或在 Gang 调度中等待关联 Pod 组一同就绪。此阶段会进行 Permit（许可）检查。\n\n*   **Bind Thread（绑定线程）**：\n    负责将 Pod 与 Node 的绑定关系持久化到 `kube-apiserver`。调度完成后，会更新 Scheduler Cache（如 Pod 和 Node 的缓存数据）。\n\n## 四、调度详细流程\n\n![调度流水线](/images/k8s-scheduler/image-20260202020113094.png)\n\n深入剖析 Scheduler Pipeline 的工作原理，我们可以看到更细致的队列管理和数据流转。\n\n### 1. 调度队列 (SchedulingQueue)\n调度队列包含三个子队列：\n\n*   **activeQ（活跃队列）**：\n    调度器启动时，所有待调度的 Pod 首先进入此队列。它是一个优先队列，按照 Pod 优先级进行排序出队。\n*   **backoffQ（退避队列）**：\n    当 Pod 因暂时性原因（如资源短缺、调度冲突）调度失败，或调度过程中 Cache 发生变化时，会进入此队列。该队列采用**指数退避**策略（例如重试间隔依次为 1s, 2s, 4s, ..., max 10s），避免在资源不可用时频繁无效重试。\n*   **unschedulableQ（不可调度队列）**：\n    当 Pod 因持久性原因（如请求的资源总量超过集群上限）无法调度时进入此队列。通常需等待集群状态发生显著变化（如新节点加入、PV 释放）才会被移出。该队列每 30s 轮询一次，或者如果 Pod 停留超过 60s，也会被尝试重新移回 `activeQ`。\n\n### 2. 调度流水线执行逻辑\n*   **采样与过滤**：\n    在 Filter 阶段，如果集群节点规模巨大，调度器通过**采样算法**（配置比例）选取部分节点进行过滤和打分，而非全量遍历，从而提升效率。\n*   **容灾与分散**：\n    为保证高可用，NodeCache 中的节点是按 Zone（可用区）分组的。在筛选节点时，调度器维护一个 `zoneIndex` 和 `nodeIndex`。\n    *   **逻辑**：`zoneIndex` 从左向右轮询，`nodeIndex` 自增。即每次从不同的 Zone 中取一个 Node 进行判断。\n    *   **目的**：确保筛选出的候选节点在物理区域上足够分散，避免单点故障。\n*   **预占与绑定**：\n    当 Filter 和 Score 阶段选出最优节点（SelectHost）后，进入 **Reserve** 阶段。此时修改 Pod 在 PodCache 中的状态为 `Assumed`（内存预占）。随后进入 **Bind** 阶段，调用 API Server 将 `nodeName` 持久化到 etcd。只有当 Informer 监听到持久化成功的数据后，Pod 状态才会转变为 `Added`。\n\n## 五、K8s 自定义调度插件扩展点\n\nKubernetes 推出了 **Scheduling Framework**，将调度过程定义为架构良好的“扩展点”（Extension Points）。用户只需实现特定接口（Interface）并注册到对应的扩展点，即可在不修改核心代码的情况下定制调度逻辑。\n\n![K8s 自定义调度插件扩展点](/images/k8s-scheduler/image-20260202020144193.png)\n\n一个完整的调度周期分为 **Scheduling Cycle**（调度周期，纯内存操作）和 **Binding Cycle**（绑定周期，涉及外部调用）。主要扩展点如下：\n\n1.  **QueueSort**：决定 Pod 在 `activeQ` 中的排序规则（即优先级）。同一时刻只能启用一个 Sort 插件。\n2.  **Pre-filter**：调度前的预处理，可检查集群或 Pod 的前置条件。若返回 Error，调度终止。\n3.  **Filter**：**核心扩展点**。用于过滤不符合要求的节点。任何一个 Filter 插件返回失败，该节点即被排除。\n4.  **Post-filter**：通知型扩展点。通常用于处理 Filter 失败后的逻辑（如触发抢占 Preemption）。\n5.  **Scoring**：**核心扩展点**。对 Filter 后的节点进行打分。\n6.  **Normalize scoring**：在最终排序前，对分值进行归一化处理或修正。\n7.  **Reserve**：通知型扩展点。在绑定前锁定资源，防止资源超卖。\n8.  **Permit**：用于阻止或延迟绑定。支持 Approve（批准）、Deny（拒绝）或 Wait（等待）三种操作（常用于 Gang 调度）。\n9.  **Pre-bind**：绑定前的执行逻辑，例如挂载网络卷。\n10. **Bind**：**核心扩展点**。执行真正的绑定操作（将 Pod 绑定到 Node）。\n11. **Post-bind**：绑定成功后的通知，常用于资源清理。\n12. **Unreserve**：若在 Reserve 之后绑定失败，触发此扩展点以释放预占资源。\n\n**开发提示**：\n*   一个插件（Plugin）可以同时实现多个扩展点接口（如既实现 Filter 又实现 Score）。\n*   这些插件基于 Go Plugin 机制，通常需要在编译阶段静态链接到调度器二进制文件中。\n*   源码接口定义位于：`pkg/scheduler/framework/v1alpha1/interface.go`。\n\n## 六、实践：编写一个简单的 HelloWorld 插件\n\n本示例将开发一个简单的调度插件 `helloworld`，其逻辑是：**强制将 Pod 调度到名称为 `k8s-node1` 的节点上**，否则调度失败。\n\n此示例主要演示插件的注册与部署流程（In-Tree 模式）。\n\n### 1. 编写插件源码\n在 Kubernetes 源码目录 `pkg/scheduler/framework/plugins` 下创建 `helloworld` 文件夹，并新建 `helloworld.go`：\n\n```go\npackage helloworld\n\nimport (\n    \"context\"\n    v1 \"k8s.io/api/core/v1\"\n    \"k8s.io/apimachinery/pkg/runtime\"\n    \"k8s.io/kubernetes/pkg/scheduler/framework\"\n)\n\nconst (\n    Name           = \"helloWorld\"\n    targetNodeName = \"k8s-node1\"\n)\n\ntype helloWorld struct{}\n\n// 确保 helloWorld 实现了 FilterPlugin 接口\nvar _ framework.FilterPlugin = &helloWorld{}\n\nfunc (f *helloWorld) Name() string {\n    return Name\n}\n\n// 核心逻辑：只允许调度到 targetNodeName\nfunc (f *helloWorld) Filter(ctx context.Context, _ *framework.CycleState, pod *v1.Pod, nodeInfo *framework.NodeInfo) *framework.Status {\n    if nodeInfo.Node().Name == targetNodeName {\n        return nil \n    }\n    return framework.NewStatus(framework.Unschedulable, \"Pod can only be scheduled to the specific node: \"+targetNodeName)\n}\n\nfunc New(ctx context.Context, _ runtime.Object, _ framework.Handle) (framework.Plugin, error) {\n    return &helloWorld{}, nil\n}\n```\n\n### 2. 注册插件\n修改 `pkg/scheduler/framework/plugins/registry.go` 文件，将插件注册到调度器注册表中：\n\n```go\nimport(\n    ...        \n    \"k8s.io/kubernetes/pkg/scheduler/framework/plugins/helloworld\" // 引入包\n    ...\n)\n\nfunc NewInTreeRegistry() runtime.Registry {\n    ...\n    registry := runtime.Registry{\n        ...        \n        helloworld.Name: helloworld.New, // 注册插件\n    }\n    return registry\n}\n```\n\n### 3. 编译与构建镜像\n你需要具备 Kubernetes 源码编译环境。\n\n```bash\n# 切换到 k8s 源码目录并编译 kube-scheduler\ncd $GOPATH/src/k8s.io/kubernetes\nmake WHAT=cmd/kube-scheduler\n\n# 编写 Dockerfile\ncat <<EOF > Dockerfile\nFROM busybox\nADD ./_output/local/bin/linux/amd64/kube-scheduler /usr/local/bin/kube-scheduler\nEOF\n\n# 构建并推送镜像 (请替换为你自己的镜像仓库地址)\ndocker build -t registry.cn-hangzhou.aliyuncs.com/zzhxxx/helloworld-scheduler:1.0 .\ndocker push registry.cn-hangzhou.aliyuncs.com/zzhxxx/helloworld-scheduler:1.0\n```\n\n### 4. 部署自定义调度器\n编写 `hello-world-scheduler.yaml`，包含 RBAC 设置、ConfigMap 配置及 Deployment 部署。\n\n**关键点**：在 ConfigMap 中通过 `KubeSchedulerConfiguration` 启用我们编写的 `helloWorld` 插件。\n\n```yaml\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: hello-world-scheduler\n  namespace: kube-system\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: hello-world-scheduler-as-kube-scheduler\nsubjects:\n- kind: ServiceAccount\n  name: hello-world-scheduler\n  namespace: kube-system\nroleRef:\n  kind: ClusterRole\n  name: system:kube-scheduler\n  apiGroup: rbac.authorization.k8s.io\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: hello-world-scheduler-config\n  namespace: kube-system\ndata:\n  hello-world-scheduler-config.yaml: |\n    apiVersion: kubescheduler.config.k8s.io/v1\n    kind: KubeSchedulerConfiguration\n    profiles:\n      - schedulerName: hello-world-scheduler # 自定义调度器名称\n        plugins:\n          filter: \n            enabled:\n              - name: helloWorld # 启用我们的插件\n        pluginConfig:\n          - name: helloworld\n            args:\n              customArgument: \"value\"\n    leaderElection:\n      leaderElect: false    \n---\n# 省略 ClusterRole 部分，通常与默认 scheduler 权限一致\n# (请确保包含 nodes, pods, bindings 等资源的访问权限)\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: hello-world-scheduler\nrules:\n- apiGroups: [\"\"]\n  resources: [\"nodes\", \"pods\", \"bindings\", \"pods/binding\", \"configmaps\"]\n  verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n# ... (其他必要权限)\n---\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: hello-world-scheduler\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: hello-world-scheduler\nsubjects:\n- kind: ServiceAccount\n  name: hello-world-scheduler\n  namespace: kube-system\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello-world-scheduler\n  namespace: kube-system\n  labels:\n    component: scheduler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: scheduler\n  template:\n    metadata:\n      labels:\n        component: scheduler\n    spec:\n      serviceAccountName: hello-world-scheduler\n      containers:\n      - name: hello-world-scheduler\n        image: registry.cn-hangzhou.aliyuncs.com/zzhxxx/helloworld-scheduler:1.0\n        command:\n        - /usr/local/bin/kube-scheduler\n        - --config=/etc/kubernetes/hello-world-scheduler/hello-world-scheduler-config.yaml\n        volumeMounts:\n          - name: config-volume\n            mountPath: /etc/kubernetes/hello-world-scheduler\n      volumes:\n        - name: config-volume\n          configMap:\n            name: hello-world-scheduler-config\n```\n\n### 5. 验证与测试\n\n**应用配置：**\n```bash\nkubectl create -f hello-world-Scheduler.yaml\n```\n\n**检查运行状态：**\n```bash\nkubectl get pod -n kube-system -l component=scheduler\n# 如遇问题，请查看日志\nkubectl logs -n kube-system <pod-name>\n```\n\n**创建测试 Pod：**\n创建一个指定使用 `hello-world-scheduler` 的 Pod。\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pod1\nspec:\n  schedulerName: hello-world-scheduler # 指定使用我们部署的调度器\n  containers:\n  - name: nginx\n    image: nginx\n```\n\n**验证结果：**\n1.  **成功调度**：查看 Pod 事件，确认是否被调度到 `k8s-node1`。\n    ```bash\n    kubectl describe pod pod1\n    ```\n    输出示例：\n    > Normal  Scheduled  ...  hello-world-scheduler  Successfully assigned default/pod1 to k8s-node1\n\n2.  **故障测试**：\n    *   将 `k8s-node1` 关机或标记为不可调度。\n    *   删除并重建 `pod1`。\n    *   观察 Pod 状态，应处于 `Pending` 状态，且 Event 提示调度失败（NodeNotReady 或类似原因），证明我们的 Filter 逻辑生效，确实只允许调度到该节点。\n\n---\n\n\n### reference：\n\n>k8s 官网：\nhttps://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/\nhttps://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/scheduling-framework/\nhttps://kubernetes.io/zh-cn/docs/reference/scheduling/\n\n> out-of-tree plugin 开发方式\n> https://github.com/kubernetes-sigs/scheduler-plugins/blob/master/doc/install.md#create-a-kubernetes-cluster\n> https://github.com/kubernetes-sigs/scheduler-plugins\n\n>  实践博客：\n> https://arthurchiao.art/blog/k8s-scheduling-plugins-zh/\n> https://isekiro.com/kubernetes%E7%BB%84%E4%BB%B6%E5%BC%80%E5%8F%91-%E8%87%AA%E5%AE%9A%E4%B9%89%E8%B0%83%E5%BA%A6%E5%99%A8%E4%B8%89/\n> https://zhuanlan.zhihu.com/p/113620537\n> http://team.jiunile.com/blog/2020/06/k8s-custom-scheduler.html\n> https://blog.haohtml.com/archives/34665  ","source":"_posts/k8s-scheduler.md","raw":"---\ntitle: Kubernetes 调度器原理与自定义插件开发实践\ndate: 2024-05-15\nupdated: 2025-11-15\ntags: \n  - k8s\n  - scheduler\ncategory: 技术教程\ndescription: 详细介绍 Kubernetes 调度器的原理和自定义插件开发实践，帮助读者理解和掌握 Kubernetes 集群资源调度的机制。\nkeywords: k8s, scheduler, 调度器, 原理, 自定义插件, 开发实践\n---\n\n## 一、背景介绍\n\n`kube-scheduler` 是 Kubernetes 集群的核心组件之一，主要负责集群资源的调度功能。它通过特定的调度算法和策略，将 Pod 分配到最优的工作节点（Node）上，从而实现集群资源的合理利用和充分分配，这也是我们选择使用 Kubernetes 的重要理由之一。\n\n默认情况下，`kube-scheduler` 提供的原生调度器能够满足绝大多数业务场景，确保 Pod 被分配到资源充足的节点运行。但在实际的生产环境中，业务逻辑往往更加复杂。例如，我们可能需要将某类 Pod 严格限制在特定的节点上运行，或者某些节点只能用于运行特定类型的应用。为了满足这些精细化的需求，我们需要深入理解 Kubernetes 的调度机制，并掌握编写自定义调度插件（Scheduling Plugins）的能力。\n\n## 二、Kubernetes Pod 部署流程\n\n![Pod 部署流程](/images/k8s-scheduler/image-20260202015836525.png)\n\nKubernetes 中 Pod 的总体部署流程如图所示，大致包含以下步骤：\n\n1.  **提交请求**：用户编写好 YAML 配置文件，向 `kube-apiserver` 提交创建请求。\n2.  **准入控制**：`kube-apiserver` 接收到请求后，首先通过 Webhooks 和 Controllers 进行一系列校验（准入控制）。\n3.  **生成 Pod 对象**：校验通过后，`kube-apiserver` 在集群中生成一个 Pod 对象。此时，该 Pod 的 `nodeName` 字段为空，状态（Phase）为 `Pending`。\n4.  **调度过程**：\n    *   `kube-scheduler` 通过 Watch 机制监听到集群中出现了 `nodeName` 为空的 Pod，将其标记为“未调度”状态。\n    *   调度器对该 Pod 执行一系列调度算法，包括过滤（Filter）和打分（Score）。\n    *   选出最合适的节点后，调度器将该节点的名称绑定到 Pod 的 `spec.nodeName` 上，完成调度并更新数据到 API Server。\n5.  **节点执行**：\n    *   目标节点上的 `kubelet` 监听到该 Pod 被分配给自己。\n    *   `kubelet` 开始执行容器创建、存储挂载、网络配置等操作。\n    *   所有资源准备就绪后，Pod 状态更新为 `Running`，至此，一个完整的调度部署过程结束。\n\n![调度流程概览](/images/k8s-scheduler/image-20260202015902141.png)\n\n## 三、调度流程概览\n\n![调度详细流程](/images/k8s-scheduler/image-20260202015909730.png)\n\n调度器的核心工作流程涉及多个组件的协同，主要包括输入源、策略控制、数据缓存和核心算法流水线。\n\n### 1. 输入来源与配置\n*   **FlagSet / File**：通过命令行参数或配置文件指定调度器参数。\n*   **ConfigMap**：存储非敏感的配置数据，用于动态调整。\n\n### 2. 调度策略 (Policy)\n*   **过滤器 (Predicates)**：快速筛选出符合硬性条件的节点。\n*   **打分器 (Priorities)**：对筛选后的节点进行优先级打分。\n*   **扩展调度器 (Extenders)**：支持外部自定义的 HTTP 回调式调度策略。\n*   **插件扩展点 (Plugins)**：当前主流的 Scheduler Framework 扩展机制。\n\n### 3. 数据缓存 (Informer)\n调度器启动时，通过 Kubernetes 的 Informer 机制（List+Watch）从 `kube-apiserver` 获取 Pods、Nodes、PV、PVC 等数据，并将这些数据预处理后存储在调度器的本地 Cache 中，以提高调度性能。\n\n### 4. 调度算法流水线 (Algorithm)\n调度工作流主要由三个并发线程模型组成：\n\n*   **Scheduler Thread（调度主线程）**：\n    核心调度逻辑在此执行，大致流程为：`PreFilter` -> `Filter` -> `PostFilter` -> `Score` -> `Reserve`。\n    *   **Filter**：筛选符合 Pod Spec 要求的节点。\n    *   **Score**：对筛选出的节点进行打分排序。\n    *   **Reserve**：将 Pod 与最优节点的关联信息写入 NodeCache（内存态预占），让后续等待调度的 Pod 能感知到资源已被占用。\n\n*   **Wait Thread（等待线程）**：\n    用于处理需等待的关联资源。例如等待 PVC 对应的 PV 创建成功，或在 Gang 调度中等待关联 Pod 组一同就绪。此阶段会进行 Permit（许可）检查。\n\n*   **Bind Thread（绑定线程）**：\n    负责将 Pod 与 Node 的绑定关系持久化到 `kube-apiserver`。调度完成后，会更新 Scheduler Cache（如 Pod 和 Node 的缓存数据）。\n\n## 四、调度详细流程\n\n![调度流水线](/images/k8s-scheduler/image-20260202020113094.png)\n\n深入剖析 Scheduler Pipeline 的工作原理，我们可以看到更细致的队列管理和数据流转。\n\n### 1. 调度队列 (SchedulingQueue)\n调度队列包含三个子队列：\n\n*   **activeQ（活跃队列）**：\n    调度器启动时，所有待调度的 Pod 首先进入此队列。它是一个优先队列，按照 Pod 优先级进行排序出队。\n*   **backoffQ（退避队列）**：\n    当 Pod 因暂时性原因（如资源短缺、调度冲突）调度失败，或调度过程中 Cache 发生变化时，会进入此队列。该队列采用**指数退避**策略（例如重试间隔依次为 1s, 2s, 4s, ..., max 10s），避免在资源不可用时频繁无效重试。\n*   **unschedulableQ（不可调度队列）**：\n    当 Pod 因持久性原因（如请求的资源总量超过集群上限）无法调度时进入此队列。通常需等待集群状态发生显著变化（如新节点加入、PV 释放）才会被移出。该队列每 30s 轮询一次，或者如果 Pod 停留超过 60s，也会被尝试重新移回 `activeQ`。\n\n### 2. 调度流水线执行逻辑\n*   **采样与过滤**：\n    在 Filter 阶段，如果集群节点规模巨大，调度器通过**采样算法**（配置比例）选取部分节点进行过滤和打分，而非全量遍历，从而提升效率。\n*   **容灾与分散**：\n    为保证高可用，NodeCache 中的节点是按 Zone（可用区）分组的。在筛选节点时，调度器维护一个 `zoneIndex` 和 `nodeIndex`。\n    *   **逻辑**：`zoneIndex` 从左向右轮询，`nodeIndex` 自增。即每次从不同的 Zone 中取一个 Node 进行判断。\n    *   **目的**：确保筛选出的候选节点在物理区域上足够分散，避免单点故障。\n*   **预占与绑定**：\n    当 Filter 和 Score 阶段选出最优节点（SelectHost）后，进入 **Reserve** 阶段。此时修改 Pod 在 PodCache 中的状态为 `Assumed`（内存预占）。随后进入 **Bind** 阶段，调用 API Server 将 `nodeName` 持久化到 etcd。只有当 Informer 监听到持久化成功的数据后，Pod 状态才会转变为 `Added`。\n\n## 五、K8s 自定义调度插件扩展点\n\nKubernetes 推出了 **Scheduling Framework**，将调度过程定义为架构良好的“扩展点”（Extension Points）。用户只需实现特定接口（Interface）并注册到对应的扩展点，即可在不修改核心代码的情况下定制调度逻辑。\n\n![K8s 自定义调度插件扩展点](/images/k8s-scheduler/image-20260202020144193.png)\n\n一个完整的调度周期分为 **Scheduling Cycle**（调度周期，纯内存操作）和 **Binding Cycle**（绑定周期，涉及外部调用）。主要扩展点如下：\n\n1.  **QueueSort**：决定 Pod 在 `activeQ` 中的排序规则（即优先级）。同一时刻只能启用一个 Sort 插件。\n2.  **Pre-filter**：调度前的预处理，可检查集群或 Pod 的前置条件。若返回 Error，调度终止。\n3.  **Filter**：**核心扩展点**。用于过滤不符合要求的节点。任何一个 Filter 插件返回失败，该节点即被排除。\n4.  **Post-filter**：通知型扩展点。通常用于处理 Filter 失败后的逻辑（如触发抢占 Preemption）。\n5.  **Scoring**：**核心扩展点**。对 Filter 后的节点进行打分。\n6.  **Normalize scoring**：在最终排序前，对分值进行归一化处理或修正。\n7.  **Reserve**：通知型扩展点。在绑定前锁定资源，防止资源超卖。\n8.  **Permit**：用于阻止或延迟绑定。支持 Approve（批准）、Deny（拒绝）或 Wait（等待）三种操作（常用于 Gang 调度）。\n9.  **Pre-bind**：绑定前的执行逻辑，例如挂载网络卷。\n10. **Bind**：**核心扩展点**。执行真正的绑定操作（将 Pod 绑定到 Node）。\n11. **Post-bind**：绑定成功后的通知，常用于资源清理。\n12. **Unreserve**：若在 Reserve 之后绑定失败，触发此扩展点以释放预占资源。\n\n**开发提示**：\n*   一个插件（Plugin）可以同时实现多个扩展点接口（如既实现 Filter 又实现 Score）。\n*   这些插件基于 Go Plugin 机制，通常需要在编译阶段静态链接到调度器二进制文件中。\n*   源码接口定义位于：`pkg/scheduler/framework/v1alpha1/interface.go`。\n\n## 六、实践：编写一个简单的 HelloWorld 插件\n\n本示例将开发一个简单的调度插件 `helloworld`，其逻辑是：**强制将 Pod 调度到名称为 `k8s-node1` 的节点上**，否则调度失败。\n\n此示例主要演示插件的注册与部署流程（In-Tree 模式）。\n\n### 1. 编写插件源码\n在 Kubernetes 源码目录 `pkg/scheduler/framework/plugins` 下创建 `helloworld` 文件夹，并新建 `helloworld.go`：\n\n```go\npackage helloworld\n\nimport (\n    \"context\"\n    v1 \"k8s.io/api/core/v1\"\n    \"k8s.io/apimachinery/pkg/runtime\"\n    \"k8s.io/kubernetes/pkg/scheduler/framework\"\n)\n\nconst (\n    Name           = \"helloWorld\"\n    targetNodeName = \"k8s-node1\"\n)\n\ntype helloWorld struct{}\n\n// 确保 helloWorld 实现了 FilterPlugin 接口\nvar _ framework.FilterPlugin = &helloWorld{}\n\nfunc (f *helloWorld) Name() string {\n    return Name\n}\n\n// 核心逻辑：只允许调度到 targetNodeName\nfunc (f *helloWorld) Filter(ctx context.Context, _ *framework.CycleState, pod *v1.Pod, nodeInfo *framework.NodeInfo) *framework.Status {\n    if nodeInfo.Node().Name == targetNodeName {\n        return nil \n    }\n    return framework.NewStatus(framework.Unschedulable, \"Pod can only be scheduled to the specific node: \"+targetNodeName)\n}\n\nfunc New(ctx context.Context, _ runtime.Object, _ framework.Handle) (framework.Plugin, error) {\n    return &helloWorld{}, nil\n}\n```\n\n### 2. 注册插件\n修改 `pkg/scheduler/framework/plugins/registry.go` 文件，将插件注册到调度器注册表中：\n\n```go\nimport(\n    ...        \n    \"k8s.io/kubernetes/pkg/scheduler/framework/plugins/helloworld\" // 引入包\n    ...\n)\n\nfunc NewInTreeRegistry() runtime.Registry {\n    ...\n    registry := runtime.Registry{\n        ...        \n        helloworld.Name: helloworld.New, // 注册插件\n    }\n    return registry\n}\n```\n\n### 3. 编译与构建镜像\n你需要具备 Kubernetes 源码编译环境。\n\n```bash\n# 切换到 k8s 源码目录并编译 kube-scheduler\ncd $GOPATH/src/k8s.io/kubernetes\nmake WHAT=cmd/kube-scheduler\n\n# 编写 Dockerfile\ncat <<EOF > Dockerfile\nFROM busybox\nADD ./_output/local/bin/linux/amd64/kube-scheduler /usr/local/bin/kube-scheduler\nEOF\n\n# 构建并推送镜像 (请替换为你自己的镜像仓库地址)\ndocker build -t registry.cn-hangzhou.aliyuncs.com/zzhxxx/helloworld-scheduler:1.0 .\ndocker push registry.cn-hangzhou.aliyuncs.com/zzhxxx/helloworld-scheduler:1.0\n```\n\n### 4. 部署自定义调度器\n编写 `hello-world-scheduler.yaml`，包含 RBAC 设置、ConfigMap 配置及 Deployment 部署。\n\n**关键点**：在 ConfigMap 中通过 `KubeSchedulerConfiguration` 启用我们编写的 `helloWorld` 插件。\n\n```yaml\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: hello-world-scheduler\n  namespace: kube-system\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: hello-world-scheduler-as-kube-scheduler\nsubjects:\n- kind: ServiceAccount\n  name: hello-world-scheduler\n  namespace: kube-system\nroleRef:\n  kind: ClusterRole\n  name: system:kube-scheduler\n  apiGroup: rbac.authorization.k8s.io\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: hello-world-scheduler-config\n  namespace: kube-system\ndata:\n  hello-world-scheduler-config.yaml: |\n    apiVersion: kubescheduler.config.k8s.io/v1\n    kind: KubeSchedulerConfiguration\n    profiles:\n      - schedulerName: hello-world-scheduler # 自定义调度器名称\n        plugins:\n          filter: \n            enabled:\n              - name: helloWorld # 启用我们的插件\n        pluginConfig:\n          - name: helloworld\n            args:\n              customArgument: \"value\"\n    leaderElection:\n      leaderElect: false    \n---\n# 省略 ClusterRole 部分，通常与默认 scheduler 权限一致\n# (请确保包含 nodes, pods, bindings 等资源的访问权限)\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: hello-world-scheduler\nrules:\n- apiGroups: [\"\"]\n  resources: [\"nodes\", \"pods\", \"bindings\", \"pods/binding\", \"configmaps\"]\n  verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n# ... (其他必要权限)\n---\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: hello-world-scheduler\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: hello-world-scheduler\nsubjects:\n- kind: ServiceAccount\n  name: hello-world-scheduler\n  namespace: kube-system\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello-world-scheduler\n  namespace: kube-system\n  labels:\n    component: scheduler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: scheduler\n  template:\n    metadata:\n      labels:\n        component: scheduler\n    spec:\n      serviceAccountName: hello-world-scheduler\n      containers:\n      - name: hello-world-scheduler\n        image: registry.cn-hangzhou.aliyuncs.com/zzhxxx/helloworld-scheduler:1.0\n        command:\n        - /usr/local/bin/kube-scheduler\n        - --config=/etc/kubernetes/hello-world-scheduler/hello-world-scheduler-config.yaml\n        volumeMounts:\n          - name: config-volume\n            mountPath: /etc/kubernetes/hello-world-scheduler\n      volumes:\n        - name: config-volume\n          configMap:\n            name: hello-world-scheduler-config\n```\n\n### 5. 验证与测试\n\n**应用配置：**\n```bash\nkubectl create -f hello-world-Scheduler.yaml\n```\n\n**检查运行状态：**\n```bash\nkubectl get pod -n kube-system -l component=scheduler\n# 如遇问题，请查看日志\nkubectl logs -n kube-system <pod-name>\n```\n\n**创建测试 Pod：**\n创建一个指定使用 `hello-world-scheduler` 的 Pod。\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pod1\nspec:\n  schedulerName: hello-world-scheduler # 指定使用我们部署的调度器\n  containers:\n  - name: nginx\n    image: nginx\n```\n\n**验证结果：**\n1.  **成功调度**：查看 Pod 事件，确认是否被调度到 `k8s-node1`。\n    ```bash\n    kubectl describe pod pod1\n    ```\n    输出示例：\n    > Normal  Scheduled  ...  hello-world-scheduler  Successfully assigned default/pod1 to k8s-node1\n\n2.  **故障测试**：\n    *   将 `k8s-node1` 关机或标记为不可调度。\n    *   删除并重建 `pod1`。\n    *   观察 Pod 状态，应处于 `Pending` 状态，且 Event 提示调度失败（NodeNotReady 或类似原因），证明我们的 Filter 逻辑生效，确实只允许调度到该节点。\n\n---\n\n\n### reference：\n\n>k8s 官网：\nhttps://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/\nhttps://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/scheduling-framework/\nhttps://kubernetes.io/zh-cn/docs/reference/scheduling/\n\n> out-of-tree plugin 开发方式\n> https://github.com/kubernetes-sigs/scheduler-plugins/blob/master/doc/install.md#create-a-kubernetes-cluster\n> https://github.com/kubernetes-sigs/scheduler-plugins\n\n>  实践博客：\n> https://arthurchiao.art/blog/k8s-scheduling-plugins-zh/\n> https://isekiro.com/kubernetes%E7%BB%84%E4%BB%B6%E5%BC%80%E5%8F%91-%E8%87%AA%E5%AE%9A%E4%B9%89%E8%B0%83%E5%BA%A6%E5%99%A8%E4%B8%89/\n> https://zhuanlan.zhihu.com/p/113620537\n> http://team.jiunile.com/blog/2020/06/k8s-custom-scheduler.html\n> https://blog.haohtml.com/archives/34665  ","slug":"k8s-scheduler","published":1,"comments":1,"layout":"post","photos":[],"_id":"cuid57GMSRFamUF_LDulEQJ8C","content":"<h2 id=\"一、背景介绍\"><a href=\"#一、背景介绍\" class=\"headerlink\" title=\"一、背景介绍\"></a>一、背景介绍</h2><p><code>kube-scheduler</code> 是 Kubernetes 集群的核心组件之一，主要负责集群资源的调度功能。它通过特定的调度算法和策略，将 Pod 分配到最优的工作节点（Node）上，从而实现集群资源的合理利用和充分分配，这也是我们选择使用 Kubernetes 的重要理由之一。</p>\n<p>默认情况下，<code>kube-scheduler</code> 提供的原生调度器能够满足绝大多数业务场景，确保 Pod 被分配到资源充足的节点运行。但在实际的生产环境中，业务逻辑往往更加复杂。例如，我们可能需要将某类 Pod 严格限制在特定的节点上运行，或者某些节点只能用于运行特定类型的应用。为了满足这些精细化的需求，我们需要深入理解 Kubernetes 的调度机制，并掌握编写自定义调度插件（Scheduling Plugins）的能力。</p>\n<h2 id=\"二、Kubernetes-Pod-部署流程\"><a href=\"#二、Kubernetes-Pod-部署流程\" class=\"headerlink\" title=\"二、Kubernetes Pod 部署流程\"></a>二、Kubernetes Pod 部署流程</h2><p><img src=\"/images/k8s-scheduler/image-20260202015836525.png\" alt=\"Pod 部署流程\"></p>\n<p>Kubernetes 中 Pod 的总体部署流程如图所示，大致包含以下步骤：</p>\n<ol>\n<li><strong>提交请求</strong>：用户编写好 YAML 配置文件，向 <code>kube-apiserver</code> 提交创建请求。</li>\n<li><strong>准入控制</strong>：<code>kube-apiserver</code> 接收到请求后，首先通过 Webhooks 和 Controllers 进行一系列校验（准入控制）。</li>\n<li><strong>生成 Pod 对象</strong>：校验通过后，<code>kube-apiserver</code> 在集群中生成一个 Pod 对象。此时，该 Pod 的 <code>nodeName</code> 字段为空，状态（Phase）为 <code>Pending</code>。</li>\n<li><strong>调度过程</strong>：<ul>\n<li><code>kube-scheduler</code> 通过 Watch 机制监听到集群中出现了 <code>nodeName</code> 为空的 Pod，将其标记为“未调度”状态。</li>\n<li>调度器对该 Pod 执行一系列调度算法，包括过滤（Filter）和打分（Score）。</li>\n<li>选出最合适的节点后，调度器将该节点的名称绑定到 Pod 的 <code>spec.nodeName</code> 上，完成调度并更新数据到 API Server。</li>\n</ul>\n</li>\n<li><strong>节点执行</strong>：<ul>\n<li>目标节点上的 <code>kubelet</code> 监听到该 Pod 被分配给自己。</li>\n<li><code>kubelet</code> 开始执行容器创建、存储挂载、网络配置等操作。</li>\n<li>所有资源准备就绪后，Pod 状态更新为 <code>Running</code>，至此，一个完整的调度部署过程结束。</li>\n</ul>\n</li>\n</ol>\n<p><img src=\"/images/k8s-scheduler/image-20260202015902141.png\" alt=\"调度流程概览\"></p>\n<h2 id=\"三、调度流程概览\"><a href=\"#三、调度流程概览\" class=\"headerlink\" title=\"三、调度流程概览\"></a>三、调度流程概览</h2><p><img src=\"/images/k8s-scheduler/image-20260202015909730.png\" alt=\"调度详细流程\"></p>\n<p>调度器的核心工作流程涉及多个组件的协同，主要包括输入源、策略控制、数据缓存和核心算法流水线。</p>\n<h3 id=\"1-输入来源与配置\"><a href=\"#1-输入来源与配置\" class=\"headerlink\" title=\"1. 输入来源与配置\"></a>1. 输入来源与配置</h3><ul>\n<li><strong>FlagSet &#x2F; File</strong>：通过命令行参数或配置文件指定调度器参数。</li>\n<li><strong>ConfigMap</strong>：存储非敏感的配置数据，用于动态调整。</li>\n</ul>\n<h3 id=\"2-调度策略-Policy\"><a href=\"#2-调度策略-Policy\" class=\"headerlink\" title=\"2. 调度策略 (Policy)\"></a>2. 调度策略 (Policy)</h3><ul>\n<li><strong>过滤器 (Predicates)</strong>：快速筛选出符合硬性条件的节点。</li>\n<li><strong>打分器 (Priorities)</strong>：对筛选后的节点进行优先级打分。</li>\n<li><strong>扩展调度器 (Extenders)</strong>：支持外部自定义的 HTTP 回调式调度策略。</li>\n<li><strong>插件扩展点 (Plugins)</strong>：当前主流的 Scheduler Framework 扩展机制。</li>\n</ul>\n<h3 id=\"3-数据缓存-Informer\"><a href=\"#3-数据缓存-Informer\" class=\"headerlink\" title=\"3. 数据缓存 (Informer)\"></a>3. 数据缓存 (Informer)</h3><p>调度器启动时，通过 Kubernetes 的 Informer 机制（List+Watch）从 <code>kube-apiserver</code> 获取 Pods、Nodes、PV、PVC 等数据，并将这些数据预处理后存储在调度器的本地 Cache 中，以提高调度性能。</p>\n<h3 id=\"4-调度算法流水线-Algorithm\"><a href=\"#4-调度算法流水线-Algorithm\" class=\"headerlink\" title=\"4. 调度算法流水线 (Algorithm)\"></a>4. 调度算法流水线 (Algorithm)</h3><p>调度工作流主要由三个并发线程模型组成：</p>\n<ul>\n<li><p><strong>Scheduler Thread（调度主线程）</strong>：<br>核心调度逻辑在此执行，大致流程为：<code>PreFilter</code> -&gt; <code>Filter</code> -&gt; <code>PostFilter</code> -&gt; <code>Score</code> -&gt; <code>Reserve</code>。</p>\n<ul>\n<li><strong>Filter</strong>：筛选符合 Pod Spec 要求的节点。</li>\n<li><strong>Score</strong>：对筛选出的节点进行打分排序。</li>\n<li><strong>Reserve</strong>：将 Pod 与最优节点的关联信息写入 NodeCache（内存态预占），让后续等待调度的 Pod 能感知到资源已被占用。</li>\n</ul>\n</li>\n<li><p><strong>Wait Thread（等待线程）</strong>：<br>用于处理需等待的关联资源。例如等待 PVC 对应的 PV 创建成功，或在 Gang 调度中等待关联 Pod 组一同就绪。此阶段会进行 Permit（许可）检查。</p>\n</li>\n<li><p><strong>Bind Thread（绑定线程）</strong>：<br>负责将 Pod 与 Node 的绑定关系持久化到 <code>kube-apiserver</code>。调度完成后，会更新 Scheduler Cache（如 Pod 和 Node 的缓存数据）。</p>\n</li>\n</ul>\n<h2 id=\"四、调度详细流程\"><a href=\"#四、调度详细流程\" class=\"headerlink\" title=\"四、调度详细流程\"></a>四、调度详细流程</h2><p><img src=\"/images/k8s-scheduler/image-20260202020113094.png\" alt=\"调度流水线\"></p>\n<p>深入剖析 Scheduler Pipeline 的工作原理，我们可以看到更细致的队列管理和数据流转。</p>\n<h3 id=\"1-调度队列-SchedulingQueue\"><a href=\"#1-调度队列-SchedulingQueue\" class=\"headerlink\" title=\"1. 调度队列 (SchedulingQueue)\"></a>1. 调度队列 (SchedulingQueue)</h3><p>调度队列包含三个子队列：</p>\n<ul>\n<li><strong>activeQ（活跃队列）</strong>：<br>调度器启动时，所有待调度的 Pod 首先进入此队列。它是一个优先队列，按照 Pod 优先级进行排序出队。</li>\n<li><strong>backoffQ（退避队列）</strong>：<br>当 Pod 因暂时性原因（如资源短缺、调度冲突）调度失败，或调度过程中 Cache 发生变化时，会进入此队列。该队列采用<strong>指数退避</strong>策略（例如重试间隔依次为 1s, 2s, 4s, …, max 10s），避免在资源不可用时频繁无效重试。</li>\n<li><strong>unschedulableQ（不可调度队列）</strong>：<br>当 Pod 因持久性原因（如请求的资源总量超过集群上限）无法调度时进入此队列。通常需等待集群状态发生显著变化（如新节点加入、PV 释放）才会被移出。该队列每 30s 轮询一次，或者如果 Pod 停留超过 60s，也会被尝试重新移回 <code>activeQ</code>。</li>\n</ul>\n<h3 id=\"2-调度流水线执行逻辑\"><a href=\"#2-调度流水线执行逻辑\" class=\"headerlink\" title=\"2. 调度流水线执行逻辑\"></a>2. 调度流水线执行逻辑</h3><ul>\n<li><strong>采样与过滤</strong>：<br>在 Filter 阶段，如果集群节点规模巨大，调度器通过<strong>采样算法</strong>（配置比例）选取部分节点进行过滤和打分，而非全量遍历，从而提升效率。</li>\n<li><strong>容灾与分散</strong>：<br>为保证高可用，NodeCache 中的节点是按 Zone（可用区）分组的。在筛选节点时，调度器维护一个 <code>zoneIndex</code> 和 <code>nodeIndex</code>。<ul>\n<li><strong>逻辑</strong>：<code>zoneIndex</code> 从左向右轮询，<code>nodeIndex</code> 自增。即每次从不同的 Zone 中取一个 Node 进行判断。</li>\n<li><strong>目的</strong>：确保筛选出的候选节点在物理区域上足够分散，避免单点故障。</li>\n</ul>\n</li>\n<li><strong>预占与绑定</strong>：<br>当 Filter 和 Score 阶段选出最优节点（SelectHost）后，进入 <strong>Reserve</strong> 阶段。此时修改 Pod 在 PodCache 中的状态为 <code>Assumed</code>（内存预占）。随后进入 <strong>Bind</strong> 阶段，调用 API Server 将 <code>nodeName</code> 持久化到 etcd。只有当 Informer 监听到持久化成功的数据后，Pod 状态才会转变为 <code>Added</code>。</li>\n</ul>\n<h2 id=\"五、K8s-自定义调度插件扩展点\"><a href=\"#五、K8s-自定义调度插件扩展点\" class=\"headerlink\" title=\"五、K8s 自定义调度插件扩展点\"></a>五、K8s 自定义调度插件扩展点</h2><p>Kubernetes 推出了 <strong>Scheduling Framework</strong>，将调度过程定义为架构良好的“扩展点”（Extension Points）。用户只需实现特定接口（Interface）并注册到对应的扩展点，即可在不修改核心代码的情况下定制调度逻辑。</p>\n<p><img src=\"/images/k8s-scheduler/image-20260202020144193.png\" alt=\"K8s 自定义调度插件扩展点\"></p>\n<p>一个完整的调度周期分为 <strong>Scheduling Cycle</strong>（调度周期，纯内存操作）和 <strong>Binding Cycle</strong>（绑定周期，涉及外部调用）。主要扩展点如下：</p>\n<ol>\n<li><strong>QueueSort</strong>：决定 Pod 在 <code>activeQ</code> 中的排序规则（即优先级）。同一时刻只能启用一个 Sort 插件。</li>\n<li><strong>Pre-filter</strong>：调度前的预处理，可检查集群或 Pod 的前置条件。若返回 Error，调度终止。</li>\n<li><strong>Filter</strong>：<strong>核心扩展点</strong>。用于过滤不符合要求的节点。任何一个 Filter 插件返回失败，该节点即被排除。</li>\n<li><strong>Post-filter</strong>：通知型扩展点。通常用于处理 Filter 失败后的逻辑（如触发抢占 Preemption）。</li>\n<li><strong>Scoring</strong>：<strong>核心扩展点</strong>。对 Filter 后的节点进行打分。</li>\n<li><strong>Normalize scoring</strong>：在最终排序前，对分值进行归一化处理或修正。</li>\n<li><strong>Reserve</strong>：通知型扩展点。在绑定前锁定资源，防止资源超卖。</li>\n<li><strong>Permit</strong>：用于阻止或延迟绑定。支持 Approve（批准）、Deny（拒绝）或 Wait（等待）三种操作（常用于 Gang 调度）。</li>\n<li><strong>Pre-bind</strong>：绑定前的执行逻辑，例如挂载网络卷。</li>\n<li><strong>Bind</strong>：<strong>核心扩展点</strong>。执行真正的绑定操作（将 Pod 绑定到 Node）。</li>\n<li><strong>Post-bind</strong>：绑定成功后的通知，常用于资源清理。</li>\n<li><strong>Unreserve</strong>：若在 Reserve 之后绑定失败，触发此扩展点以释放预占资源。</li>\n</ol>\n<p><strong>开发提示</strong>：</p>\n<ul>\n<li>一个插件（Plugin）可以同时实现多个扩展点接口（如既实现 Filter 又实现 Score）。</li>\n<li>这些插件基于 Go Plugin 机制，通常需要在编译阶段静态链接到调度器二进制文件中。</li>\n<li>源码接口定义位于：<code>pkg/scheduler/framework/v1alpha1/interface.go</code>。</li>\n</ul>\n<h2 id=\"六、实践：编写一个简单的-HelloWorld-插件\"><a href=\"#六、实践：编写一个简单的-HelloWorld-插件\" class=\"headerlink\" title=\"六、实践：编写一个简单的 HelloWorld 插件\"></a>六、实践：编写一个简单的 HelloWorld 插件</h2><p>本示例将开发一个简单的调度插件 <code>helloworld</code>，其逻辑是：<strong>强制将 Pod 调度到名称为 <code>k8s-node1</code> 的节点上</strong>，否则调度失败。</p>\n<p>此示例主要演示插件的注册与部署流程（In-Tree 模式）。</p>\n<h3 id=\"1-编写插件源码\"><a href=\"#1-编写插件源码\" class=\"headerlink\" title=\"1. 编写插件源码\"></a>1. 编写插件源码</h3><p>在 Kubernetes 源码目录 <code>pkg/scheduler/framework/plugins</code> 下创建 <code>helloworld</code> 文件夹，并新建 <code>helloworld.go</code>：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> helloworld</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> (</span><br><span class=\"line\">    <span class=\"string\">&quot;context&quot;</span></span><br><span class=\"line\">    v1 <span class=\"string\">&quot;k8s.io/api/core/v1&quot;</span></span><br><span class=\"line\">    <span class=\"string\">&quot;k8s.io/apimachinery/pkg/runtime&quot;</span></span><br><span class=\"line\">    <span class=\"string\">&quot;k8s.io/kubernetes/pkg/scheduler/framework&quot;</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">const</span> (</span><br><span class=\"line\">    Name           = <span class=\"string\">&quot;helloWorld&quot;</span></span><br><span class=\"line\">    targetNodeName = <span class=\"string\">&quot;k8s-node1&quot;</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> helloWorld <span class=\"keyword\">struct</span>&#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 确保 helloWorld 实现了 FilterPlugin 接口</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> _ framework.FilterPlugin = &amp;helloWorld&#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(f *helloWorld)</span></span> Name() <span class=\"type\">string</span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Name</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 核心逻辑：只允许调度到 targetNodeName</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(f *helloWorld)</span></span> Filter(ctx context.Context, _ *framework.CycleState, pod *v1.Pod, nodeInfo *framework.NodeInfo) *framework.Status &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> nodeInfo.Node().Name == targetNodeName &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">nil</span> </span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> framework.NewStatus(framework.Unschedulable, <span class=\"string\">&quot;Pod can only be scheduled to the specific node: &quot;</span>+targetNodeName)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">New</span><span class=\"params\">(ctx context.Context, _ runtime.Object, _ framework.Handle)</span></span> (framework.Plugin, <span class=\"type\">error</span>) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> &amp;helloWorld&#123;&#125;, <span class=\"literal\">nil</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"2-注册插件\"><a href=\"#2-注册插件\" class=\"headerlink\" title=\"2. 注册插件\"></a>2. 注册插件</h3><p>修改 <code>pkg/scheduler/framework/plugins/registry.go</code> 文件，将插件注册到调度器注册表中：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span>(</span><br><span class=\"line\">    ...        </span><br><span class=\"line\">    <span class=\"string\">&quot;k8s.io/kubernetes/pkg/scheduler/framework/plugins/helloworld&quot;</span> <span class=\"comment\">// 引入包</span></span><br><span class=\"line\">    ...</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">NewInTreeRegistry</span><span class=\"params\">()</span></span> runtime.Registry &#123;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    registry := runtime.Registry&#123;</span><br><span class=\"line\">        ...        </span><br><span class=\"line\">        helloworld.Name: helloworld.New, <span class=\"comment\">// 注册插件</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> registry</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"3-编译与构建镜像\"><a href=\"#3-编译与构建镜像\" class=\"headerlink\" title=\"3. 编译与构建镜像\"></a>3. 编译与构建镜像</h3><p>你需要具备 Kubernetes 源码编译环境。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 切换到 k8s 源码目录并编译 kube-scheduler</span></span><br><span class=\"line\"><span class=\"built_in\">cd</span> <span class=\"variable\">$GOPATH</span>/src/k8s.io/kubernetes</span><br><span class=\"line\">make WHAT=cmd/kube-scheduler</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 编写 Dockerfile</span></span><br><span class=\"line\"><span class=\"built_in\">cat</span> &lt;&lt;<span class=\"string\">EOF &gt; Dockerfile</span></span><br><span class=\"line\"><span class=\"string\">FROM busybox</span></span><br><span class=\"line\"><span class=\"string\">ADD ./_output/local/bin/linux/amd64/kube-scheduler /usr/local/bin/kube-scheduler</span></span><br><span class=\"line\"><span class=\"string\">EOF</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 构建并推送镜像 (请替换为你自己的镜像仓库地址)</span></span><br><span class=\"line\">docker build -t registry.cn-hangzhou.aliyuncs.com/zzhxxx/helloworld-scheduler:1.0 .</span><br><span class=\"line\">docker push registry.cn-hangzhou.aliyuncs.com/zzhxxx/helloworld-scheduler:1.0</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"4-部署自定义调度器\"><a href=\"#4-部署自定义调度器\" class=\"headerlink\" title=\"4. 部署自定义调度器\"></a>4. 部署自定义调度器</h3><p>编写 <code>hello-world-scheduler.yaml</code>，包含 RBAC 设置、ConfigMap 配置及 Deployment 部署。</p>\n<p><strong>关键点</strong>：在 ConfigMap 中通过 <code>KubeSchedulerConfiguration</code> 启用我们编写的 <code>helloWorld</code> 插件。</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">ServiceAccount</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">hello-world-scheduler</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">kube-system</span></span><br><span class=\"line\"><span class=\"meta\">---</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">rbac.authorization.k8s.io/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">ClusterRoleBinding</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">hello-world-scheduler-as-kube-scheduler</span></span><br><span class=\"line\"><span class=\"attr\">subjects:</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"attr\">kind:</span> <span class=\"string\">ServiceAccount</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">hello-world-scheduler</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">kube-system</span></span><br><span class=\"line\"><span class=\"attr\">roleRef:</span></span><br><span class=\"line\">  <span class=\"attr\">kind:</span> <span class=\"string\">ClusterRole</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">system:kube-scheduler</span></span><br><span class=\"line\">  <span class=\"attr\">apiGroup:</span> <span class=\"string\">rbac.authorization.k8s.io</span></span><br><span class=\"line\"><span class=\"meta\">---</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">ConfigMap</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">hello-world-scheduler-config</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">kube-system</span></span><br><span class=\"line\"><span class=\"attr\">data:</span></span><br><span class=\"line\">  <span class=\"attr\">hello-world-scheduler-config.yaml:</span> <span class=\"string\">|</span></span><br><span class=\"line\"><span class=\"string\">    apiVersion: kubescheduler.config.k8s.io/v1</span></span><br><span class=\"line\"><span class=\"string\">    kind: KubeSchedulerConfiguration</span></span><br><span class=\"line\"><span class=\"string\">    profiles:</span></span><br><span class=\"line\"><span class=\"string\">      - schedulerName: hello-world-scheduler # 自定义调度器名称</span></span><br><span class=\"line\"><span class=\"string\">        plugins:</span></span><br><span class=\"line\"><span class=\"string\">          filter: </span></span><br><span class=\"line\"><span class=\"string\">            enabled:</span></span><br><span class=\"line\"><span class=\"string\">              - name: helloWorld # 启用我们的插件</span></span><br><span class=\"line\"><span class=\"string\">        pluginConfig:</span></span><br><span class=\"line\"><span class=\"string\">          - name: helloworld</span></span><br><span class=\"line\"><span class=\"string\">            args:</span></span><br><span class=\"line\"><span class=\"string\">              customArgument: &quot;value&quot;</span></span><br><span class=\"line\"><span class=\"string\">    leaderElection:</span></span><br><span class=\"line\"><span class=\"string\">      leaderElect: false    </span></span><br><span class=\"line\"><span class=\"string\"></span><span class=\"meta\">---</span></span><br><span class=\"line\"><span class=\"comment\"># 省略 ClusterRole 部分，通常与默认 scheduler 权限一致</span></span><br><span class=\"line\"><span class=\"comment\"># (请确保包含 nodes, pods, bindings 等资源的访问权限)</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">rbac.authorization.k8s.io/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">ClusterRole</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">hello-world-scheduler</span></span><br><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"attr\">apiGroups:</span> [<span class=\"string\">&quot;&quot;</span>]</span><br><span class=\"line\">  <span class=\"attr\">resources:</span> [<span class=\"string\">&quot;nodes&quot;</span>, <span class=\"string\">&quot;pods&quot;</span>, <span class=\"string\">&quot;bindings&quot;</span>, <span class=\"string\">&quot;pods/binding&quot;</span>, <span class=\"string\">&quot;configmaps&quot;</span>]</span><br><span class=\"line\">  <span class=\"attr\">verbs:</span> [<span class=\"string\">&quot;get&quot;</span>, <span class=\"string\">&quot;list&quot;</span>, <span class=\"string\">&quot;watch&quot;</span>, <span class=\"string\">&quot;create&quot;</span>, <span class=\"string\">&quot;update&quot;</span>, <span class=\"string\">&quot;patch&quot;</span>, <span class=\"string\">&quot;delete&quot;</span>]</span><br><span class=\"line\"><span class=\"comment\"># ... (其他必要权限)</span></span><br><span class=\"line\"><span class=\"meta\">---</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">ClusterRoleBinding</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">rbac.authorization.k8s.io/v1</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">hello-world-scheduler</span></span><br><span class=\"line\"><span class=\"attr\">roleRef:</span></span><br><span class=\"line\">  <span class=\"attr\">apiGroup:</span> <span class=\"string\">rbac.authorization.k8s.io</span></span><br><span class=\"line\">  <span class=\"attr\">kind:</span> <span class=\"string\">ClusterRole</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">hello-world-scheduler</span></span><br><span class=\"line\"><span class=\"attr\">subjects:</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"attr\">kind:</span> <span class=\"string\">ServiceAccount</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">hello-world-scheduler</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">kube-system</span></span><br><span class=\"line\"><span class=\"meta\">---</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">apps/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">Deployment</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">hello-world-scheduler</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">kube-system</span></span><br><span class=\"line\">  <span class=\"attr\">labels:</span></span><br><span class=\"line\">    <span class=\"attr\">component:</span> <span class=\"string\">scheduler</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\">  <span class=\"attr\">replicas:</span> <span class=\"number\">1</span></span><br><span class=\"line\">  <span class=\"attr\">selector:</span></span><br><span class=\"line\">    <span class=\"attr\">matchLabels:</span></span><br><span class=\"line\">      <span class=\"attr\">component:</span> <span class=\"string\">scheduler</span></span><br><span class=\"line\">  <span class=\"attr\">template:</span></span><br><span class=\"line\">    <span class=\"attr\">metadata:</span></span><br><span class=\"line\">      <span class=\"attr\">labels:</span></span><br><span class=\"line\">        <span class=\"attr\">component:</span> <span class=\"string\">scheduler</span></span><br><span class=\"line\">    <span class=\"attr\">spec:</span></span><br><span class=\"line\">      <span class=\"attr\">serviceAccountName:</span> <span class=\"string\">hello-world-scheduler</span></span><br><span class=\"line\">      <span class=\"attr\">containers:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">hello-world-scheduler</span></span><br><span class=\"line\">        <span class=\"attr\">image:</span> <span class=\"string\">registry.cn-hangzhou.aliyuncs.com/zzhxxx/helloworld-scheduler:1.0</span></span><br><span class=\"line\">        <span class=\"attr\">command:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">/usr/local/bin/kube-scheduler</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">--config=/etc/kubernetes/hello-world-scheduler/hello-world-scheduler-config.yaml</span></span><br><span class=\"line\">        <span class=\"attr\">volumeMounts:</span></span><br><span class=\"line\">          <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">config-volume</span></span><br><span class=\"line\">            <span class=\"attr\">mountPath:</span> <span class=\"string\">/etc/kubernetes/hello-world-scheduler</span></span><br><span class=\"line\">      <span class=\"attr\">volumes:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">config-volume</span></span><br><span class=\"line\">          <span class=\"attr\">configMap:</span></span><br><span class=\"line\">            <span class=\"attr\">name:</span> <span class=\"string\">hello-world-scheduler-config</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"5-验证与测试\"><a href=\"#5-验证与测试\" class=\"headerlink\" title=\"5. 验证与测试\"></a>5. 验证与测试</h3><p><strong>应用配置：</strong></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl create -f hello-world-Scheduler.yaml</span><br></pre></td></tr></table></figure>\n\n<p><strong>检查运行状态：</strong></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl get pod -n kube-system -l component=scheduler</span><br><span class=\"line\"><span class=\"comment\"># 如遇问题，请查看日志</span></span><br><span class=\"line\">kubectl logs -n kube-system &lt;pod-name&gt;</span><br></pre></td></tr></table></figure>\n\n<p><strong>创建测试 Pod：</strong><br>创建一个指定使用 <code>hello-world-scheduler</code> 的 Pod。</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">Pod</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">pod1</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\">  <span class=\"attr\">schedulerName:</span> <span class=\"string\">hello-world-scheduler</span> <span class=\"comment\"># 指定使用我们部署的调度器</span></span><br><span class=\"line\">  <span class=\"attr\">containers:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">nginx</span></span><br><span class=\"line\">    <span class=\"attr\">image:</span> <span class=\"string\">nginx</span></span><br></pre></td></tr></table></figure>\n\n<p><strong>验证结果：</strong></p>\n<ol>\n<li><p><strong>成功调度</strong>：查看 Pod 事件，确认是否被调度到 <code>k8s-node1</code>。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl describe pod pod1</span><br></pre></td></tr></table></figure>\n<p>输出示例：</p>\n<blockquote>\n<p>Normal  Scheduled  …  hello-world-scheduler  Successfully assigned default&#x2F;pod1 to k8s-node1</p>\n</blockquote>\n</li>\n<li><p><strong>故障测试</strong>：</p>\n<ul>\n<li>将 <code>k8s-node1</code> 关机或标记为不可调度。</li>\n<li>删除并重建 <code>pod1</code>。</li>\n<li>观察 Pod 状态，应处于 <code>Pending</code> 状态，且 Event 提示调度失败（NodeNotReady 或类似原因），证明我们的 Filter 逻辑生效，确实只允许调度到该节点。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3 id=\"reference：\"><a href=\"#reference：\" class=\"headerlink\" title=\"reference：\"></a>reference：</h3><blockquote>\n<p>k8s 官网：<br><a href=\"https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/\">https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/</a><br><a href=\"https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/scheduling-framework/\">https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/scheduling-framework/</a><br><a href=\"https://kubernetes.io/zh-cn/docs/reference/scheduling/\">https://kubernetes.io/zh-cn/docs/reference/scheduling/</a></p>\n</blockquote>\n<blockquote>\n<p>out-of-tree plugin 开发方式<br><a href=\"https://github.com/kubernetes-sigs/scheduler-plugins/blob/master/doc/install.md#create-a-kubernetes-cluster\">https://github.com/kubernetes-sigs/scheduler-plugins/blob/master/doc/install.md#create-a-kubernetes-cluster</a><br><a href=\"https://github.com/kubernetes-sigs/scheduler-plugins\">https://github.com/kubernetes-sigs/scheduler-plugins</a></p>\n</blockquote>\n<blockquote>\n<p> 实践博客：<br><a href=\"https://arthurchiao.art/blog/k8s-scheduling-plugins-zh/\">https://arthurchiao.art/blog/k8s-scheduling-plugins-zh/</a><br><a href=\"https://isekiro.com/kubernetes%E7%BB%84%E4%BB%B6%E5%BC%80%E5%8F%91-%E8%87%AA%E5%AE%9A%E4%B9%89%E8%B0%83%E5%BA%A6%E5%99%A8%E4%B8%89/\">https://isekiro.com/kubernetes%E7%BB%84%E4%BB%B6%E5%BC%80%E5%8F%91-%E8%87%AA%E5%AE%9A%E4%B9%89%E8%B0%83%E5%BA%A6%E5%99%A8%E4%B8%89/</a><br><a href=\"https://zhuanlan.zhihu.com/p/113620537\">https://zhuanlan.zhihu.com/p/113620537</a><br><a href=\"http://team.jiunile.com/blog/2020/06/k8s-custom-scheduler.html\">http://team.jiunile.com/blog/2020/06/k8s-custom-scheduler.html</a><br><a href=\"https://blog.haohtml.com/archives/34665\">https://blog.haohtml.com/archives/34665</a>  </p>\n</blockquote>\n","excerpt":"","more":"<h2 id=\"一、背景介绍\"><a href=\"#一、背景介绍\" class=\"headerlink\" title=\"一、背景介绍\"></a>一、背景介绍</h2><p><code>kube-scheduler</code> 是 Kubernetes 集群的核心组件之一，主要负责集群资源的调度功能。它通过特定的调度算法和策略，将 Pod 分配到最优的工作节点（Node）上，从而实现集群资源的合理利用和充分分配，这也是我们选择使用 Kubernetes 的重要理由之一。</p>\n<p>默认情况下，<code>kube-scheduler</code> 提供的原生调度器能够满足绝大多数业务场景，确保 Pod 被分配到资源充足的节点运行。但在实际的生产环境中，业务逻辑往往更加复杂。例如，我们可能需要将某类 Pod 严格限制在特定的节点上运行，或者某些节点只能用于运行特定类型的应用。为了满足这些精细化的需求，我们需要深入理解 Kubernetes 的调度机制，并掌握编写自定义调度插件（Scheduling Plugins）的能力。</p>\n<h2 id=\"二、Kubernetes-Pod-部署流程\"><a href=\"#二、Kubernetes-Pod-部署流程\" class=\"headerlink\" title=\"二、Kubernetes Pod 部署流程\"></a>二、Kubernetes Pod 部署流程</h2><p><img src=\"/images/k8s-scheduler/image-20260202015836525.png\" alt=\"Pod 部署流程\"></p>\n<p>Kubernetes 中 Pod 的总体部署流程如图所示，大致包含以下步骤：</p>\n<ol>\n<li><strong>提交请求</strong>：用户编写好 YAML 配置文件，向 <code>kube-apiserver</code> 提交创建请求。</li>\n<li><strong>准入控制</strong>：<code>kube-apiserver</code> 接收到请求后，首先通过 Webhooks 和 Controllers 进行一系列校验（准入控制）。</li>\n<li><strong>生成 Pod 对象</strong>：校验通过后，<code>kube-apiserver</code> 在集群中生成一个 Pod 对象。此时，该 Pod 的 <code>nodeName</code> 字段为空，状态（Phase）为 <code>Pending</code>。</li>\n<li><strong>调度过程</strong>：<ul>\n<li><code>kube-scheduler</code> 通过 Watch 机制监听到集群中出现了 <code>nodeName</code> 为空的 Pod，将其标记为“未调度”状态。</li>\n<li>调度器对该 Pod 执行一系列调度算法，包括过滤（Filter）和打分（Score）。</li>\n<li>选出最合适的节点后，调度器将该节点的名称绑定到 Pod 的 <code>spec.nodeName</code> 上，完成调度并更新数据到 API Server。</li>\n</ul>\n</li>\n<li><strong>节点执行</strong>：<ul>\n<li>目标节点上的 <code>kubelet</code> 监听到该 Pod 被分配给自己。</li>\n<li><code>kubelet</code> 开始执行容器创建、存储挂载、网络配置等操作。</li>\n<li>所有资源准备就绪后，Pod 状态更新为 <code>Running</code>，至此，一个完整的调度部署过程结束。</li>\n</ul>\n</li>\n</ol>\n<p><img src=\"/images/k8s-scheduler/image-20260202015902141.png\" alt=\"调度流程概览\"></p>\n<h2 id=\"三、调度流程概览\"><a href=\"#三、调度流程概览\" class=\"headerlink\" title=\"三、调度流程概览\"></a>三、调度流程概览</h2><p><img src=\"/images/k8s-scheduler/image-20260202015909730.png\" alt=\"调度详细流程\"></p>\n<p>调度器的核心工作流程涉及多个组件的协同，主要包括输入源、策略控制、数据缓存和核心算法流水线。</p>\n<h3 id=\"1-输入来源与配置\"><a href=\"#1-输入来源与配置\" class=\"headerlink\" title=\"1. 输入来源与配置\"></a>1. 输入来源与配置</h3><ul>\n<li><strong>FlagSet &#x2F; File</strong>：通过命令行参数或配置文件指定调度器参数。</li>\n<li><strong>ConfigMap</strong>：存储非敏感的配置数据，用于动态调整。</li>\n</ul>\n<h3 id=\"2-调度策略-Policy\"><a href=\"#2-调度策略-Policy\" class=\"headerlink\" title=\"2. 调度策略 (Policy)\"></a>2. 调度策略 (Policy)</h3><ul>\n<li><strong>过滤器 (Predicates)</strong>：快速筛选出符合硬性条件的节点。</li>\n<li><strong>打分器 (Priorities)</strong>：对筛选后的节点进行优先级打分。</li>\n<li><strong>扩展调度器 (Extenders)</strong>：支持外部自定义的 HTTP 回调式调度策略。</li>\n<li><strong>插件扩展点 (Plugins)</strong>：当前主流的 Scheduler Framework 扩展机制。</li>\n</ul>\n<h3 id=\"3-数据缓存-Informer\"><a href=\"#3-数据缓存-Informer\" class=\"headerlink\" title=\"3. 数据缓存 (Informer)\"></a>3. 数据缓存 (Informer)</h3><p>调度器启动时，通过 Kubernetes 的 Informer 机制（List+Watch）从 <code>kube-apiserver</code> 获取 Pods、Nodes、PV、PVC 等数据，并将这些数据预处理后存储在调度器的本地 Cache 中，以提高调度性能。</p>\n<h3 id=\"4-调度算法流水线-Algorithm\"><a href=\"#4-调度算法流水线-Algorithm\" class=\"headerlink\" title=\"4. 调度算法流水线 (Algorithm)\"></a>4. 调度算法流水线 (Algorithm)</h3><p>调度工作流主要由三个并发线程模型组成：</p>\n<ul>\n<li><p><strong>Scheduler Thread（调度主线程）</strong>：<br>核心调度逻辑在此执行，大致流程为：<code>PreFilter</code> -&gt; <code>Filter</code> -&gt; <code>PostFilter</code> -&gt; <code>Score</code> -&gt; <code>Reserve</code>。</p>\n<ul>\n<li><strong>Filter</strong>：筛选符合 Pod Spec 要求的节点。</li>\n<li><strong>Score</strong>：对筛选出的节点进行打分排序。</li>\n<li><strong>Reserve</strong>：将 Pod 与最优节点的关联信息写入 NodeCache（内存态预占），让后续等待调度的 Pod 能感知到资源已被占用。</li>\n</ul>\n</li>\n<li><p><strong>Wait Thread（等待线程）</strong>：<br>用于处理需等待的关联资源。例如等待 PVC 对应的 PV 创建成功，或在 Gang 调度中等待关联 Pod 组一同就绪。此阶段会进行 Permit（许可）检查。</p>\n</li>\n<li><p><strong>Bind Thread（绑定线程）</strong>：<br>负责将 Pod 与 Node 的绑定关系持久化到 <code>kube-apiserver</code>。调度完成后，会更新 Scheduler Cache（如 Pod 和 Node 的缓存数据）。</p>\n</li>\n</ul>\n<h2 id=\"四、调度详细流程\"><a href=\"#四、调度详细流程\" class=\"headerlink\" title=\"四、调度详细流程\"></a>四、调度详细流程</h2><p><img src=\"/images/k8s-scheduler/image-20260202020113094.png\" alt=\"调度流水线\"></p>\n<p>深入剖析 Scheduler Pipeline 的工作原理，我们可以看到更细致的队列管理和数据流转。</p>\n<h3 id=\"1-调度队列-SchedulingQueue\"><a href=\"#1-调度队列-SchedulingQueue\" class=\"headerlink\" title=\"1. 调度队列 (SchedulingQueue)\"></a>1. 调度队列 (SchedulingQueue)</h3><p>调度队列包含三个子队列：</p>\n<ul>\n<li><strong>activeQ（活跃队列）</strong>：<br>调度器启动时，所有待调度的 Pod 首先进入此队列。它是一个优先队列，按照 Pod 优先级进行排序出队。</li>\n<li><strong>backoffQ（退避队列）</strong>：<br>当 Pod 因暂时性原因（如资源短缺、调度冲突）调度失败，或调度过程中 Cache 发生变化时，会进入此队列。该队列采用<strong>指数退避</strong>策略（例如重试间隔依次为 1s, 2s, 4s, …, max 10s），避免在资源不可用时频繁无效重试。</li>\n<li><strong>unschedulableQ（不可调度队列）</strong>：<br>当 Pod 因持久性原因（如请求的资源总量超过集群上限）无法调度时进入此队列。通常需等待集群状态发生显著变化（如新节点加入、PV 释放）才会被移出。该队列每 30s 轮询一次，或者如果 Pod 停留超过 60s，也会被尝试重新移回 <code>activeQ</code>。</li>\n</ul>\n<h3 id=\"2-调度流水线执行逻辑\"><a href=\"#2-调度流水线执行逻辑\" class=\"headerlink\" title=\"2. 调度流水线执行逻辑\"></a>2. 调度流水线执行逻辑</h3><ul>\n<li><strong>采样与过滤</strong>：<br>在 Filter 阶段，如果集群节点规模巨大，调度器通过<strong>采样算法</strong>（配置比例）选取部分节点进行过滤和打分，而非全量遍历，从而提升效率。</li>\n<li><strong>容灾与分散</strong>：<br>为保证高可用，NodeCache 中的节点是按 Zone（可用区）分组的。在筛选节点时，调度器维护一个 <code>zoneIndex</code> 和 <code>nodeIndex</code>。<ul>\n<li><strong>逻辑</strong>：<code>zoneIndex</code> 从左向右轮询，<code>nodeIndex</code> 自增。即每次从不同的 Zone 中取一个 Node 进行判断。</li>\n<li><strong>目的</strong>：确保筛选出的候选节点在物理区域上足够分散，避免单点故障。</li>\n</ul>\n</li>\n<li><strong>预占与绑定</strong>：<br>当 Filter 和 Score 阶段选出最优节点（SelectHost）后，进入 <strong>Reserve</strong> 阶段。此时修改 Pod 在 PodCache 中的状态为 <code>Assumed</code>（内存预占）。随后进入 <strong>Bind</strong> 阶段，调用 API Server 将 <code>nodeName</code> 持久化到 etcd。只有当 Informer 监听到持久化成功的数据后，Pod 状态才会转变为 <code>Added</code>。</li>\n</ul>\n<h2 id=\"五、K8s-自定义调度插件扩展点\"><a href=\"#五、K8s-自定义调度插件扩展点\" class=\"headerlink\" title=\"五、K8s 自定义调度插件扩展点\"></a>五、K8s 自定义调度插件扩展点</h2><p>Kubernetes 推出了 <strong>Scheduling Framework</strong>，将调度过程定义为架构良好的“扩展点”（Extension Points）。用户只需实现特定接口（Interface）并注册到对应的扩展点，即可在不修改核心代码的情况下定制调度逻辑。</p>\n<p><img src=\"/images/k8s-scheduler/image-20260202020144193.png\" alt=\"K8s 自定义调度插件扩展点\"></p>\n<p>一个完整的调度周期分为 <strong>Scheduling Cycle</strong>（调度周期，纯内存操作）和 <strong>Binding Cycle</strong>（绑定周期，涉及外部调用）。主要扩展点如下：</p>\n<ol>\n<li><strong>QueueSort</strong>：决定 Pod 在 <code>activeQ</code> 中的排序规则（即优先级）。同一时刻只能启用一个 Sort 插件。</li>\n<li><strong>Pre-filter</strong>：调度前的预处理，可检查集群或 Pod 的前置条件。若返回 Error，调度终止。</li>\n<li><strong>Filter</strong>：<strong>核心扩展点</strong>。用于过滤不符合要求的节点。任何一个 Filter 插件返回失败，该节点即被排除。</li>\n<li><strong>Post-filter</strong>：通知型扩展点。通常用于处理 Filter 失败后的逻辑（如触发抢占 Preemption）。</li>\n<li><strong>Scoring</strong>：<strong>核心扩展点</strong>。对 Filter 后的节点进行打分。</li>\n<li><strong>Normalize scoring</strong>：在最终排序前，对分值进行归一化处理或修正。</li>\n<li><strong>Reserve</strong>：通知型扩展点。在绑定前锁定资源，防止资源超卖。</li>\n<li><strong>Permit</strong>：用于阻止或延迟绑定。支持 Approve（批准）、Deny（拒绝）或 Wait（等待）三种操作（常用于 Gang 调度）。</li>\n<li><strong>Pre-bind</strong>：绑定前的执行逻辑，例如挂载网络卷。</li>\n<li><strong>Bind</strong>：<strong>核心扩展点</strong>。执行真正的绑定操作（将 Pod 绑定到 Node）。</li>\n<li><strong>Post-bind</strong>：绑定成功后的通知，常用于资源清理。</li>\n<li><strong>Unreserve</strong>：若在 Reserve 之后绑定失败，触发此扩展点以释放预占资源。</li>\n</ol>\n<p><strong>开发提示</strong>：</p>\n<ul>\n<li>一个插件（Plugin）可以同时实现多个扩展点接口（如既实现 Filter 又实现 Score）。</li>\n<li>这些插件基于 Go Plugin 机制，通常需要在编译阶段静态链接到调度器二进制文件中。</li>\n<li>源码接口定义位于：<code>pkg/scheduler/framework/v1alpha1/interface.go</code>。</li>\n</ul>\n<h2 id=\"六、实践：编写一个简单的-HelloWorld-插件\"><a href=\"#六、实践：编写一个简单的-HelloWorld-插件\" class=\"headerlink\" title=\"六、实践：编写一个简单的 HelloWorld 插件\"></a>六、实践：编写一个简单的 HelloWorld 插件</h2><p>本示例将开发一个简单的调度插件 <code>helloworld</code>，其逻辑是：<strong>强制将 Pod 调度到名称为 <code>k8s-node1</code> 的节点上</strong>，否则调度失败。</p>\n<p>此示例主要演示插件的注册与部署流程（In-Tree 模式）。</p>\n<h3 id=\"1-编写插件源码\"><a href=\"#1-编写插件源码\" class=\"headerlink\" title=\"1. 编写插件源码\"></a>1. 编写插件源码</h3><p>在 Kubernetes 源码目录 <code>pkg/scheduler/framework/plugins</code> 下创建 <code>helloworld</code> 文件夹，并新建 <code>helloworld.go</code>：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> helloworld</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> (</span><br><span class=\"line\">    <span class=\"string\">&quot;context&quot;</span></span><br><span class=\"line\">    v1 <span class=\"string\">&quot;k8s.io/api/core/v1&quot;</span></span><br><span class=\"line\">    <span class=\"string\">&quot;k8s.io/apimachinery/pkg/runtime&quot;</span></span><br><span class=\"line\">    <span class=\"string\">&quot;k8s.io/kubernetes/pkg/scheduler/framework&quot;</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">const</span> (</span><br><span class=\"line\">    Name           = <span class=\"string\">&quot;helloWorld&quot;</span></span><br><span class=\"line\">    targetNodeName = <span class=\"string\">&quot;k8s-node1&quot;</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> helloWorld <span class=\"keyword\">struct</span>&#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 确保 helloWorld 实现了 FilterPlugin 接口</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> _ framework.FilterPlugin = &amp;helloWorld&#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(f *helloWorld)</span></span> Name() <span class=\"type\">string</span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Name</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 核心逻辑：只允许调度到 targetNodeName</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(f *helloWorld)</span></span> Filter(ctx context.Context, _ *framework.CycleState, pod *v1.Pod, nodeInfo *framework.NodeInfo) *framework.Status &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> nodeInfo.Node().Name == targetNodeName &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">nil</span> </span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> framework.NewStatus(framework.Unschedulable, <span class=\"string\">&quot;Pod can only be scheduled to the specific node: &quot;</span>+targetNodeName)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">New</span><span class=\"params\">(ctx context.Context, _ runtime.Object, _ framework.Handle)</span></span> (framework.Plugin, <span class=\"type\">error</span>) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> &amp;helloWorld&#123;&#125;, <span class=\"literal\">nil</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"2-注册插件\"><a href=\"#2-注册插件\" class=\"headerlink\" title=\"2. 注册插件\"></a>2. 注册插件</h3><p>修改 <code>pkg/scheduler/framework/plugins/registry.go</code> 文件，将插件注册到调度器注册表中：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span>(</span><br><span class=\"line\">    ...        </span><br><span class=\"line\">    <span class=\"string\">&quot;k8s.io/kubernetes/pkg/scheduler/framework/plugins/helloworld&quot;</span> <span class=\"comment\">// 引入包</span></span><br><span class=\"line\">    ...</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">NewInTreeRegistry</span><span class=\"params\">()</span></span> runtime.Registry &#123;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    registry := runtime.Registry&#123;</span><br><span class=\"line\">        ...        </span><br><span class=\"line\">        helloworld.Name: helloworld.New, <span class=\"comment\">// 注册插件</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> registry</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"3-编译与构建镜像\"><a href=\"#3-编译与构建镜像\" class=\"headerlink\" title=\"3. 编译与构建镜像\"></a>3. 编译与构建镜像</h3><p>你需要具备 Kubernetes 源码编译环境。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 切换到 k8s 源码目录并编译 kube-scheduler</span></span><br><span class=\"line\"><span class=\"built_in\">cd</span> <span class=\"variable\">$GOPATH</span>/src/k8s.io/kubernetes</span><br><span class=\"line\">make WHAT=cmd/kube-scheduler</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 编写 Dockerfile</span></span><br><span class=\"line\"><span class=\"built_in\">cat</span> &lt;&lt;<span class=\"string\">EOF &gt; Dockerfile</span></span><br><span class=\"line\"><span class=\"string\">FROM busybox</span></span><br><span class=\"line\"><span class=\"string\">ADD ./_output/local/bin/linux/amd64/kube-scheduler /usr/local/bin/kube-scheduler</span></span><br><span class=\"line\"><span class=\"string\">EOF</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 构建并推送镜像 (请替换为你自己的镜像仓库地址)</span></span><br><span class=\"line\">docker build -t registry.cn-hangzhou.aliyuncs.com/zzhxxx/helloworld-scheduler:1.0 .</span><br><span class=\"line\">docker push registry.cn-hangzhou.aliyuncs.com/zzhxxx/helloworld-scheduler:1.0</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"4-部署自定义调度器\"><a href=\"#4-部署自定义调度器\" class=\"headerlink\" title=\"4. 部署自定义调度器\"></a>4. 部署自定义调度器</h3><p>编写 <code>hello-world-scheduler.yaml</code>，包含 RBAC 设置、ConfigMap 配置及 Deployment 部署。</p>\n<p><strong>关键点</strong>：在 ConfigMap 中通过 <code>KubeSchedulerConfiguration</code> 启用我们编写的 <code>helloWorld</code> 插件。</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">ServiceAccount</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">hello-world-scheduler</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">kube-system</span></span><br><span class=\"line\"><span class=\"meta\">---</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">rbac.authorization.k8s.io/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">ClusterRoleBinding</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">hello-world-scheduler-as-kube-scheduler</span></span><br><span class=\"line\"><span class=\"attr\">subjects:</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"attr\">kind:</span> <span class=\"string\">ServiceAccount</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">hello-world-scheduler</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">kube-system</span></span><br><span class=\"line\"><span class=\"attr\">roleRef:</span></span><br><span class=\"line\">  <span class=\"attr\">kind:</span> <span class=\"string\">ClusterRole</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">system:kube-scheduler</span></span><br><span class=\"line\">  <span class=\"attr\">apiGroup:</span> <span class=\"string\">rbac.authorization.k8s.io</span></span><br><span class=\"line\"><span class=\"meta\">---</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">ConfigMap</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">hello-world-scheduler-config</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">kube-system</span></span><br><span class=\"line\"><span class=\"attr\">data:</span></span><br><span class=\"line\">  <span class=\"attr\">hello-world-scheduler-config.yaml:</span> <span class=\"string\">|</span></span><br><span class=\"line\"><span class=\"string\">    apiVersion: kubescheduler.config.k8s.io/v1</span></span><br><span class=\"line\"><span class=\"string\">    kind: KubeSchedulerConfiguration</span></span><br><span class=\"line\"><span class=\"string\">    profiles:</span></span><br><span class=\"line\"><span class=\"string\">      - schedulerName: hello-world-scheduler # 自定义调度器名称</span></span><br><span class=\"line\"><span class=\"string\">        plugins:</span></span><br><span class=\"line\"><span class=\"string\">          filter: </span></span><br><span class=\"line\"><span class=\"string\">            enabled:</span></span><br><span class=\"line\"><span class=\"string\">              - name: helloWorld # 启用我们的插件</span></span><br><span class=\"line\"><span class=\"string\">        pluginConfig:</span></span><br><span class=\"line\"><span class=\"string\">          - name: helloworld</span></span><br><span class=\"line\"><span class=\"string\">            args:</span></span><br><span class=\"line\"><span class=\"string\">              customArgument: &quot;value&quot;</span></span><br><span class=\"line\"><span class=\"string\">    leaderElection:</span></span><br><span class=\"line\"><span class=\"string\">      leaderElect: false    </span></span><br><span class=\"line\"><span class=\"string\"></span><span class=\"meta\">---</span></span><br><span class=\"line\"><span class=\"comment\"># 省略 ClusterRole 部分，通常与默认 scheduler 权限一致</span></span><br><span class=\"line\"><span class=\"comment\"># (请确保包含 nodes, pods, bindings 等资源的访问权限)</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">rbac.authorization.k8s.io/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">ClusterRole</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">hello-world-scheduler</span></span><br><span class=\"line\"><span class=\"attr\">rules:</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"attr\">apiGroups:</span> [<span class=\"string\">&quot;&quot;</span>]</span><br><span class=\"line\">  <span class=\"attr\">resources:</span> [<span class=\"string\">&quot;nodes&quot;</span>, <span class=\"string\">&quot;pods&quot;</span>, <span class=\"string\">&quot;bindings&quot;</span>, <span class=\"string\">&quot;pods/binding&quot;</span>, <span class=\"string\">&quot;configmaps&quot;</span>]</span><br><span class=\"line\">  <span class=\"attr\">verbs:</span> [<span class=\"string\">&quot;get&quot;</span>, <span class=\"string\">&quot;list&quot;</span>, <span class=\"string\">&quot;watch&quot;</span>, <span class=\"string\">&quot;create&quot;</span>, <span class=\"string\">&quot;update&quot;</span>, <span class=\"string\">&quot;patch&quot;</span>, <span class=\"string\">&quot;delete&quot;</span>]</span><br><span class=\"line\"><span class=\"comment\"># ... (其他必要权限)</span></span><br><span class=\"line\"><span class=\"meta\">---</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">ClusterRoleBinding</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">rbac.authorization.k8s.io/v1</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">hello-world-scheduler</span></span><br><span class=\"line\"><span class=\"attr\">roleRef:</span></span><br><span class=\"line\">  <span class=\"attr\">apiGroup:</span> <span class=\"string\">rbac.authorization.k8s.io</span></span><br><span class=\"line\">  <span class=\"attr\">kind:</span> <span class=\"string\">ClusterRole</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">hello-world-scheduler</span></span><br><span class=\"line\"><span class=\"attr\">subjects:</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"attr\">kind:</span> <span class=\"string\">ServiceAccount</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">hello-world-scheduler</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">kube-system</span></span><br><span class=\"line\"><span class=\"meta\">---</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">apps/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">Deployment</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">hello-world-scheduler</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">kube-system</span></span><br><span class=\"line\">  <span class=\"attr\">labels:</span></span><br><span class=\"line\">    <span class=\"attr\">component:</span> <span class=\"string\">scheduler</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\">  <span class=\"attr\">replicas:</span> <span class=\"number\">1</span></span><br><span class=\"line\">  <span class=\"attr\">selector:</span></span><br><span class=\"line\">    <span class=\"attr\">matchLabels:</span></span><br><span class=\"line\">      <span class=\"attr\">component:</span> <span class=\"string\">scheduler</span></span><br><span class=\"line\">  <span class=\"attr\">template:</span></span><br><span class=\"line\">    <span class=\"attr\">metadata:</span></span><br><span class=\"line\">      <span class=\"attr\">labels:</span></span><br><span class=\"line\">        <span class=\"attr\">component:</span> <span class=\"string\">scheduler</span></span><br><span class=\"line\">    <span class=\"attr\">spec:</span></span><br><span class=\"line\">      <span class=\"attr\">serviceAccountName:</span> <span class=\"string\">hello-world-scheduler</span></span><br><span class=\"line\">      <span class=\"attr\">containers:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">hello-world-scheduler</span></span><br><span class=\"line\">        <span class=\"attr\">image:</span> <span class=\"string\">registry.cn-hangzhou.aliyuncs.com/zzhxxx/helloworld-scheduler:1.0</span></span><br><span class=\"line\">        <span class=\"attr\">command:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">/usr/local/bin/kube-scheduler</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">--config=/etc/kubernetes/hello-world-scheduler/hello-world-scheduler-config.yaml</span></span><br><span class=\"line\">        <span class=\"attr\">volumeMounts:</span></span><br><span class=\"line\">          <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">config-volume</span></span><br><span class=\"line\">            <span class=\"attr\">mountPath:</span> <span class=\"string\">/etc/kubernetes/hello-world-scheduler</span></span><br><span class=\"line\">      <span class=\"attr\">volumes:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">config-volume</span></span><br><span class=\"line\">          <span class=\"attr\">configMap:</span></span><br><span class=\"line\">            <span class=\"attr\">name:</span> <span class=\"string\">hello-world-scheduler-config</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"5-验证与测试\"><a href=\"#5-验证与测试\" class=\"headerlink\" title=\"5. 验证与测试\"></a>5. 验证与测试</h3><p><strong>应用配置：</strong></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl create -f hello-world-Scheduler.yaml</span><br></pre></td></tr></table></figure>\n\n<p><strong>检查运行状态：</strong></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl get pod -n kube-system -l component=scheduler</span><br><span class=\"line\"><span class=\"comment\"># 如遇问题，请查看日志</span></span><br><span class=\"line\">kubectl logs -n kube-system &lt;pod-name&gt;</span><br></pre></td></tr></table></figure>\n\n<p><strong>创建测试 Pod：</strong><br>创建一个指定使用 <code>hello-world-scheduler</code> 的 Pod。</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">Pod</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">pod1</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\">  <span class=\"attr\">schedulerName:</span> <span class=\"string\">hello-world-scheduler</span> <span class=\"comment\"># 指定使用我们部署的调度器</span></span><br><span class=\"line\">  <span class=\"attr\">containers:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">nginx</span></span><br><span class=\"line\">    <span class=\"attr\">image:</span> <span class=\"string\">nginx</span></span><br></pre></td></tr></table></figure>\n\n<p><strong>验证结果：</strong></p>\n<ol>\n<li><p><strong>成功调度</strong>：查看 Pod 事件，确认是否被调度到 <code>k8s-node1</code>。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl describe pod pod1</span><br></pre></td></tr></table></figure>\n<p>输出示例：</p>\n<blockquote>\n<p>Normal  Scheduled  …  hello-world-scheduler  Successfully assigned default&#x2F;pod1 to k8s-node1</p>\n</blockquote>\n</li>\n<li><p><strong>故障测试</strong>：</p>\n<ul>\n<li>将 <code>k8s-node1</code> 关机或标记为不可调度。</li>\n<li>删除并重建 <code>pod1</code>。</li>\n<li>观察 Pod 状态，应处于 <code>Pending</code> 状态，且 Event 提示调度失败（NodeNotReady 或类似原因），证明我们的 Filter 逻辑生效，确实只允许调度到该节点。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3 id=\"reference：\"><a href=\"#reference：\" class=\"headerlink\" title=\"reference：\"></a>reference：</h3><blockquote>\n<p>k8s 官网：<br><a href=\"https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/\">https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/</a><br><a href=\"https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/scheduling-framework/\">https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/scheduling-framework/</a><br><a href=\"https://kubernetes.io/zh-cn/docs/reference/scheduling/\">https://kubernetes.io/zh-cn/docs/reference/scheduling/</a></p>\n</blockquote>\n<blockquote>\n<p>out-of-tree plugin 开发方式<br><a href=\"https://github.com/kubernetes-sigs/scheduler-plugins/blob/master/doc/install.md#create-a-kubernetes-cluster\">https://github.com/kubernetes-sigs/scheduler-plugins/blob/master/doc/install.md#create-a-kubernetes-cluster</a><br><a href=\"https://github.com/kubernetes-sigs/scheduler-plugins\">https://github.com/kubernetes-sigs/scheduler-plugins</a></p>\n</blockquote>\n<blockquote>\n<p> 实践博客：<br><a href=\"https://arthurchiao.art/blog/k8s-scheduling-plugins-zh/\">https://arthurchiao.art/blog/k8s-scheduling-plugins-zh/</a><br><a href=\"https://isekiro.com/kubernetes%E7%BB%84%E4%BB%B6%E5%BC%80%E5%8F%91-%E8%87%AA%E5%AE%9A%E4%B9%89%E8%B0%83%E5%BA%A6%E5%99%A8%E4%B8%89/\">https://isekiro.com/kubernetes%E7%BB%84%E4%BB%B6%E5%BC%80%E5%8F%91-%E8%87%AA%E5%AE%9A%E4%B9%89%E8%B0%83%E5%BA%A6%E5%99%A8%E4%B8%89/</a><br><a href=\"https://zhuanlan.zhihu.com/p/113620537\">https://zhuanlan.zhihu.com/p/113620537</a><br><a href=\"http://team.jiunile.com/blog/2020/06/k8s-custom-scheduler.html\">http://team.jiunile.com/blog/2020/06/k8s-custom-scheduler.html</a><br><a href=\"https://blog.haohtml.com/archives/34665\">https://blog.haohtml.com/archives/34665</a>  </p>\n</blockquote>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cuidvZwLBwExEKdx-oaUYficy","category_id":"cuidyUd-40QcwVtkj5Lk4sEGa","_id":"cuidlJ_jMINGXbZoScfULieQN"},{"post_id":"cuidW-85cENBSdM3YwmniaYgO","category_id":"cuidyUd-40QcwVtkj5Lk4sEGa","_id":"cuid18g6c28LHmG9Uk8uQMWa1"},{"post_id":"cuidbGd9C9Lf2EyejajXVOyaY","category_id":"cuidZ52iqtzd9eDvrpeUhMLXv","_id":"cuidC8OKzWrj0b9WFxk3LnvCf"},{"post_id":"cuid57GMSRFamUF_LDulEQJ8C","category_id":"cuidZ52iqtzd9eDvrpeUhMLXv","_id":"cuidGYVJk96MLTZg3NsZsniUX"}],"PostTag":[{"post_id":"cuidvZwLBwExEKdx-oaUYficy","tag_id":"cuidAQqi0Od_Q7-Rgy2svIvyh","_id":"cuidd4-iRBe-pO6hp_2gZHERN"},{"post_id":"cuidvZwLBwExEKdx-oaUYficy","tag_id":"cuidGWnRXVXc_yqsMeEYODDsw","_id":"cuidfnIqm0w3HsKWBh15CCa_x"},{"post_id":"cuidvZwLBwExEKdx-oaUYficy","tag_id":"cuidyomHw5mbGoGIpo1NwTxWN","_id":"cuidltKQq9j9KgGuczpZB9Zph"},{"post_id":"cuidvZwLBwExEKdx-oaUYficy","tag_id":"cuidH-UNGinmgilA_kFWbv5gC","_id":"cuido-cDqwAuJWTEBRIlmM8d4"},{"post_id":"cuidW-85cENBSdM3YwmniaYgO","tag_id":"cuidwVWiI8DX8SuIantTYUsgx","_id":"cuidFx6M4a73D2yiTRKZiA2Gu"},{"post_id":"cuidW-85cENBSdM3YwmniaYgO","tag_id":"cuidS2dm6p7NI3WsFwAZ9D6a3","_id":"cuidz1XT6uUN1byOaEODY7_dg"},{"post_id":"cuidW-85cENBSdM3YwmniaYgO","tag_id":"cuidf66MghwwG5ev8ns7drABV","_id":"cuidqRPjR6M8_VOObNYJtTDGY"},{"post_id":"cuidbGd9C9Lf2EyejajXVOyaY","tag_id":"cuidbvXCSGHwu6khISMx5tZYW","_id":"cuidrG_VqQ3mcqLXbgh5xiS_c"},{"post_id":"cuidbGd9C9Lf2EyejajXVOyaY","tag_id":"cuid0_0J5S4F-4aK4squ2MhTM","_id":"cuidZwJM4jQvYwmwy_8x147QZ"},{"post_id":"cuidbGd9C9Lf2EyejajXVOyaY","tag_id":"cuidpgAd6vrfT9m_-MEcWaY3y","_id":"cuidIPE6_Ikgl8DqHH0nF0sU8"},{"post_id":"cuidbGd9C9Lf2EyejajXVOyaY","tag_id":"cuid_Zxc8BGx0RoAJe1w1CIC9","_id":"cuidSlF8cIXNTsuTkqjLz6zdB"},{"post_id":"cuidbGd9C9Lf2EyejajXVOyaY","tag_id":"cuidCxZIE-woNMHviVTo1znau","_id":"cuidOjfi3IzBYxr0_YwlqyWi7"},{"post_id":"cuid57GMSRFamUF_LDulEQJ8C","tag_id":"cuidpliyW0wJ5LWw3qX6Ri_Tt","_id":"cuidHAfI0zOx-p3BWunxNvEC8"},{"post_id":"cuid57GMSRFamUF_LDulEQJ8C","tag_id":"cuidN51mkVDUUl3ZQTNcrYR7E","_id":"cuidCDzMmWjpml9QjZ22zhveI"}],"Tag":[{"name":"DeepSeek","_id":"cuidAQqi0Od_Q7-Rgy2svIvyh"},{"name":"Context Parallelism","_id":"cuidGWnRXVXc_yqsMeEYODDsw"},{"name":"Ascend","_id":"cuidyomHw5mbGoGIpo1NwTxWN"},{"name":"Optimization","_id":"cuidH-UNGinmgilA_kFWbv5gC"},{"name":"Deep Learning","_id":"cuidwVWiI8DX8SuIantTYUsgx"},{"name":"LLM inference","_id":"cuidS2dm6p7NI3WsFwAZ9D6a3"},{"name":"Deepseek","_id":"cuidf66MghwwG5ev8ns7drABV"},{"name":"Clash","_id":"cuidbvXCSGHwu6khISMx5tZYW"},{"name":"代理配置","_id":"cuid0_0J5S4F-4aK4squ2MhTM"},{"name":"Linux","_id":"cuidpgAd6vrfT9m_-MEcWaY3y"},{"name":"命令行工具","_id":"cuid_Zxc8BGx0RoAJe1w1CIC9"},{"name":"网络工具","_id":"cuidCxZIE-woNMHviVTo1znau"},{"name":"k8s","_id":"cuidpliyW0wJ5LWw3qX6Ri_Tt"},{"name":"scheduler","_id":"cuidN51mkVDUUl3ZQTNcrYR7E"}]}}